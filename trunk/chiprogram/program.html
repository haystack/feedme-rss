
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html>
<head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<title>CHI 2010 - Test Program</title>


	<script type="text/javascript" src="http://ajax.googleapis.com/ajax/libs/jquery/1.4.1/jquery.min.js"></script>
	<script type="text/javascript" src="spinner/jquery.spinner.js"></script>
	
    <link rel="stylesheet" href="http://groups.csail.mit.edu/haystack/feedme/jquery-ui-autocomplete/themes/base/ui.all.css" type="text/css" />
	<script type="text/javascript" src="http://groups.csail.mit.edu/haystack/feedme/jquery.fancybox-1.3.1/fancybox/jquery.fancybox-1.3.1.pack.js"></script>
    <link rel="stylesheet" href="http://groups.csail.mit.edu/haystack/feedme/jquery.fancybox-1.3.1/fancybox/jquery.fancybox-1.3.1.css" type="text/css" />
	<script type="text/javascript" src="http://groups.csail.mit.edu/haystack/feedme/jquery.elastic-1.6.source.js"></script>
	<script type="text/javascript" src="http://groups.csail.mit.edu/haystack/feedme/jquery.color.js"></script>
	
	<script type="text/javascript" src="http://groups.csail.mit.edu/haystack/feedme/feedme-chi.js"></script>

	<script type="text/javascript">

		$(document).ready(function() {

			var sessions = $("td.session");
			var sessionDetails = $("td.session_details");
			var searchTimeout = null;
			
			var savedSearch = "";
			var mode = "live";


			jQuery.expr[':'].Contain = function(a,i,m){
			    return (a.textContent || a.innerText || "").toLowerCase().indexOf(m[3].toLowerCase())>=0;
			};
		

			$("td.session_details").parent().hide();
			$("td.session_details").hide();
			$("span.togglePapers").hide();
			
			$("td.session").click(function() {
				
				if (mode == "print") {
					return false;
				}
				
				var id = $(this).attr("id");				
				var details = $("td#" + id + "_details");
				
				if (details.length == 0) {
					return;
				}
				
				var alreadyShowing = $(this).hasClass("expanded");

				$(this).parent().next().find("td.session_details").hide();
				$(this).parent().next().hide();
				$(this).siblings("td.time").attr("rowspan", 1);
				//$(this).siblings("td.session").css("border-top-width", "0px");
				$(this).parent().children().removeClass("expanded");

				if (!alreadyShowing) {
					$(this).siblings("td.time").attr("rowspan", 2);
					details.parent().show();
					details.show();
					//$(this).siblings("td.session").css("border-top-width", "1px");
					$(this).addClass("expanded");
				}
			});
									
			function filterSessions() {
				var search = $("input#filter").val();
				if (search != "") {
					sessions.fadeTo(0, 0.33);
					sessionDetails.filter(":visible").fadeTo(0, 0.33);
					sessionDetails.filter(":Contain(" + search + ")").each(function(index) {
						$(this).filter(":visible").fadeTo(0, 1.0)
						var sID = $(this).attr("id").split("_")[0];
						$("td#" + sID).fadeTo(0, 1.0);
					});
					sessions.filter(":Contain(" + search + ")").each(function(index) {
						var sID = $(this).attr("id");
						$(this).fadeTo(0, 1.0);
						$("div#" + sID + "_details").filter(":visible").fadeTo(0, 1.0);
					});
				} else {
					sessions.filter(":visible").fadeTo(0, 1.0);
					sessionDetails.filter(":visible").fadeTo(0, 1.0);
				}
				location.hash = escape(search);
			}

			/*
			$("input#filter").click(function() {
				$(this).attr("value", "");
				$(this).keyup();
			});
			*/
			
			$("input#filter").keyup(function() {
				clearTimeout(searchTimeout);
				searchTimeout = setTimeout(filterSessions, 200);
			});
			
			
			$("span.toggleAbstract").toggle(
				function () {
			    	$(this).next("span.abstractText").show();
				},
			    function () {
			    	$(this).next("span.abstractText").hide();
			    }
			);
			
			
			$("input.sessioncheck").click(function(event) {
				event.stopPropagation();
				
				var sessionId = $(this).parent().attr("id");
				var details = $("td#" + sessionId + "_details");
				
				var paperchecks = details.children("div.paper").children("input.papercheck");
				paperchecks.attr("checked", $(this).attr("checked"));
			
				/*
				if ($(this).attr("checked")) {
					$(this).next("span.paperschecked").text("" + paperchecks.length);
				} else {
					if ($(this).next("span.paperschecked").text() == $(this).nextAll("span.totalpapers").text()) {
						$(this).next("span.paperschecked").text("0");
					} else {
						$(this).attr("checked", true);
						paperchecks.attr("checked", true);
						$(this).next("span.paperschecked").text("" + paperchecks.length);
					}
				}
				*/
			
				fadeChecked();
			
			});
			
			$("input.papercheck").click(function() {
				var sessionId  = $(this).parent().parent().attr("id").split("_", 1)[0];
				var checkCount = $(this).parent().parent().children("div.paper").children("input:checked").length;
				$("td#" + sessionId + " > span.paperschecked").text("" + checkCount);
				if (checkCount > 0) {
					$("td#" + sessionId + " > input.sessioncheck").attr("checked", true);
				} else {
					$("td#" + sessionId + " > input.sessioncheck").attr("checked", false);
				}
				
				fadeChecked();
			});
			
			
			function printMode() {
				savedSearch = $("input#filter").val();
				$("input#filter").val("");
				filterSessions();
				$("input#filter").attr("disabled", "disabled");
				mode = "print";
			}
			
			function liveMode() {
				$("input#filter").removeAttr("disabled");
				$("input#filter").val(savedSearch);
				filterSessions();
				mode = "live";
			}
			
			
			function fadeChecked() {
				if ($("input#showChecked").attr("checked")) {
					
					printMode();
					
					$("div.paper > input.papercheck:not(:checked)").parent().fadeTo(0, 0.75);
					$("div.paper > input.papercheck:checked").parent().fadeTo(0, 1.0);
					
					$("td.session > input.sessioncheck:not(:checked)").parent().fadeTo(0, 0.75).each(function(index) {
						$("td#" + $(this).attr("id") + "_details").hide();
						$(this).removeClass("expanded");
						$(this).hide();
					});
					
					$("td.session > input.sessioncheck:checked").parent().fadeTo(0, 1.0).each(function(index) {
						$("td#" + $(this).attr("id") + "_details").show();
						$("td#" + $(this).attr("id") + "_details").parent().show();
						$(this).parent().next().show();
						$(this).siblings("td.time").attr("rowspan", 2);
						$(this).addClass("expanded");
					});

					$("tr.details_row > td").each(function(index) {
						var detailsShown = $(this).parent().children("td.session_details:visible").length;
						var newColspan = $(this).parent().prev("tr.timeslot").children("td.session").length / detailsShown;
						//$(this).parent().children("td.session_details:visible").attr("colspan", newColspan);
						$(this).parent().children("td.session_details:visible").attr("colspan", 1);
					});

				} else {
					
					$("div.paper").fadeTo(0, 1.0);
					$("td.session_details").hide();
					$("td.session_details").parent().hide();
					$("td.session_details").each(function(index) {
						$(this).attr("colspan", $(this).parent().prev("tr.timeslot").children("td.session").length);
					});
					$("td.time").attr("rowspan", 1);
					$("td.session").show();
					$("td.session").removeClass("expanded");
					
					liveMode();
					
				}
			}
			
			$("input#showChecked").click(function() {
				fadeChecked();
			});
			
            FeedMeChi();

			var query = location.hash;
			if (query != "") {
				if ($("div" + query).length == 1) {
				    $("td" + query.split("_")[0]).click();
				    window.location = location.href;
				} else if ($("td" + query).length == 1) {
					$("td" + query).click();
				} else {
					$("input#filter").val(unescape(query.slice(1)));
					filterSessions();
				}
			}
            
        });
        
	</script>
	
	<style type="text/css">
		
		/* CSS RESET */
		
		html, body, div, span, applet, object, iframe,
		h1, h2, h3, h4, h5, h6, p, blockquote, pre,
		a, abbr, acronym, address, big, cite, code,
		del, dfn, em, font, img, ins, kbd, q, s, samp,
		small, strike, strong, sub, sup, tt, var,
		b, u, i, center,
		dl, dt, dd, ol, ul, li,
		fieldset, form, label, legend,
		table, caption, tbody, tfoot, thead, tr, th, td {
			margin: 0;
			padding: 0;
			border: 0;
			font-size: 100%;
			vertical-align: baseline;
			background: transparent;
		}
		body {
			line-height: 1;
		}
		ol, ul {
			list-style: none;
		}
		blockquote, q {
			quotes: none;
		}
		blockquote:before, blockquote:after,
		q:before, q:after {
			content: '';
			content: none;
		}

		/* remember to define focus styles! 
		:focus {
			outline: 0;
		}
		*/
		/* remember to highlight inserts somehow! */
		ins {
			text-decoration: none;
		}
		del {
			text-decoration: line-through;
			font-weight: normal;
		}

		/* tables still need 'cellspacing="0"' in the markup 
		table {
			border-collapse: collapse;
			border-spacing: 0;
		}
		*/
		/* END CSS RESET */
		
		
		body {
			font-family: Helvetica;
			margin: 0em 1em;
		}
		
		
		table.program {
			margin: 1em;
			line-height: 1.25em;
			table-layout: fixed;
		}
		
		td {
			font-size: 0.8em;
			min-width: 5em;
		}
		
		tr.timeslot td {
			padding: 1em;
			border: 1px solid #AAA;
			border-top-width: 0px;
			border-left-width: 0px;
			width: 10em;
		}

		tr.timeslot td:first-child {
			border-left-width: 1px;
		}

		tr.closer td {
			border-top: 1px solid #AAA;
		}
		
		
		td.time {
			text-align: center;
			vertical-align: top;
			background-color: #EBEBEB;
			font-weight: bold;
			line-height: 1.5em;
			width: 5em;
			max-width: 5em;
		}

		td.session {
			cursor: pointer;
			text-align: center;
			
		}
		
		input.sessioncheck {
			margin-top: 1em;
		}
		
		td.session img {
			margin-top: 1em;
			display: inline;
		}
		
		td.expanded {
			border-bottom-width: 0px !important;
			border-bottom-color: #FFF;
			background-color: #EEF;
		}
		
		td.session:hover {
			background-color: #EEF;
		}
		
		tr.details_row {
			display: none;
		}
		
		td.session_details {
			padding: 1em;
			background-color: #EEF;
			border-bottom: 1px solid #AAA;
			border-right: 1px solid #AAA;
		}
		
		td.session_details div {
			/*margin-bottom: 1em; (only applied to div.abstract, so I added it below) */
		}
		
		

		span.type, .title {
			display: block;
		}
		
		span.type {
			font-style: italic;
			white-space: nowrap;
		}
		
		span.location {
			white-space: nowrap;
			display: block;
		}
		
		.title {
			font-weight: bold;
			margin: 0.5em 0em;
			text-decoration: none;
		}
		
		div.day {
			margin-bottom: 5em;
		}
		
		div.day h1 {
			font-size: 1.5em;
		}
		
		div.paper {
			margin-bottom: 2em !important;
		}
		
		div.paper span.title {
			display: inline;
		}
		
		div.paper span.type {
			display: inline;	
		}
		
		div#notice {
			background-color: #DDF;
			padding: 1em;
		}
		
		div.authors {
			margin-left: 1em;
			margin-bottom: 0.5em !important;
		}
		
		a.author {
			color: #000;
		}
		
		
		div.abstract {
			margin-left: 1em;
			margin-bottom: 1em;
		}
		
		span.toggleAbstract {
			font-weight: bold;
			cursor: pointer;
		}
		
		span.abstractText {
			display: none;
		}
		
		input.papercheck {
			margin-right: 0.75em;
			margin-left: 1em;
		}
		
		.affiliation {
			font-style: italic;
			color: #000;
		}
		
		div#searchArea {
			margin: 2em;
			font-weight: bold;
		}
		
		div#searchArea span {
			margin: 0em 1em;
			text-transform: uppercase;
			font-variant: small-caps;
			font-weight: bold;
		}

		div#searchArea input#filter {
			font-size: 1em;
			text-transform: uppercase;
			font-variant: small-caps;
			font-weight: bold;
		}

		div#pageLinks {
			margin-top: 2em;
			margin-left: 1em;
		}
		
		div#pageLinks a {
			text-transform: uppercase;
			font-variant: small-caps;
			margin: 0em 1em;
		}
		
		/* FeedMe styles */
		a.fm-share {
		    margin-left: 5px;
		    color: #000000;
		    text-decoration: underline;
		    cursor: pointer;
		}
		
		.feedme-suggestion-container {
		    background-color: #EEEEFF;
		    padding: 10px 15px;
            /*border: 1px solid #d2d2d2;*/
		}
        .feedme-suggestion-container a { 
            color: #333;
        }		
        .feedme-suggestion-container div { 
            margin-bottom: 0px;
        }	
        
        .feedme-suggestions { 
            display: inline; 
        }
        .feedme-person { }

        .feedme-placeholder { 
            display: inline;
        }
        .feedme-button { 
            display: inline-block; 
            padding: 3px 6px; 
            margin: 0px 10px 5px 0px; 
            cursor: pointer; 
            /*border: 1px solid white;*/
            vertical-align: top; 
            text-align: center;
        }
        .feedme-toggle { 
            background-color: #F3F5FC;
            border: 1px solid #d2d2d2;
            -moz-border-radius: 5px; 
        }
        .feedme-sent {
            -moz-border-radius: 5px;         
        }
        .feedme-autocomplete { 
            width: 100px; 
        }
        .feedme-autocomplete-container { 
            display: inline; 
            vertical-align: middle;
            margin-right: 10px; 
        }
        .feedme-autocomplete-added {
        }
        .feedme-autocompleteToggle { 
            color: gray; 
        }
        .feedme-addImg { 
            margin-left: 5px;
            cursor: pointer;
            }
        .wait-for-suggestions { 
            visibility: hidden;
        }
        .expand-container { 
            display: none; 
        }
        .comment-textarea { 
            height: 21px; 
            width: 315px; 
            margin-top: 10px;
            margin-right: 5px; 
        }
        .feedme-num-shared { 
            font-size: 7pt; 
            text-align: right; 
            color: #666;
        }
        .feedme-recommend-header { 
            display: inline-block; 
            margin-right: 5px; 
        }
        .feedme-share-button {
            position: relative;
            width: 30px;
            vertical-align: top;
            top: 10px;
            /*border-color: #FF9900;*/
        }
        .feedme-now-button { 
            /*-moz-border-radius-topright: 0px;
            -moz-border-radius-bottomright: 0px;
            margin-right: 0px; 
            border-right: 0px*/
        }
        .feedme-now-button.no-social {
            border: 1px solid #d2d2d2;
            -moz-border-radius: 5px; 
        }
        .feedme-later-button { 
            -moz-border-radius-topleft: 0px;
            -moz-border-radius-bottomleft: 0px; 
        }
        .feedme-more-recommendations {
            display: inline;
        }
        .feedme-recommendations-group {
            position: relative;
            right: 7px;
        }

        .feedme-logo-icon {
            position: relative;
            right: 3px;
            top: -3px;
        }
        .feedme-send-individually-area {
            opacity: 0;
            position: relative;
            right: 3    px;
        }
		
	</style>


</head>

<body>

	<div id="notice">
		This is not an official CHI 2010 page. For any questions or comments
		regarding the contents of this page feel free to 
		<a href="mailto:nirmal@gatech.edu?subject=CHIPages">email</a> or
		contact me on <a href="http://twitter.com/nirmalpatel">twitter</a>.
	</div>

	<div id="pageLinks">
		<a href="program.html">Conference Program</a>
		<a href="byAuthors.html">Sort By Author</a>
		<a href="byAffiliation.html">Sort By Affiliation</a>
	</div>

	<div id="searchArea">
		Filter by session title, papers, authors, abstracts, location... : 
		<input id="filter" type="text" value="" />
	</div>

	

	<!-- GENERATED Tue Mar 23 15:44:55 2010 -->
<div class="day" id="04/12/10">
<h1>Monday, April 12</h1>
<table cellspacing="0" class="program">
<tr class="timeslot">
<td class="time">9:00&nbsp;AM</td>
<td class="session" style="text-align: left" colspan="8" id="SOpeningPlenary">
<span class="type">Opening Plenary</span>
<span class="title">Messy Futures: Culture, technology and research</span>
<span class="author">Genevieve Bell, PhD</span>
Intel Fellow and Director, User Experience,
Digital Home Group, 
<span class="affiliation">INTEL</span>
</td>
</tr><tr class="timeslot">
<td class="time">11:30&nbsp;AM<br/><em>to</em><br/>1:00&nbsp;PM</td>
<td class="session" id="S38">
<span class="type">Papers/Notes</span>
<span class="title">Organizations and Communities</span>
<span class="location">Centennial 1</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S20">
<span class="type">Panel</span>
<span class="title">Addressing Challenges in Doing International Field Research</span>
<span class="location">Centennial 2</span>
</td>
<td class="session" id="S37">
<span class="type">Papers/Notes</span>
<span class="title">Multitasking</span>
<span class="location">Centennial 3</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S35">
<span class="type">Papers/Notes</span>
<span class="title">Exploratory Search</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S6">
<span class="type">SIG</span>
<span class="title">Current Issues in Assessing and Improving Information Usability</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S36">
<span class="type">Papers/Notes</span>
<span class="title">Making Meaning in Large Displays</span>
<span class="location">Hanover CDE</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S34">
<span class="type">Papers/Notes</span>
<span class="title">EPIC #FAIL</span>
<span class="location">Hanover FG</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S40">
<span class="type">Papers/Notes</span>
<span class="title">Social Support for Cancer Patients</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S39">
<span class="type">Papers/Notes</span>
<span class="title">Privacy Awareness and Attitudes</span>
<span class="location">Regency 6</span>
</td>
<td class="session" id="S41">
<span class="type">Papers/Notes</span>
<span class="title">Visualization</span>
<span class="location">Regency 7</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
</tr>
<tr class="details_row">

<td colspan="10" class="session_details" id="S38_details"><div class="paper"><span class="title">Across Boundaries of Influence and Accountability: The Multiple Scales of Public Sector Information Systems</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Christopher A. Le Dantec" class="author">Christopher A. Le Dantec</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#W. Keith S. Edwards" class="author">W. Keith S. Edwards</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The use of ICTs in the public sector has long been touted for its potential to transform the institutions that govern and pro- vide social services. The focus, however, has largely been on systems that are used within particular scales of the public sector, such as at the scale of state or national government, the scale of regional or municipal entity, or at the scale of local service providers. The work presented here takes aim at examining ICT use that crosses these scales of influence and accountability. We report on a year long ethnographic investigation conducted at a variety of social service outlets to understand how a shared information system crosses the boundaries of these very distinct organizations. We put for- ward that such systems are central to the work done in the public sector and represent a class of collaborative work that has gone understudied.</span></div></div><div class="paper"><span class="title">A Case Study of Micro-blogging in the Enterprise: Use, Value, and Related Issues</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jun Zhang" class="author">Jun Zhang</a> <a href="byAffiliation.html#Pitney Bowes" class="affiliation">Pitney Bowes</a>,<br /><a href="byAuthors.html#Yan Qu" class="author">Yan Qu</a> <a href="byAffiliation.html#University of Maryland " class="affiliation">University of Maryland </a>,<br /><a href="byAuthors.html#Jane Cody" class="author">Jane Cody</a> <a href="byAffiliation.html#Pitney Bowes" class="affiliation">Pitney Bowes</a>,<br /><a href="byAuthors.html#Yuling Wu" class="author">Yuling Wu</a> <a href="byAffiliation.html#Pitney Bowes" class="affiliation">Pitney Bowes</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This is a case study about the early adoption and use of micro-blogging in a Fortune 500 company.  The study used several independent data sources:  five months of empirical micro-blogging data, user demographic information from corporate HR records, a web based survey, and targeted interviews. The results revealed that users vary in their posting activities, reading behaviors, and perceived values. The analysis also identified barriers to adoption, such as the noise-to-value ratio paradoxes. The findings can help both practitioners and scholars build an initial understanding of how knowledge workers are likely to use micro-blogging in the enterprise. </span></div></div><div class="paper"><span class="title">Student Socialization in the Age of Facebook</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Louise Barkhuus" class="author">Louise Barkhuus</a> <a href="byAffiliation.html#University of California, San Diego" class="affiliation">University of California, San Diego</a>,<br /><a href="byAuthors.html#Juliana Tashiro" class="author">Juliana Tashiro</a> <a href="byAffiliation.html#University of California, San Diego" class="affiliation">University of California, San Diego</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Most research regarding online social networks such as Facebook, MySpace, Linked-In and Friendster has looked at these networks in terms of activity within the online network, such as profile management and friending behavior. In this paper we are instead focusing on offline socializing structures around an online social network (exemplified by Facebook) and how this can facilitate in-person social life for students. Because students lead nomadic lives, they find Facebook a particularly useful tool for initiating and managing social gatherings, and as they adopt mobile technologies that can access online social networks, their ad-hoc social life is further enabled. We conclude that online social networks are a powerful tool for encouraging peripheral friendships, important in particular to students. We emphasize that the use of online social networks must be viewed from a perspective of use that involves both mobile and stationary platforms and that it is important to relate online and offline social practices.</span></div></div></td>

<td colspan="10" class="session_details" id="S20_details"><div class="paper"><span class="title">Addressing Challenges in Doing International Field Research</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Elizabeth Churchill" class="author">Elizabeth Churchill</a> <a href="byAffiliation.html#Yahoo! Research" class="affiliation">Yahoo! Research</a>,<br /><a href="byAuthors.html#Susan Dray" class="author">Susan Dray</a> <a href="byAffiliation.html#Dray &amp; Associates, Inc." class="affiliation">Dray &amp; Associates, Inc.</a>,<br /><a href="byAuthors.html#Ame Elliott" class="author">Ame Elliott</a> <a href="byAffiliation.html#IDEO" class="affiliation">IDEO</a>,<br /><a href="byAuthors.html#Patrick Larvie" class="author">Patrick Larvie</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a>,<br /><a href="byAuthors.html#David Siegel" class="author">David Siegel</a> <a href="byAffiliation.html#Dray &amp; Associates, Inc." class="affiliation">Dray &amp; Associates, Inc.</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This panel will discuss some of the key challenges in doing international field research including issues with planning, conducting, interpreting, and reporting on such research.  Panelists will also share potential solutions and approaches they have used to try to deal with these challenges, and will discuss with the audience additional challenges that audience members have encountered, offering ideas on how to address these as appropriate.</span></div></div></td>

<td colspan="10" class="session_details" id="S37_details"><div class="paper"><span class="title">Multitasking and Monotasking: The Effects of Mental Workload on Deferred Task Interruptions</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Dario D. Salvucci" class="author">Dario D. Salvucci</a> <a href="byAffiliation.html#Drexel University" class="affiliation">Drexel University</a>,<br /><a href="byAuthors.html#Peter Bogunovich" class="author">Peter Bogunovich</a> <a href="byAffiliation.html#Drexel University" class="affiliation">Drexel University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Recent research has found that forced interruptions at points of higher mental workload are more disruptive than at points of lower workload. This paper investigates a complementary idea: when users experience deferrable interruptions at points of higher workload, they may tend to defer processing of the interruption until times of lower workload. In an experiment, users performed a mail-browser primary task while being occasionally interrupted by a secondary chat task, evenly distributed between points of higher and lower workload. Analysis showed that 94% of the time, users switched to the interrupting task during periods of lower workload, versus only 6% during periods of higher workload. The results suggest that when interruptions can be deferred, users have a strong tendency to monotask until primary-task mental workload has been minimized.</span></div></div><div class="paper"><span class="title">On Reconstruction of Task Context after Interruption</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Dario D. Salvucci" class="author">Dario D. Salvucci</a> <a href="byAffiliation.html#Drexel University" class="affiliation">Drexel University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Theoretical accounts of task resumption after interruption have almost exclusively argued for resumption as a primarily memory-based process. In contrast, for many task domains, resumption can more accurately be represented in terms of a process of reconstruction -- perceptual re-encoding of the information necessary to perform the task. This paper discusses a theoretical, computational framework in which one can represent these reconstruction processes and account for aspects of performance, such as measures of resumption lag. The paper also describes computational models of two sample task domains that illustrate the sometimes complex relationship between reconstruction and more general human cognitive, perceptual, and motor processes.</span></div></div><div class="paper"><span class="title">Evaluating Cues for Resuming Interrupted Programming Tasks</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Chris Parnin" class="author">Chris Parnin</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Robert DeLine" class="author">Robert DeLine</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Developers, like all modern knowledge workers, are frequently interrupted and blocked in their tasks. In this paper we present a contextual inquiry into developers' current strategies for resuming interrupted tasks and investigate the effect of automated cues on improving task resumption. We surveyed 371 programmers on the nature of their tasks, interruptions, task suspension and resumption strategies and found that they rely heavily on note-taking across several types of media. We then ran a controlled lab study to compare the effects of two different automated cues to note taking when resuming interrupted programming tasks. The two cues differed in (1) whether activities were summarized in aggregate or presented chronologically and (2) whether activities were presented as program symbols or as code snippets. Both cues performed well: developers using either cue completed their tasks with twice the success rate as those using note-taking alone. Despite the similar performance of the cues, developers strongly preferred the cue that presents activities chronologically as code snippets.</span></div></div><div class="paper"><span class="title">Multitasking Bar: Prototype and Evaluation of Introducing the Task Concept into a Browser</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Qing Wang" class="author">Qing Wang</a> <a href="byAffiliation.html#Sun Yat-Sen University" class="affiliation">Sun Yat-Sen University</a>,<br /><a href="byAuthors.html#Huiyou Chang" class="author">Huiyou Chang</a> <a href="byAffiliation.html#Sun Yat-Sen University" class="affiliation">Sun Yat-Sen University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper clarifies two common patterns of multitasking on the Web, namely Multiple Tasks (MT) and Multiple Session Task (MST). To support both of these, the task concept needs to be introduced into a browser. An online pilot survey has revealed which attributes of the task concept are most significant to Web users and as a result a simple prototype, the Multitasking Bar (MB), is proposed based on these findings. The MB copes with the multitasking needs of both MT and MST in the browser by providing functions for task related Web page management and task schedule management. A two-session controlled experiment has been conducted to evaluate the MB and to compare user performance and experience when multitasking on the Web with and without support for MT and MST. Results show that support for both MST and MT significantly improves user task performance efficiency and greatly enhances the user experience when multitasking on the Web.</span></div></div></td>

<td colspan="10" class="session_details" id="S35_details"><div class="paper"><span class="title">Reactive Information Foraging for Evolving Goals</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Joseph Lawrance" class="author">Joseph Lawrance</a> <a href="byAffiliation.html#Oregon State University  Massachusetts Institute of Technology" class="affiliation">Oregon State University  Massachusetts Institute of Technology</a>,<br /><a href="byAuthors.html#Margaret Burnett" class="author">Margaret Burnett</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Rachel Bellamy" class="author">Rachel Bellamy</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a>,<br /><a href="byAuthors.html#Christopher Bogart" class="author">Christopher Bogart</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Calvin Swart" class="author">Calvin Swart</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Information foraging models have predicted the navigation paths of people browsing the web and (more recently) of programmers while debugging, but these models do not explicitly model users' goals evolving over time. We present a new information foraging model called PFIS2 that does model information seeking with potentially evolving goals. We then evaluated variants of this model in a field study that analyzed programmers' daily navigations over a seven-month period. Our results were that PFIS2 predicted users' navigation remarkably well, even though the goals of navigation, and even the information landscape itself, were changing markedly during the pursuit of information.</span></div></div><div class="paper"><span class="title">How does search behavior change as  search becomes more difficult?</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Anne Aula" class="author">Anne Aula</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a>,<br /><a href="byAuthors.html#Rehan M. Khan" class="author">Rehan M. Khan</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a>,<br /><a href="byAuthors.html#Zhiwei Guan" class="author">Zhiwei Guan</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Search engines make it easy to check facts online, but finding some specific kinds of information sometimes proves to be difficult. We studied the behavioral signals that suggest that a user is having trouble in a search task. First, we ran a lab study with 23 users to gain a preliminary understanding on how users' behavior changes when they struggle finding the information they're looking for. The observations were then tested with 179 participants who all completed an average of 22.3 tasks from a pool of 100 tasks. The large-scale study provided quantitative support for our qualitative observations from the lab study. When having difficulty in finding information, users start to formulate more diverse queries, they use advanced operators more, and they spend a longer time on the search result page as compared to the successful tasks. The results complement the existing body of research focusing on successful search strategies.</span></div></div><div class="paper"><span class="title">Effects of Popularity and Quality on the Usage of Query Suggestions during Information Search</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Diane Kelly" class="author">Diane Kelly</a> <a href="byAffiliation.html#University of North Carolina" class="affiliation">University of North Carolina</a>,<br /><a href="byAuthors.html#Amber Cushing" class="author">Amber Cushing</a> <a href="byAffiliation.html#University of North Carolina" class="affiliation">University of North Carolina</a>,<br /><a href="byAuthors.html#Maureen Dostert" class="author">Maureen Dostert</a> <a href="byAffiliation.html#University of North Carolina" class="affiliation">University of North Carolina</a>,<br /><a href="byAuthors.html#Xi Niu" class="author">Xi Niu</a> <a href="byAffiliation.html#University of North Carolina" class="affiliation">University of North Carolina</a>,<br /><a href="byAuthors.html#Karl Gyllstrom" class="author">Karl Gyllstrom</a> <a href="byAffiliation.html#University of North Carolina" class="affiliation">University of North Carolina</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Many search systems provide users with recommended queries during online information seeking.  Although usage statistics are often used to recommend queries, this information is usually not displayed to the user.  In this study, we investigate how the presentation of this information impacts use of query suggestions.  Twenty-three subjects used an experimental search system to find documents about four topics.  Eight query suggestions were provided for each topic: four were high quality queries and four were low quality queries. Fake usage information indicating how many other people used the queries was also provided.  For half the queries this information was high and for the other half this information was low. Results showed that subjects could distinguish between high and low quality queries and were not influenced by the usage information. Qualitative data revealed that subjects felt favorable about the suggestions, but the usage information was less important for the search task used in this study.</span></div></div></td>

<td colspan="10" class="session_details" id="S6_details"><div class="paper"><span class="title">Current Issues in Assessing and Improving Information Usability</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Stephanie Rosenbaum" class="author">Stephanie Rosenbaum</a> <a href="byAffiliation.html#Tec-Ed, Inc." class="affiliation">Tec-Ed, Inc.</a>,<br /><a href="byAuthors.html#Judith Ramey" class="author">Judith Ramey</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Janice Redish" class="author">Janice Redish</a> <a href="byAffiliation.html#Redish &amp; Associates, Inc." class="affiliation">Redish &amp; Associates, Inc.</a></div></div></td>

<td colspan="10" class="session_details" id="S36_details"><div class="paper"><span class="title">Space to Think: Large, High-Resolution Displays for Sensemaking</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Christopher Andrews" class="author">Christopher Andrews</a> <a href="byAffiliation.html#Virginia Polytechnic Institute and State University" class="affiliation">Virginia Polytechnic Institute and State University</a>,<br /><a href="byAuthors.html#Alex Endert" class="author">Alex Endert</a> <a href="byAffiliation.html#Virginia Polytechnic Institute and State University" class="affiliation">Virginia Polytechnic Institute and State University</a>,<br /><a href="byAuthors.html#Chris North" class="author">Chris North</a> <a href="byAffiliation.html#Virginia Polytechnic Institute and State University" class="affiliation">Virginia Polytechnic Institute and State University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Space supports human cognitive abilities in a myriad of ways. The note attached to the side of the monitor, the papers spread out on the desk, diagrams scrawled on a whiteboard, and even the keys left out on the counter are all examples of using space to recall, reveal relationships, and think. Technological advances have made it possible to construct large display environments in which space has real meaning. This paper examines how increased space affects the way displays are regarded and used within the context of the cognitively demanding task of sensemaking. A pair of studies were conducted demonstrating how the spatial environment supports sensemaking by becoming part of the distributed cognitive process, providing both external memory and a semantic layer.</span></div></div><div class="paper"><span class="title">Effects of Interior Bezels of Tiled-Monitor Large Displays on Visual Search, Tunnel Steering, and Target Selection</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Xiaojun Bi" class="author">Xiaojun Bi</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a>,<br /><a href="byAuthors.html#Seok-Hyung Bae" class="author">Seok-Hyung Bae</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a>,<br /><a href="byAuthors.html#Ravin Balakrishnan" class="author">Ravin Balakrishnan</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Tiled-monitor large displays are widely used in various application domains. However, how their interior bezels affect user performance and behavior has not been fully understood. We conducted three controlled experiments to investigate effects of tiled-monitor interior bezels on visual search, straight-tunnel steering, and target selection tasks. The conclusions of our paper are: 1) interior bezels do not affect visual search time nor error rate; however, splitting objects across bezels is detrimental to search accuracy, 2) interior bezels are detrimental to straight-tunnel steering, but not to target selection. In addition, we discuss how interior bezels affect user behaviors, and suggest guidelines for effectively using tiled-monitor large displays and designing user interfaces suited to them.</span></div></div><div class="paper"><span class="title">Let's go from the whiteboard: Supporting transitions in work through whiteboard capture and reuse</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Stacy Branham" class="author">Stacy Branham</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a>,<br /><a href="byAuthors.html#Gene Golovchinsky" class="author">Gene Golovchinsky</a> <a href="byAffiliation.html#FX Palo Alto Laboratory, Inc." class="affiliation">FX Palo Alto Laboratory, Inc.</a>,<br /><a href="byAuthors.html#Scott Carter" class="author">Scott Carter</a> <a href="byAffiliation.html#FX Palo Alto Laboratory, Inc." class="affiliation">FX Palo Alto Laboratory, Inc.</a>,<br /><a href="byAuthors.html#Jacob Biehl" class="author">Jacob Biehl</a> <a href="byAffiliation.html#FX Palo Alto Laboratory, Inc." class="affiliation">FX Palo Alto Laboratory, Inc.</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The use of whiteboards is pervasive across a wide range of  work domains. But some of the qualities that make them  successfulan intuitive interface, physical working space,  and easy erasureinherently make them poor tools for  archival and reuse. If whiteboard content could be made  available in times and spaces beyond those supported by  the whiteboard alone, how might it be appropriated? We  explore this question via ReBoard, a system that  automatically captures whiteboard images and makes them  accessible through a novel set of user-centered access tools.  Through the lens of a seven week workplace field study,  we found that by enabling new workflows, ReBoard  increased the value of whiteboard content for collaboration.</span></div></div></td>

<td colspan="10" class="session_details" id="S34_details"><div class="paper"><span class="title">Estimating Residual Error Rate in Recognized Handwritten Documents Using Artificial Error Injection</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Edward Lank" class="author">Edward Lank</a> <a href="byAffiliation.html#University of Waterloo" class="affiliation">University of Waterloo</a>,<br /><a href="byAuthors.html#Ryan Stedman" class="author">Ryan Stedman</a> <a href="byAffiliation.html#University of Waterloo" class="affiliation">University of Waterloo</a>,<br /><a href="byAuthors.html#Michael Terry" class="author">Michael Terry</a> <a href="byAffiliation.html#University of Waterloo" class="affiliation">University of Waterloo</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Both handwriting recognition systems and their users are error prone. Handwriting recognizers make recognition errors, and users may miss those errors when verifying output. As a result, it is common for recognized documents to contain residual errors. Unfortunately, in some application domains (e.g. health informatics), tolerance for residual errors in recognized handwriting may be very low, and a desire might exist to maximize user accuracy during verification. In this paper, we present a technique that allows us to measure the performance of a user verifying recognizer output. We inject artificial errors into a set of recognized handwritten forms and show that the rate of injected errors and recognition errors caught is highly correlated in real time. Systems supporting user verification can make use of this measure of user accuracy in a variety of ways. For example, they can force users to slow down or can highlight injected errors that were missed, thus encouraging users to take more care. </span></div></div><div class="paper"><span class="title">Predicting the Cost of Error Correction in Character-Based Text Entry Technologies</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ahmed S. Arif" class="author">Ahmed S. Arif</a> <a href="byAffiliation.html#York University" class="affiliation">York University</a>,<br /><a href="byAuthors.html#Wolfgang Stuerzlinger" class="author">Wolfgang Stuerzlinger</a> <a href="byAffiliation.html#York University" class="affiliation">York University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Researchers have developed many models to predict and understand human performance in text entry. Most of the models are specific to a technology or fail to account for human factors and variations in system parameters, and the relationship between them. Moreover, the process of fixing errors and its effects on text entry performance has not been studied. Here, we first analyze real-life text entry error correction behaviors. We then use our findings to develop a new model to predict the cost of error correction for character-based text entry technologies. We validate our model against quantities derived from the literature, as well as with a user study. Our study shows that the predicted and observed cost of error correction correspond well. At the end, we discuss potential applications of our new model.</span></div></div><div class="paper"><span class="title">SHRIMP - Solving Collision and Out of Vocabulary Problems in Mobile Predictive Input with Motion Gesture</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Jingtao Wang" class="author">Jingtao Wang</a> <a href="byAffiliation.html#University of California at Berkeley" class="affiliation">University of California at Berkeley</a>,<br /><a href="byAuthors.html#Shumin Zhai" class="author">Shumin Zhai</a> <a href="byAffiliation.html#IBM Almaden Research Center" class="affiliation">IBM Almaden Research Center</a>,<br /><a href="byAuthors.html#John Canny" class="author">John Canny</a> <a href="byAffiliation.html#University of California at Berkeley" class="affiliation">University of California at Berkeley</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Dictionary-based disambiguation (DBD) is a very popular solution for text entry on mobile phone keypads but suffers from two problems: 1. the resolution of encoding collision (two or more words sharing the same numeric key sequence) and 2. entering out-of-vocabulary (OOV) words. In this paper, we present SHRIMP, a system and method that addresses these two problems by integrating DBD with camera based motion sensing that enables the user to express preference through a tilting or movement gesture. SHRIMP (Small Handheld Rapid Input with Motion and Prediction) runs on camera phones equipped with a standard 12-key keypad. SHRIMP maintains the speed advantage of DBD driven predictive text input while enabling the user to overcome DBD collision and OOV problems seamlessly without even a mode switch. An initial empirical study demonstrates that SHRIMP can be learned very quickly, performed immediately faster than MultiTap and handled OOV words more efficiently than DBD. </span></div></div></td>

<td colspan="10" class="session_details" id="S40_details"><div class="paper"><span class="title">Catalyzing Social Support for Breast Cancer Patients</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Meredith M. Skeels" class="author">Meredith M. Skeels</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Kenton T. Unruh" class="author">Kenton T. Unruh</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Christopher Powell" class="author">Christopher Powell</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Wanda Pratt" class="author">Wanda Pratt</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Social support is a critical, yet underutilized resource when undergoing cancer care. Underutilization occurs in two conditions: (a) when patients fail to seek out information, material assistance, and emotional support from family and friends or (b) when family and friends fail to meet the individualized needs and preferences of patients. Social networks are most effective when kept up to date on the patient's status, yet updating everyone takes effort that patients cannot always put in. To improve this situation, we describe the results of our participatory design activities with breast cancer patients. During this process, we uncovered the information a social network needs to stay informed as well as a host of barriers to social support that technology could help break down. Our resulting prototype, built using Facebook Connect, includes explicit features to reduce these barriers and thus, promote the healthy outcomes associated with strong social support.</span></div></div><div class="paper"><span class="title">Transforming Clinic Environments into Information Workspaces for Patients</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kenton T. Unruh" class="author">Kenton T. Unruh</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Meredith M. Skeels" class="author">Meredith M. Skeels</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Andrea Civan-Hartzler" class="author">Andrea Civan-Hartzler</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Wanda Pratt" class="author">Wanda Pratt</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Although clinic environments are a primary location for exchanging information with clinicians, patients experience these spaces as harsh environments to access, use, exchange, and manage information. In this paper, we present results from an ethnographic-inspired study of breast cancer patients actively interacting with information in clinic environments. Through observations and interviews, we observed information interactions in awkward physical positions; inefficient use of existing clinical space; separation of patients from their information and lack of support for collaborative document viewing. These factors compromised patients' abilities to manage their information work when they experienced bursts of information exchange, lack of advance information, fragmented attention, and heightened stress in clinic environments. To overcome these challenges, we identify formative strategies to focus attention, encourage collaboration, and improve communication in clinical settings. </span></div></div><div class="paper"><span class="title">Blowing in the Wind: Unanchored Patient Information Work during Cancer Care</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Predrag Klasnja" class="author">Predrag Klasnja</a> <a href="byAffiliation.html#University of Washington  Intel" class="affiliation">University of Washington  Intel</a>,<br /><a href="byAuthors.html#Andrea Civan Hartzler" class="author">Andrea Civan Hartzler</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Kent T. Unruh" class="author">Kent T. Unruh</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Wanda Pratt" class="author">Wanda Pratt</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Patients do considerable information work. Technologies that help patients manage health information so they can play active roles in their health-care, such as personal health records, provide patients with effective support for focused and sustained personal health tasks. Yet, little attention has been paid to patients' needs for information management support while on the go and away from their personal health information collections. Through a qualitative field study, we investigated the information work that breast cancer patients do in such unanchored settings'. We report on the types of unanchored information work that patients do over the course of cancer treatment, reasons this work is challenging, and strategies used by patients to overcome those challenges. Our description of unanchored patient information work expands our understanding of patients' information practices and points to valuable design directions for supporting critical but unmet needs.</span></div></div></td>

<td colspan="10" class="session_details" id="S39_details"><div class="paper"><span class="title">Independence and Interaction: Understanding Seniors'  Privacy and Awareness Needs For Aging in Place</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jeremy Birnholtz" class="author">Jeremy Birnholtz</a> <a href="byAffiliation.html#Cornell University, University of Toronto" class="affiliation">Cornell University, University of Toronto</a>,<br /><a href="byAuthors.html#McKenzie Jones-Rounds" class="author">McKenzie Jones-Rounds</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">As America's baby boom population gets older, aging in place  the idea that seniors can remain independent in a comfortable home environment while being monitored and receiving care from family and caregivers living elsewhere  has received significant attention. Fostering a sense of independence while simultaneously enabling monitoring and frequent interaction can seem paradoxical, however. This raises questions of how we can design technologies that help seniors retain their independence and a sense of comfort, while still interacting with and being monitored regularly by others.  We present results from an interview study of 30 seniors, caregivers and relatives in which we sought to understand how they managed their interactions, availability, privacy and independence. Results suggest that they rely on attributes of the physical environment, temporal structures such as routine conversations and activities, and technological mediation.</span></div></div><div class="paper"><span class="title">ContraVision: Exploring Users' Reactions to FuturisticTechnology</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Clara Mancini" class="author">Clara Mancini</a> <a href="byAffiliation.html#Dept of Computing, The Open University" class="affiliation">Dept of Computing, The Open University</a>,<br /><a href="byAuthors.html#Yvonne Rogers" class="author">Yvonne Rogers</a> <a href="byAffiliation.html#Dept of Computing, The Open University" class="affiliation">Dept of Computing, The Open University</a>,<br /><a href="byAuthors.html#Arosha K. Bandara" class="author">Arosha K. Bandara</a> <a href="byAffiliation.html#Dept of Computing, The Open University" class="affiliation">Dept of Computing, The Open University</a>,<br /><a href="byAuthors.html#Tony Coe" class="author">Tony Coe</a> <a href="byAffiliation.html#Two Cats Can" class="affiliation">Two Cats Can</a>,<br /><a href="byAuthors.html#Lukasz Jedrzejczyk" class="author">Lukasz Jedrzejczyk</a> <a href="byAffiliation.html#Dept of Computing, The Open University" class="affiliation">Dept of Computing, The Open University</a>,<br /><a href="byAuthors.html#Adam N. Joinson" class="author">Adam N. Joinson</a> <a href="byAffiliation.html#School of Management, University of Bath" class="affiliation">School of Management, University of Bath</a>,<br /><a href="byAuthors.html#Blaine A. Price" class="author">Blaine A. Price</a> <a href="byAffiliation.html#Dept of Computing, The Open University" class="affiliation">Dept of Computing, The Open University</a>,<br /><a href="byAuthors.html#Keerthi Thomas" class="author">Keerthi Thomas</a> <a href="byAffiliation.html#Dept of Computing, The Open " class="affiliation">Dept of Computing, The Open </a>,<br /><a href="byAuthors.html#Bashar Nuseibeh" class="author">Bashar Nuseibeh</a> <a href="byAffiliation.html#Dept of Computing, The Open University &amp; Lero, University of Limerick" class="affiliation">Dept of Computing, The Open University &amp; Lero, University of Limerick</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">How can we best explore the range of users' reactions when developing future technologies that maybe controversial, such as personal healthcare systems? Our approach -Contravision - uses futuristic videos, or other narrative forms, that convey either negative or positive aspects of the proposed technology for the same scenarios. We conducted a users study to investigate what range of responses the different versions elicited. Our findings show that the use of two systematically comparable representations of the same technology can elicit a wider spectrum of reactions than a single representation can. We discuss why this is so and the value of obtaining breadth in user feedback for potentially controversial technologies.</span></div></div><div class="paper"><span class="title">I Don't Mind Being Logged, but Want to Remain in Control: A Field Study of Mobile Activity and Context Logging</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Tuula Kärkkäinen" class="author">Tuula Kärkkäinen</a> <a href="byAffiliation.html#Tampere University of Technology, Unit of Human-Centered Technology" class="affiliation">Tampere University of Technology, Unit of Human-Centered Technology</a>,<br /><a href="byAuthors.html#Tuomas Vaittinen" class="author">Tuomas Vaittinen</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Kaisa Väänänen-Vainio-Mattila" class="author">Kaisa Väänänen-Vainio-Mattila</a> <a href="byAffiliation.html#Tampere University of Technology, Unit of Human-Centered Technology,  Nokia Research Center" class="affiliation">Tampere University of Technology, Unit of Human-Centered Technology,  Nokia Research Center</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">People have a natural tendency to capture and share their experiences via stories, photos and other mementos. As users are increasingly carrying the enabling devices with them, capturing life events is becoming more spontaneous. The automatic and persistent collecting of information about one's life and behavior is called lifelogging. Lifelogging relieves the user from manually capturing events but also poses many challenges from the user's perspective. We conducted a field study to explore the user experience of mobile phone activity and context logging, a technically feasible form of lifelogging. Our results indicate that users quickly stop to pay attention to the logging, but they want to be in control of logging the most private information. Although logging personal content, such as text messages, is experienced as a possible privacy threat, browsing the content and getting insight to the revealed life patterns was considered interesting and fun.</span></div></div></td>

<td colspan="10" class="session_details" id="S41_details"><div class="paper"><span class="title">Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Jeffrey Heer" class="author">Jeffrey Heer</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Michael Bostock" class="author">Michael Bostock</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Understanding perception is critical to effective visualization design. With its low cost and scalability, crowdsourcing presents an attractive option for evaluating the large design space of visualizations; however, it first requires validation. In this paper, we assess the viability of Amazon's Mechanical Turk as a platform for graphical perception experiments. We replicate previous studies of spatial encoding and luminance contrast and compare our results. We also conduct new experiments on rectangular area perception (as in treemaps or cartograms) and on chart size and gridline spacing. Our results demonstrate that crowdsourced perception experiments are viable and contribute new insights for visualization design. Lastly, we report cost and performance data from our experiments and distill recommendations for the design of crowdsourced studies.</span></div></div><div class="paper"><span class="title">ManyNets: An Interface for Multiple Network Analysis and  Visualization</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Manuel Freire Morán" class="author">Manuel Freire Morán</a> <a href="byAffiliation.html#Universidad Autónoma de Madrid" class="affiliation">Universidad Autónoma de Madrid</a>,<br /><a href="byAuthors.html#Catherine Plaisant" class="author">Catherine Plaisant</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Ben Shneiderman" class="author">Ben Shneiderman</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Jen Golbeck" class="author">Jen Golbeck</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Traditional network analysis tools support analysts in studying a single network. ManyNets offers these analysts a powerful new approach that enables them to work on multiple networks simultaneously. Several thousand networks can be presented as rows in a tabular visualization, and then inspected, sorted and filtered according to their attributes. The networks to be displayed can be obtained by subdivision of larger networks. Examples of meaningful subdivisions used by analysts include ego networks, community extraction, and time-based slices. Cell visualizations and interactive column overviews allow analysts to assess the distribution of attributes within particular sets of networks. Details, such as traditional node-link diagrams, are available on demand. We describe a case study analyzing a social network geared towards film recommendations by means of decomposition. A small usability study provides feedback on the use of the interface on a set of tasks issued from the case study.</span></div></div><div class="paper"><span class="title">A Comparative Evaluation on Tree Visualization Methods for Hierarchical Structures with Large Fan-outs</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Hyunjoo Song" class="author">Hyunjoo Song</a> <a href="byAffiliation.html#Seoul National University" class="affiliation">Seoul National University</a>,<br /><a href="byAuthors.html#Bohyung Kim" class="author">Bohyung Kim</a> <a href="byAffiliation.html#Seoul National University" class="affiliation">Seoul National University</a>,<br /><a href="byAuthors.html#Bongshin Lee" class="author">Bongshin Lee</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Jinwook Seo" class="author">Jinwook Seo</a> <a href="byAffiliation.html#Seoul National University" class="affiliation">Seoul National University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Hierarchical structures with large fan-outs are hard to browse and understand. In the conventional node-link tree visualization, the screen quickly becomes overcrowded as users open nodes that have too many child nodes to fit in one screen. To address this problem, we propose two extensions to the conventional node-link tree visualization: a list view with a scrollbar and a multi-column interface. We compared them against the conventional tree visualization interface in a user study. Results show that users are able to browse and understand the tree structure faster with the multi-column interface than the other two interfaces. Overall, they also liked the multi-column better than others.</span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">2:30&nbsp;PM<br/><em>to</em><br/>4:00&nbsp;PM</td>
<td class="session" id="S43">
<span class="type">Papers/Notes</span>
<span class="title">Games and Players</span>
<span class="location">Centennial 1</span>
</td>
<td class="session" id="S50">
<span class="type">Paper + Panel</span>
<span class="title">The Infrastructure Problem in HCI</span>
<span class="location">Centennial 2</span>
</td>
<td class="session" id="S45">
<span class="type">Papers/Notes</span>
<span class="title">Language 2.0</span>
<span class="location">Centennial 3</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S47">
<span class="type">Papers/Notes</span>
<span class="title">Mobile Device Interaction</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S7">
<span class="type">SIG</span>
<span class="title">Understanding 'Cool'</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S46">
<span class="type">Papers/Notes</span>
<span class="title">Market Models for Q&amp;A Services</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S42">
<span class="type">Papers/Notes</span>
<span class="title">Call Centers</span>
<span class="location">Hanover FG</span>
</td>
<td class="session" id="S49">
<span class="type">Papers/Notes</span>
<span class="title">The Age of Searching</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S48">
<span class="type">Papers/Notes</span>
<span class="title">Privacy Behaviors</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S44">
<span class="type">Papers/Notes</span>
<span class="title">Interfaces and Visualization</span>
<span class="location">Regency 7</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
</tr>
<tr class="details_row">

<td colspan="10" class="session_details" id="S43_details"><div class="paper"><span class="title">The Rogue in the Lovely Black Dress: Intimacy in World of Warcraft</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Tyler Pace" class="author">Tyler Pace</a> <a href="byAffiliation.html#Indiana University" class="affiliation">Indiana University</a>,<br /><a href="byAuthors.html#Shaowen Bardzell" class="author">Shaowen Bardzell</a> <a href="byAffiliation.html#Indiana University" class="affiliation">Indiana University</a>,<br /><a href="byAuthors.html#Jeffrey Bardzell" class="author">Jeffrey Bardzell</a> <a href="byAffiliation.html#Indiana University" class="affiliation">Indiana University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we present a critical analysis of player accounts of intimacy and intimate experiences in the massively multiplayer online role-playing game World of Warcraft (WoW). Our analysis explores four characteristics that players articulated about their virtual intimate experiences: the permeability of intimacy across virtual and real worlds, the mundane as the origin of intimacy, the significance of reciprocity and exchange, and the formative role of temporality in shaping understandings and recollections of intimate experiences. We also consider the manifest ways that WoW's software features support and encourage these characteristics.</span></div></div><div class="paper"><span class="title">Physical Activity Motivating Games: Virtual Rewards for Real Activity</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Shlomo Berkovsky" class="author">Shlomo Berkovsky</a> <a href="byAffiliation.html#CSIRO" class="affiliation">CSIRO</a>,<br /><a href="byAuthors.html#Mac Coombe" class="author">Mac Coombe</a> <a href="byAffiliation.html#CSIRO" class="affiliation">CSIRO</a>,<br /><a href="byAuthors.html#Jill Freyne" class="author">Jill Freyne</a> <a href="byAffiliation.html#CSIRO" class="affiliation">CSIRO</a>,<br /><a href="byAuthors.html#Dipak Bhandari" class="author">Dipak Bhandari</a> <a href="byAffiliation.html#CSIRO" class="affiliation">CSIRO</a>,<br /><a href="byAuthors.html#Nilufar Baghaei" class="author">Nilufar Baghaei</a> <a href="byAffiliation.html#CSIRO" class="affiliation">CSIRO</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Contemporary lifestyle has become increasingly sedentary: little physical (sports, exercises) and much sedentary (TV, computers) activity. The nature of sedentary activity is self-reinforcing, such that increasing physical and decreasing sedentary activity is difficult. We present a novel approach aimed at combating this problem in the context of computer games. Rather than explicitly changing the amount of physical and sedentary activity a person sets out to perform, we propose a new game design that leverages user engagement to generate out of game motivation to perform physical activity while playing. In our design, players gain virtual game rewards in return for real physical activity performed. Here we present and evaluate an application of our design to the game Neverball. We adapted Neverball by reducing the time allocated to accomplish the game tasks and motivated players to perform physical activity by offering time based rewards. An empirical evaluation involving 180 participants shows that the participants performed more physical activity, decreased the amount of sedentary playing time, and did not report a decrease in perceived enjoyment of playing the activity motivating version of Neverball. </span></div></div><div class="paper"><span class="title">Understanding and Evaluating Cooperative Games</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Magy Seif El-Nasr" class="author">Magy Seif El-Nasr</a> <a href="byAffiliation.html#Simon Fraser University" class="affiliation">Simon Fraser University</a>,<br /><a href="byAuthors.html#Bardia Aghabeigi" class="author">Bardia Aghabeigi</a> <a href="byAffiliation.html#Simon Fraser University" class="affiliation">Simon Fraser University</a>,<br /><a href="byAuthors.html#Mona Erfani" class="author">Mona Erfani</a> <a href="byAffiliation.html#Simon Fraser University" class="affiliation">Simon Fraser University</a>,<br /><a href="byAuthors.html#David Milam" class="author">David Milam</a> <a href="byAffiliation.html#Simon Fraser University" class="affiliation">Simon Fraser University</a>,<br /><a href="byAuthors.html#Beth Lameman" class="author">Beth Lameman</a> <a href="byAffiliation.html#Simon Fraser University" class="affiliation">Simon Fraser University</a>,<br /><a href="byAuthors.html#Hamid Maygoli" class="author">Hamid Maygoli</a> <a href="byAffiliation.html#New Media Research and Education" class="affiliation">New Media Research and Education</a>,<br /><a href="byAuthors.html#Sang Mah" class="author">Sang Mah</a> <a href="byAffiliation.html#Bardel Entertainment" class="affiliation">Bardel Entertainment</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Cooperative design has been an integral part of many games. With the success of games like Left4Dead, many game designers and producers are currently exploring the addition of cooperative patterns within their games. Unfortunately, very little research investigated cooperative patterns or methods to evaluate them. In this paper, we present a set of cooperative patterns identified based on analysis of fourteen cooperative games. Additionally, we propose Cooperative Performance Metrics (CPM). To evaluate the use of these CPMs, we ran a study with a total of 60 participants, grouped in 2-3 participants per session. Participants were asked to play four cooperative games (Rock Band 2, Lego Star Wars, Kameo, and Little Big Planet). Videos of the play sessions were annotated using the CPMs, which were then mapped to cooperative patterns that caused them. Results, validated through inter-rater agreement, identify several effective cooperative patterns and lessons for future cooperative game designs.  </span></div></div></td>

<td colspan="10" class="session_details" id="S50_details"><div class="paper"><span class="title">The Infrastructure Problem in HCI</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Keith Edwards" class="author">Keith Edwards</a> <a href="byAffiliation.html#Georgia Tech" class="affiliation">Georgia Tech</a>,<br /><a href="byAuthors.html#Mark W. Newman" class="author">Mark W. Newman</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Erika S. Poole" class="author">Erika S. Poole</a> <a href="byAffiliation.html#Georgia Tech" class="affiliation">Georgia Tech</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">HCI endeavors to create human-centered computer systems, but underlying technological infrastructures often stymie these efforts. We outline three specific classes of user experience difficulties caused by underlying technical infrastructures, which we term constrained possibilities, unmediated interaction, and interjected abstractions. We explore how prior approaches in HCI have addressed these issues, and discuss new approaches that will be required for future progress. We argue that the HCI community must become more deeply involved with the creation of technical infrastructures. Doing so, however, requires a substantial expansion to the methodological toolbox of HCI.</span></div></div></td>

<td colspan="10" class="session_details" id="S45_details"><div class="paper"><span class="title">An Unobtrusive Behavioral Model of Gross National Happiness</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Adam D. I. Kramer" class="author">Adam D. I. Kramer</a> <a href="byAffiliation.html#University of Oregon" class="affiliation">University of Oregon</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">I analyze the use of emotion words for approximately 100 million Facebook users since September of 2007. Gross national happiness is operationalized as a standardized difference between the use of positive and negative words, aggregated across days, and present a graph of this metric. I begin to validate this metric by showing that positive and negative word use in status updates covaries with self-reported satisfaction with life (convergent validity), and also note that the graph shows peaks and valleys on days that are culturally and emotionally significant (face validity). I discuss the development and computation of this metric, argue that this metric and graph serves as a representation of the overall emotional health of the nation, and discuss the importance of tracking such metrics.</span></div></div><div class="paper"><span class="title">The Tower of Babel Meets Web 2.0: User-Generated Content and its Applications in a Multilingual Context</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Brent Hecht" class="author">Brent Hecht</a> <a href="byAffiliation.html#Northwestern University" class="affiliation">Northwestern University</a>,<br /><a href="byAuthors.html#Darren Gergle" class="author">Darren Gergle</a> <a href="byAffiliation.html#Northwestern University" class="affiliation">Northwestern University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This study explores language's fragmenting effect on user-generated content by examining the diversity of knowledge representations across 25 different Wikipedia language editions. This diversity is measured at two levels: the concepts that are included in each edition and the ways in which these concepts are described. We demonstrate that the diversity present is greater than has been presumed in the literature and has a significant influence on applications that use Wikipedia as a source of world knowledge. We close by explicating how knowledge diversity can be beneficially leveraged to create culturally-aware applications and hyperlingual applications.</span></div></div><div class="paper"><span class="title">Indexicality of Language and the Art of Creating Treasures</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Matti Rantanen" class="author">Matti Rantanen</a> <a href="byAffiliation.html#Systems Analysis Laboratory, Aalto University" class="affiliation">Systems Analysis Laboratory, Aalto University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The indexicality of language refers to the linkage between the language and the situation of use for determining the meaning of what is being said. In this paper I describe how a player of a location-based treasure hunt game called geocaching uses indexicality of language in creating clues when hiding treasures. Based on this account, the skill, I argue, in creating an exciting treasure depends on understanding the disjunction between the context in which the clue is first interpreted and the context in which it receives its final meaning. An interesting clue should therefore contain both a literal or conventional meaning and a situated meaning, and the situated meaning should only arise when the player is close enough to the treasure.</span></div></div><div class="paper"><span class="title">Visualizing Language Use in Team Conversations: Designing Through Theory, Experiments, and Iterations</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Gilly Leshed" class="author">Gilly Leshed</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Dan Cosley" class="author">Dan Cosley</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Jeffrey T. Hancock" class="author">Jeffrey T. Hancock</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Geri Gay" class="author">Geri Gay</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">One way to potentially help people develop effective teamwork skills is to visualize elements of their language use during team conversations. There are several challenges in designing such visualizations, such as how to balance attention between the conversation and the visualization and how much guidance to offer about appropriate behaviors. We discuss the design space around these questions in the context of GroupMeter, a chatroom augmented with visualizations of language use. We generate and critique potential answers to these questions using prior theoretical and empirical work, then describe how the interface evolved and how our answers changed over a series of prototypes we deployed in experimental studies. We conclude with the lessons from our experience that could be used by designers of collaboration-enhancing systems.</span></div></div></td>

<td colspan="10" class="session_details" id="S47_details"><div class="paper"><span class="title">CrossTrainer: Testing the Use of Multimodal Interfaces in Situ</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Eve Hoggan" class="author">Eve Hoggan</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Stephen Brewster" class="author">Stephen Brewster</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We report the results of an exploratory 8-day field study of CrossTrainer: a mobile game with crossmodal audio and tactile feedback. Our research focuses on the longitudinal effects on performance with audio and tactile feedback, the impact of context such as location and situation on per-formance and personal modality preference. The results of this study indicate that crossmodal feedback can aid users in entering answers quickly and accurately using a variety of different widgets. Our study shows that there are times when audio is more appropriate than tactile and vice versa and for this reason devices should support both tactile and audio feedback to cover the widest range of environments, user preference, locations and tasks.</span></div></div><div class="paper"><span class="title">Newport: Enabling Sharing During Mobile Calls</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Junius Gunaratne" class="author">Junius Gunaratne</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#A.J. Brush" class="author">A.J. Brush</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Newport is a collaborative application for sharing context (e.g. location) and content (e.g. photos and notes) during mobile phone calls. People can share during a phone call and sharing ends when the call ends. Newport also supports using a computer during a call to make it easier to share content from the phone or launch screen sharing if the caller is also at a computer. We describe Newport's system design and a formative evaluation with 12 participants to study their experience using Newport to share location, receive directions, share photos, and perform desktop sharing. Participants preferred using Newport to current methods for these tasks. They also preferred limiting sharing location to phone calls compared with publishing it continuously. Tying sharing to a phone call gives individuals a social sense of security, providing a mechanism for exchanging information with unknown people.</span></div></div><div class="paper"><span class="title">Attractive Phones Don't Have To Work Better: Independent Effects of Attractiveness, Effectiveness, and Efficiency on Perceived Usability</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Jeffrey M. Quinn" class="author">Jeffrey M. Quinn</a> <a href="byAffiliation.html#Sprint Nextel" class="affiliation">Sprint Nextel</a>,<br /><a href="byAuthors.html#Tuan Q. Tran" class="author">Tuan Q. Tran</a> <a href="byAffiliation.html#Sprint Nextel" class="affiliation">Sprint Nextel</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Participants sometimes rate products high in usability despite experiencing obvious usability problems (low effectiveness or efficiency). Is it possible that this occurs because high product attractiveness compensates for low effectiveness/efficiency? Previous research has not investigated the interplay between attractiveness, effectiveness, and efficiency to determine whether attractiveness accounts for additional variance in usability ratings beyond that which is explained by effectiveness and efficiency. The present research provides the first test of this idea. Using data from usability testing, we demonstrate that attractiveness, effectiveness, and efficiency each has an independent influence on usability ratings and, in the present research, attractiveness had the largest impact. We report results of quantitative analyses that suggest multiple mechanisms could be responsible for the relationship between attractiveness and usability.</span></div></div></td>

<td colspan="10" class="session_details" id="S7_details"><div class="paper"><span class="title">Understanding 'Cool'</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Karen Holtzblatt" class="author">Karen Holtzblatt</a> <a href="byAffiliation.html#InContext Design" class="affiliation">InContext Design</a>,<br /><a href="byAuthors.html#David Rondeau" class="author">David Rondeau</a> <a href="byAffiliation.html#InContext Design" class="affiliation">InContext Design</a>,<br /><a href="byAuthors.html#Les Holtzblatt" class="author">Les Holtzblatt</a> <a href="byAffiliation.html#The MITRE Corporation" class="affiliation">The MITRE Corporation</a></div></div></td>

<td colspan="10" class="session_details" id="S46_details"><div class="paper"><span class="title">Why Pay?: Exploring How Financial Incentives are Used for Question &amp; Answer</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Gary Hsieh" class="author">Gary Hsieh</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Robert Kraut" class="author">Robert Kraut</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Scott Hudson" class="author">Scott Hudson</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Electronic commerce has enabled a number of online pay-for-answer services. However, despite commercial interest, we still lack a comprehensive understanding of how financial incentives support question asking and answering. Using 800 questions randomly selected from a pay-for-answer site, along with site usage statistics, we examined what factors impact askers' decisions to pay. We also explored how financial rewards affect answers, and if question pricing can help organize Q&amp;A exchanges for archival purposes. We found that askers' decisions are two-partwhether or not to pay and how much to pay. Askers are more likely to pay when requesting facts and will pay more when questions are more difficult. On the answer side, our results support prior findings that paying more may elicit a higher number of answers and answers that are longer, but may not elicit higher quality answers (as rated by the askers). Finally, we present evidence that questions with higher rewards have higher archival value, which suggests that pricing can be used to support archival use. </span></div></div><div class="paper"><span class="title">Hidden Markets: UI Design for a P2P Backup Application</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sven Seuken" class="author">Sven Seuken</a> <a href="byAffiliation.html#Harvard University" class="affiliation">Harvard University</a>,<br /><a href="byAuthors.html#Kamal Jain" class="author">Kamal Jain</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Desney S. Tan" class="author">Desney S. Tan</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Mary Czerwinski" class="author">Mary Czerwinski</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The Internet has allowed market-based systems to become increasingly pervasive. In this paper we explore the role of user interface (UI) design for these markets. Different UIs induce different mental models which in turn determine how users understand and interact with a market. Thus, the intersection of UI design and economics is a novel and important research area. We make three contributions at this intersection. First, we present a novel design paradigm which we call &quot;hidden markets&quot;. The primary goal of hidden markets is to hide as much of the market complexities as possible. Second, we explore this new design paradigm using one particular example: a P2P backup application. We explain the market underlying this system and provide a detailed description of the new UI we developed. Third, we present results from a formative usability study. Our findings indicate that a number of users could benefit from a market-based P2P backup system. Most users intuitively understood the give &amp; take principle as well as the bundle constraints of the market. However, the pricing aspect was difficult to discover/understand for many users and thus needs further investigation. Overall, the results are encouraging and show promise for the hidden market paradigm.</span></div></div><div class="paper"><span class="title">Re-examining Price as a Predictor of Answer Quality in an Online Q&amp;A Site</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Grace YoungJoo Jeon" class="author">Grace YoungJoo Jeon</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Yong-Mi Kim" class="author">Yong-Mi Kim</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Yan Chen" class="author">Yan Chen</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Online question-answering services provide mechanisms for knowledge exchange by allowing users to ask and answer questions on a wide range of topics.  A key question for designing such services is whether charging a price has an effect on answer quality. Two field experiments using one such service, Google Answers, offer conflicting answers to this question. To resolve this inconsistency, we re-analyze data from Harper et al. [5] and Chen et al. [2] to study the price effect in greater depth. Decomposing the price effect into two different levels yields results that reconcile those of the two field experiments. Specifically, we find that: (1) a higher price significantly increases the likelihood that a question receives an answer and (2) for questions that receive an answer, there is no significant price effect on answer quality. Additionally, we find that the rater background makes a difference in evaluating answer quality.  </span></div></div><div class="paper"><span class="title">Why User of Yahoo! Answers Do Not Answer Questions</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#David Dearman" class="author">David Dearman</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a>,<br /><a href="byAuthors.html#Khai N. Truong" class="author">Khai N. Truong</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Despite the number and diversity of question and answer websites, posing a question to the community does not guarantee a response. A significant body of knowledge has been accumulated identifying the motivations for members to contribute to communities of collective action, such as Yahoo! Answers. In contrast, it is not well understood why members choose not to answer a question that they have already read. To explore this issue, we surveyed 135 active members of Yahoo! Answers. We show that top and regular contributors have the same reasons to not answer a question: the subject nature and composition of the question; the perception of how the questioner will receive, interpret and react to their response; and the belief that if the question has received too many responses their response will lose its meaning and get lost in the crowd. Informed by our results, we discussed opportunities to improve the efficacy of the question and answering process, and encourage greater contributions through improved interface and community design.</span></div></div></td>

<td colspan="10" class="session_details" id="S42_details"><div class="paper"><span class="title">Ontology Models for Interaction Design: Case Study of Online Support</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Keith Butler" class="author">Keith Butler</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Jia Zhang" class="author">Jia Zhang</a> <a href="byAffiliation.html#University of Texas" class="affiliation">University of Texas</a>,<br /><a href="byAuthors.html#Anne Hunt" class="author">Anne Hunt</a> <a href="byAffiliation.html# " class="affiliation"> </a>,<br /><a href="byAuthors.html#Beth Huffer" class="author">Beth Huffer</a> <a href="byAffiliation.html# " class="affiliation"> </a>,<br /><a href="byAuthors.html#John Muehleisen" class="author">John Muehleisen</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a></div></div><div class="paper"><span class="title">The Fulfillment of User Needs and the Course of Time in Field Investigation</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Claudia Nass" class="author">Claudia Nass</a> <a href="byAffiliation.html#Fraunhofer Institute for Experimental Software Engineering" class="affiliation">Fraunhofer Institute for Experimental Software Engineering</a>,<br /><a href="byAuthors.html#Daniel Kerkow" class="author">Daniel Kerkow</a> <a href="byAffiliation.html#Fraunhofer Institute for Experimental Software Engineering" class="affiliation">Fraunhofer Institute for Experimental Software Engineering</a>,<br /><a href="byAuthors.html#Jessica Jung" class="author">Jessica Jung</a> <a href="byAffiliation.html#Fraunhofer Institute for Experimental Software Engineering" class="affiliation">Fraunhofer Institute for Experimental Software Engineering</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Business contexts represent a big challenge for software development, specifically in terms of finding a balance between business goals and users goals. This context determines the utility of an application, but good user experience (UX) with business applications is only achieved if the software supports the fulfillment of users goals and needs. This article presents the efforts realized in a call-center of a German telephone company aimed at enhancing UX and hence creating a positive influence on the emotional state of the users/employees. It describes a method applied for the elicitation of user needs as well as ideas for improving UX. Beyond that, the results indicate that software properties can influence the emotional state of the user if they support the fulfillment of human needs and thus positively affect the achievement of business goals.</span></div></div><div class="paper"><span class="title">Using &quot;Rapid Experimentation&quot; to Inform Customer Service Experience Design</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Soni Meckem" class="author">Soni Meckem</a> <a href="byAffiliation.html#Cisco Systems, Inc." class="affiliation">Cisco Systems, Inc.</a>,<br /><a href="byAuthors.html#Jennifer Lee Carlson" class="author">Jennifer Lee Carlson</a> <a href="byAffiliation.html#Tec-Ed, Inc." class="affiliation">Tec-Ed, Inc.</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This case study describes how Cisco followed a Rapid  Experimentation methodology in conducting iterative,  high velocity pilot studies to inform a large global  customer service experience design project. The  research findings described in this case study informed  the design of a better mechanism for customers to  select their expected outcomes, so Cisco can provide a  personalized service experience. This improved  accuracy moves us closer to our goal of eliminating at  least 5% of all re-routing of service requests. In  addition, customer satisfaction improves as we  approach our target of reducing average Time-To-  Resolution by at least 5%, which also saves on the  Cost-Per-Call for Cisco.    The case study explains how these studies improved  the direction of the design concept and narrowed the  research focus to answer more specific design  questions. It summarizes how this approach was  successfully applied in the customer service experience  design situation to achieve the same experience design  goal in 8 weeks, 4 weeks ahead of the 12-week schedule. We also  describe lessons learned in applying the Rapid  Experimentation methodology.</span></div></div></td>

<td colspan="10" class="session_details" id="S49_details"><div class="paper"><span class="title">Exploiting Knowledge-in-the-head and Knowledge-in-the-social-web: Effects of Domain Expertise on Exploratory Search in Individual and Social Search Environments</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ruogu Kang" class="author">Ruogu Kang</a> <a href="byAffiliation.html#University of Illinois at Urbana-Champaign" class="affiliation">University of Illinois at Urbana-Champaign</a>,<br /><a href="byAuthors.html#Wai-Tat Fu" class="author">Wai-Tat Fu</a> <a href="byAffiliation.html#University of Illinois at Urbana-Champaign" class="affiliation">University of Illinois at Urbana-Champaign</a>,<br /><a href="byAuthors.html#Thomas George Kannampallil" class="author">Thomas George Kannampallil</a> <a href="byAffiliation.html#University of Illinois at Urbana-Champaign" class="affiliation">University of Illinois at Urbana-Champaign</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Our study compared how experts and novices performed exploratory search using a traditional search engine and a social tagging system. As expected, results showed that social tagging systems could facilitate exploratory search for both experts and novices. We, however, also found that experts were better at interpreting the social tags and generating search keywords, which made them better at finding information in both interfaces. Specifically, experts found more general information than novices by better interpretation of social tags in the tagging system; and experts also found more domain-specific information by generating more of their own keywords. We found a dynamic interaction between knowledge-in-the-head and knowledge-in-the-social-web that although information seekers are more and more reliant on information from the social Web, domain expertise is still important in guiding them to find and evaluate the information. Implications on the design of social search systems that facilitate exploratory search are also discussed.</span></div></div><div class="paper"><span class="title">Interactive Effects of Age and Interface Differences on Search Strategies and Performance</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jessie Chin" class="author">Jessie Chin</a> <a href="byAffiliation.html#University of Illinois at Urbana Champaign, UIUC" class="affiliation">University of Illinois at Urbana Champaign, UIUC</a>,<br /><a href="byAuthors.html#Wai-Tat Fu" class="author">Wai-Tat Fu</a> <a href="byAffiliation.html#University of Illinois at Urbana Champaign, UIUC" class="affiliation">University of Illinois at Urbana Champaign, UIUC</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present results from an experiment that studied the information search behavior of younger and older adults in a medical decision-making task. To study how different combination of tasks and interfaces influenced search strategies and decision-making outcomes, we varied information structures of two interfaces and presented different task descriptions to participants. We found that younger adults tended to use different search strategies in different combination of tasks and interfaces, and older adults tended to use the same top-down strategies across conditions. We concluded that older adults were able to perform mental transformation of medical terms more effectively than younger adults. Thus older adults did not require changing strategies to maintain the same level of performance.    </span></div></div><div class="paper"><span class="title">Children's Roles Using Keyword Search Interfaces at Home</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Allison Druin" class="author">Allison Druin</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Elizabeth Foss" class="author">Elizabeth Foss</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Hilary Hutchinson" class="author">Hilary Hutchinson</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a>,<br /><a href="byAuthors.html#Leshell Hatley" class="author">Leshell Hatley</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Evan Golub" class="author">Evan Golub</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Children want to find information about their world, but there are barriers to finding what they seek.  Young people have varying abilities to formulate multi-step queries and comprehend search results. Challenges in understanding where to type, confusion about what tools are available, and frustration with how to parse the results page all have led to a lack of perceived search success for children 7-11 years old.  In this paper, we describe seven search roles children display as information seekers using Internet keyword interfaces, based on a home study of 83 children ages 7, 9, and 11. These roles are defined not only by the children's search actions, but also by who influences their searching, their perceived success, and trends in age and gender.  These roles suggest a need for new interfaces that expand the notion of keywords, scaffold results, and develop a search culture among children.</span></div></div></td>

<td colspan="10" class="session_details" id="S48_details"><div class="paper"><span class="title">Using Reinforcement to Strengthen Users' Secure Behaviors</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ricardo Villamarin Salomon" class="author">Ricardo Villamarin Salomon</a> <a href="byAffiliation.html#University of Pittsburgh" class="affiliation">University of Pittsburgh</a>,<br /><a href="byAuthors.html#Jose Brustoloni" class="author">Jose Brustoloni</a> <a href="byAffiliation.html#University of Pittsburgh" class="affiliation">University of Pittsburgh</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Users have a strong tendency toward dismissing security dialogs unthinkingly. Prior research has shown that users' responses to security dialogs become significantly more thoughtful when dialogs are polymorphic, and that further improvements can be obtained when dialogs are also audited and auditors penalize users who give unreasonable responses. We contribute an Operant Conditioning model that fits these observations, and, inspired by the model, propose Security Reinforcing Applications (SRAs). SRAs seek to reward users' secure behavior, instead of penalizing insecure behavior. User studies show that SRAs improve users' secure behaviors and that behaviors strengthened in this way do not extinguish after a period of several weeks in which users do not interact with SRAs. Moreover, inspired by Social Learning theory, we propose Vicarious Security Reinforcement (VSR). A user study shows that VSR accelerates SRA benefits.</span></div></div><div class="paper"><span class="title">Who Falls for Phish? A Demographic Analysis of Phishing Susceptibility and Effectiveness of Interventions</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Steve Sheng" class="author">Steve Sheng</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Mandy Holbrook" class="author">Mandy Holbrook</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Ponnurangam Kumaraguru" class="author">Ponnurangam Kumaraguru</a> <a href="byAffiliation.html#Indraprastha Institute of Information Technology " class="affiliation">Indraprastha Institute of Information Technology </a>,<br /><a href="byAuthors.html#Lorrie Cranor" class="author">Lorrie Cranor</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Julie Downs" class="author">Julie Downs</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we present the results of a roleplay survey instrument administered to 1001 online survey respondents to study both the relationship between demographics and phishing susceptibility and the effectiveness of several anti-phishing educational materials. Our results suggest that women are more susceptible than men to phishing and participants between the ages of 18 and 25 are more susceptible to phishing than other age groups. We explain these demographic factors through a mediation analysis. Educational materials reduced users' tendency to enter information into phishing webpages by 40% percent; however, some of the educational materials we tested also slightly decreased participants' tendency to click on legitimate links. </span></div></div><div class="paper"><span class="title">The True Cost of Unusable Password Policies: Password Use in the Wild</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Philip Inglesant" class="author">Philip Inglesant</a> <a href="byAffiliation.html#University College London" class="affiliation">University College London</a>,<br /><a href="byAuthors.html#M. Angela Sasse" class="author">M. Angela Sasse</a> <a href="byAffiliation.html#University College London" class="affiliation">University College London</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">HCI research published 10 years ago pointed out that many users cannot cope with the number and complexity of passwords, and resort to insecure workarounds as a consequence. We present a study which re-examined password policies and password practice in the workplace today.   32 staff members in two organisations kept a password diary for 1 week, which produced a sample of 196 passwords. The diary was followed by an interview which covered details of each password, in its context of use.  We find that users are in general concerned to maintain security, but that existing security policies are too inflexible to match their capabilities, and the tasks and contexts in which they operate. As a result, these password policies can place demands on users which impact negatively on their productivity and, ultimately, that of the organisation.  We conclude that, rather than focussing password policies on maximizing password strength and enforcing frequency alone, policies should be designed using HCI principles to help the user to set an appropriately strong password in a specific context of use.</span></div></div></td>

<td colspan="10" class="session_details" id="S44_details"><div class="paper"><span class="title">Occlusion-Aware Interfaces</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Daniel Vogel" class="author">Daniel Vogel</a> <a href="byAffiliation.html#University of Toronto,  Mount Allison University" class="affiliation">University of Toronto,  Mount Allison University</a>,<br /><a href="byAuthors.html#Ravin Balakrishnan" class="author">Ravin Balakrishnan</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We define occlusion-aware interfaces as interaction techniques which know what area of the display is currently occluded, and use this knowledge to counteract potential problems and/or utilize the hidden area. As a case study, we describe the Occlusion-Aware Viewer, which identifies important regions hidden beneath the hand and displays them in a non-occluded area using a bubble-like callout. To determine what is important, we use an application agnostic image processing layer. For the occluded area, we use a user configurable, real-time version of Vogel et al.'s [21]  geometric model. In an evaluation with a simultaneous monitoring task, we find the technique can successfully mitigate the effects of occlusion, although issues with ambiguity and stability suggest further refinements. Finally, we present designs for three other occlusion-aware techniques for pop-ups, dragging, and a hidden widget.</span></div></div><div class="paper"><span class="title">High-Precision Magnification Lenses</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Caroline Appert" class="author">Caroline Appert</a> <a href="byAffiliation.html#LRI - Université Paris-Sud et CNRS,  INRIA" class="affiliation">LRI - Université Paris-Sud et CNRS,  INRIA</a>,<br /><a href="byAuthors.html#Olivier Chapuis" class="author">Olivier Chapuis</a> <a href="byAffiliation.html#LRI - Université Paris-Sud et CNRS,  INRIA" class="affiliation">LRI - Université Paris-Sud et CNRS,  INRIA</a>,<br /><a href="byAuthors.html#Emmanuel Pietriga" class="author">Emmanuel Pietriga</a> <a href="byAffiliation.html#INRIA,  LRI - Université Paris-Sud et CNRS  " class="affiliation">INRIA,  LRI - Université Paris-Sud et CNRS  </a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Focus+context interfaces provide in-place magnification of a region of the display, smoothly integrating the focus of attention into its surroundings. Two representations of the data exist simultaneously at two different scales, providing an alternative to classical pan &amp; zoom for navigating multi-scale interfaces. For many practical applications however, the magnification range of focus+context  techniques is too limited. This paper addresses this limitation by exploring the quantization problem: the mismatch between visual and motor precision in the magnified region. We introduce three new interaction techniques that solve this problem by integrating fast navigation and high-precision interaction in the magnified region. Speed couples precision to navigation speed. Key and Ring use a discrete switch between precision levels, the former using a keyboard modifier, the latter by decoupling the cursor from the lens' center. We report on three experiments showing that our techniques make interacting with lenses easier while increasing the range of practical magnification factors, and that performance can be further improved by integrating speed-dependent visual behaviors.  </span></div></div><div class="paper"><span class="title">Quasi-Qwerty Soft Keyboard Optimization</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Xiaojun Bi" class="author">Xiaojun Bi</a> <a href="byAffiliation.html#University of Toronto  IBM Research - Almaden" class="affiliation">University of Toronto  IBM Research - Almaden</a>,<br /><a href="byAuthors.html#Barton Smith" class="author">Barton Smith</a> <a href="byAffiliation.html#IBM Research - Almaden" class="affiliation">IBM Research - Almaden</a>,<br /><a href="byAuthors.html#Shumin Zhai" class="author">Shumin Zhai</a> <a href="byAffiliation.html#IBM Research - Almaden" class="affiliation">IBM Research - Almaden</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">It has been well understood that optimized soft keyboard layouts improve motor movement efficiency over the standard Qwerty layouts, but have the drawback of long initial visual search time for novice users. To ease the initial searching time on optimized soft keyboards, we explored Quasi-Qwerty optimization so that the resulting layouts are close to Qwerty. Our results show that a middle ground between the optimized but new, and the familiar but inefficient (Qwerty) does exist. We show that by allowing letters to move at most one step (key) away from their original positions on Qwerty in an optimization process, one can achieve about half of what free optimization could gain in movement efficiency. An experiment shows that due to users' familiarity with Qwerty, a layout with quasi Qwerty optimization could significantly reduce novice users' visual search time to between those of Qwerty and a freely optimized layout. The results in this work provide designers with a new quantitative understanding of the soft keyboard design space.</span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">4:30&nbsp;PM<br/><em>to</em><br/>6:00&nbsp;PM</td>
<td class="session" id="S28">
<span class="type">ToCHI</span>
<span class="title">Studying and Prototyping</span>
<span class="location"></span>
</td>
<td class="session" id="S52">
<span class="type">Papers/Notes</span>
<span class="title">Dance, Dust, and Drama: Designing Design</span>
<span class="location">Centennial 1</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S21">
<span class="type">Panel</span>
<span class="title">What Makes a Good Design Critic? Food Design vs. Product Design Criticism</span>
<span class="location">Centennial 2</span>
</td>
<td class="session" id="S51">
<span class="type">Papers/Notes</span>
<span class="title">Computing on the Body</span>
<span class="location">Centennial 3</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S54">
<span class="type">Papers/Notes</span>
<span class="title">Organizing and Organizations</span>
<span class="location">Centennial 4</span>
</td>
<td class="session" id="S8">
<span class="type">SIG</span>
<span class="title">Can we all stand under our umbrella? The Arts and Design Research in HCI</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S57">
<span class="type">Papers/Notes</span>
<span class="title">Writing in the Real World</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S56">
<span class="type">Papers/Notes</span>
<span class="title">Speech and Touch</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S53">
<span class="type">Papers/Notes</span>
<span class="title">End-User Programming I</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S55">
<span class="type">Papers/Notes</span>
<span class="title">Performance, Stagecraft, and Magic</span>
<span class="location">Regency 7</span>
</td>
</tr>
<tr class="details_row">

<td colspan="10" class="session_details" id="S28_details"><div class="paper"><span class="title">Unpacking the television: User practices around a changing technology</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Louise Barkhuus" class="author">Louise Barkhuus</a> <a href="byAffiliation.html#University of California San Diego" class="affiliation">University of California San Diego</a>,<br /><a href="byAuthors.html#Barry Brown" class="author">Barry Brown</a> <a href="byAffiliation.html#University of California San Diego" class="affiliation">University of California San Diego</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper investigates the changing television watching practices amongst early adopters of PVRs and Internet downloading of video. Through in-depth interviews with 21 video enthusiasts, we describe how television watching change when decoupled from broadcast TV schedules. TV watching becomes more active as programs are gathered from schedules, played from a stored collection and fast forwarded. Download users exploit the internet to view shows and movies not broadcast, yet this watching is not fundamentally different from recording shows using a PVR, since both involve selection of shows from a limited range and a wait before the shows can be watched.</span></div></div><div class="paper"><span class="title">The Calendar is Crucial': Coordination and Awareness through the Family Calendar</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Carman Neustaedter" class="author">Carman Neustaedter</a> <a href="byAffiliation.html#Kodak Research Labs" class="affiliation">Kodak Research Labs</a>,<br /><a href="byAuthors.html#AJ Brush" class="author">AJ Brush</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Saul Greenberg" class="author">Saul Greenberg</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Everyday family life involves a myriad of mundane activities that need to be planned and coordinated. We describe findings from studies of 44 different families' calendaring routines to understand how to best design technology to support them. We outline how a typology of calendars containing family activities is used by three different types of families-Monocentric, Pericentric, and Polycentric-which vary in the level of family involvement in the calendaring process. We describe these family types, the content of family calendars, the ways in which they are extended through annotations and augmentations, and the implications from these findings for design.</span></div></div><div class="paper"><span class="title">Out on the town: a socio-physical approach to the design of a context aware urban guide</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jeni Paay" class="author">Jeni Paay</a> <a href="byAffiliation.html#Aalborg University" class="affiliation">Aalborg University</a>,<br /><a href="byAuthors.html#Jesper Kjeldskov" class="author">Jesper Kjeldskov</a> <a href="byAffiliation.html#Aalborg University" class="affiliation">Aalborg University</a>,<br /><a href="byAuthors.html#Steve Howard" class="author">Steve Howard</a> <a href="byAffiliation.html#The University of Melbourne" class="affiliation">The University of Melbourne</a>,<br /><a href="byAuthors.html#Bharat Dave" class="author">Bharat Dave</a> <a href="byAffiliation.html#The University of Melbourne" class="affiliation">The University of Melbourne</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">As urban environments become increasingly hybridized, mixing the social, built and digital in interesting ways, designing for computing in the city presents new challenges. Here we synthesize earlier work in human-computer interaction, sociology and architecture in order to deliberately influence the design of digital systems. We propose, illustrate and evaluate a multi-disciplinary approach combining rapid ethnography, architectural analysis, design sketching and paper prototyping. Following the approach we provide empirically grounded representations of the socio-physical context of use. We then use this understanding to influence the design of a context aware system to be used whilst out on the town.</span></div></div><div class="paper"><span class="title">Rapid Prototyping and Evaluation of In-Vehicle Interfaces</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Dario Salvucci" class="author">Dario Salvucci</a> <a href="byAffiliation.html#Drexel University" class="affiliation">Drexel University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">As driver distraction from in-vehicle devices becomes an increasingly critical issue, researchers have aimed to establish better scientific understanding of distraction along with better engineering tools to build less distracting devices. This paper presents a new system, Distract-R, that allows designers to rapidly prototype and evaluate new in-vehicle interfaces. The core engine of the system relies on a rigorous cognitive model of driver behavior which, when integrated with models of task behavior on the prototyped interfaces, generate predictions of driver performance and distraction. Distract-R allows a designer to prototype basic interfaces, demonstrate possible tasks on these interfaces, specify relevant driver characteristics and driving scenarios, and finally simulate, visualize, and analyze the resulting behavior as generated by the cognitive model. The paper includes three modeling studies that demonstrate the systems ability to account for various aspects of driver performance for several types of in-vehicle interfaces. More generally, Distract-R illustrates how cognitive models can be used as internal simulation engines for design tools intended for non-modelers, with the ultimate goal of helping to understand and predict user behavior in multitasking environments.</span></div></div></td>

<td colspan="10" class="session_details" id="S52_details"><div class="paper"><span class="title">Hand in Hand with the Material: Designing for Suppleness</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Petra Sundström" class="author">Petra Sundström</a> <a href="byAffiliation.html#Mobile Life @ Stockholm University" class="affiliation">Mobile Life @ Stockholm University</a>,<br /><a href="byAuthors.html#Kristina Höök" class="author">Kristina Höök</a> <a href="byAffiliation.html#Mobile Life @ Stockholm University" class="affiliation">Mobile Life @ Stockholm University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Designing for a supple interaction, involving users bodily and emotionally into a dance' with a system is a chal-lenging task. Any break-ups in interaction become fatal to the sensual, fluent, bodily and social experience sought. A user-centered, iterative design cycle is therefore required.   But getting to know the affordances of the digital material used to build the application plays an equally important role in the design process. The feel' of the digital mate-rial properties sometimes even determines what the de-sign should be. We describe three situations in which the properties and affordances of sensor network technologies guided our design process of FriendSense - a system for expressing friendship and emotional closeness through movement. We show how the sensor node look and feel, choice of sensors, limitations of the radio signal strength and coverage, as well as iterative prototyping to properly exploit the software/algorithmic possibilities guided our design process.</span></div></div><div class="paper"><span class="title">The case of the disappearing ox: seeing through digital images to an analysis of ancient texts</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Grace De la Flor" class="author">Grace De la Flor</a> <a href="byAffiliation.html#Computing Laboratory,  University of Oxford" class="affiliation">Computing Laboratory,  University of Oxford</a>,<br /><a href="byAuthors.html#Paul Luff" class="author">Paul Luff</a> <a href="byAffiliation.html#Centre for Work, Interaction and Technology  Department of Management,  King's College  " class="affiliation">Centre for Work, Interaction and Technology  Department of Management,  King's College  </a>,<br /><a href="byAuthors.html#Marina Jirotka" class="author">Marina Jirotka</a> <a href="byAffiliation.html#Oxford e-Research Centre,  University of Oxford" class="affiliation">Oxford e-Research Centre,  University of Oxford</a>,<br /><a href="byAuthors.html#Ruth Kirkham" class="author">Ruth Kirkham</a> <a href="byAffiliation.html#Humanities Division,  University of Oxford" class="affiliation">Humanities Division,  University of Oxford</a>,<br /><a href="byAuthors.html#John Pybus" class="author">John Pybus</a> <a href="byAffiliation.html#Humanities Division,  University of Oxford" class="affiliation">Humanities Division,  University of Oxford</a>,<br /><a href="byAuthors.html#Annamaria Carusi" class="author">Annamaria Carusi</a> <a href="byAffiliation.html#Oxford e-Research Centre,  University of Oxford" class="affiliation">Oxford e-Research Centre,  University of Oxford</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">There are numerous settings where people examine, scrutinize and discuss the details of images in the course of their work. In most medical domains, scans and x-rays are used in the diagnosis of cases; in most areas of science, methods of visualization have been adopted to assist in the analysis of data; and images of different kinds are critical for many research fields in the social sciences and humanities. It is not surprising that recently technologies have been proposed to assist with the analysis and examination of images. In this paper, we consider requirements for technologies in a rather distinctive domain of research, the classics. Drawing upon an analysis of the detailed ways in which classicists work with digital images, we discuss the requirements for systems to support researchers in this domain, and also provide further considerations on the general development of image processing technologies and visualization techniques.</span></div></div><div class="paper"><span class="title">The Implications of Improvisational Acting and Role-Playing on Design Methodologies</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ben Medler" class="author">Ben Medler</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Brian Magerko" class="author">Brian Magerko</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">For decades designers have used theatre metaphors to  describe design methodologies and have used performance  techniques to enhance the design process, two of which are  improvisational acting and role-playing. Unfortunately,  most design literature does not differentiate between these  two practices even while using them in combination with  various design methods. This paper discusses how  improvisation and role-playing have been employed during  the design process and why they are distinct from one  another. The authors draw upon their current research  involving improvisational acting and compare it with other  role-playing research which examines role-playing from  both a serious and entertainment angle. They conclude  through this comparison that both performance techniques  have their place in the design process and that more  informed definitions of each technique can aid designers in  deciding which technique's properties will benefit them the  most.</span></div></div></td>

<td colspan="10" class="session_details" id="S21_details"><div class="paper"><span class="title">What Makes a Good Design Critic?  Food Design vs. Product Design Criticism</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Patañjali Venkatacharya" class="author">Patañjali Venkatacharya</a> <a href="byAffiliation.html#Oracle USA, Inc. and  Patañjali's Kitchen LLC" class="affiliation">Oracle USA, Inc. and  Patañjali's Kitchen LLC</a>,<br /><a href="byAuthors.html#Jonathan Kessler" class="author">Jonathan Kessler</a> <a href="byAffiliation.html#Food Critic &amp; Writer" class="affiliation">Food Critic &amp; Writer</a>,<br /><a href="byAuthors.html#Tami Hardeman" class="author">Tami Hardeman</a> <a href="byAffiliation.html#Food Stylist" class="affiliation">Food Stylist</a>,<br /><a href="byAuthors.html#Ed Seiber" class="author">Ed Seiber</a> <a href="byAffiliation.html#Architect &amp; Interior Designer,  Seiber Design, Inc." class="affiliation">Architect &amp; Interior Designer,  Seiber Design, Inc.</a>,<br /><a href="byAuthors.html#Bill Buxton" class="author">Bill Buxton</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This panel will bring together leading food design and product design critics. The panelists will include: a leading Atlanta-based food critic and writer, a food stylist, a restaurant architect &amp; designer, and a well-known product design critic familiar with the field of user experience. Together, the panel will compare and contrast how design experts from these two disciplines provide design criticism, and whether there are any novel learning points from each perspective. </span></div></div></td>

<td colspan="10" class="session_details" id="S51_details"><div class="paper"><span class="title">BuzzWear: Alert perception in Wearable Tactile Displays on the Wrist</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Seungyon Claire Lee" class="author">Seungyon Claire Lee</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Thad Starner" class="author">Thad Starner</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present two experiments to evaluate wrist-worn wearable tactile displays (WTDs) that provide easy to perceive alerts for on-the-go users.  The first experiment (2304 trials, 12 participants) focuses on the perception sensitivity of tactile patterns and reveals that people discriminate our 24 tactile patterns with up to 99% accuracy after 40 minutes of training. Among the four parameters (intensity, starting point, temporal pattern, and direction) that vary in the 24 patterns, intensity is the most difficult parameter to distinguish and temporal pattern is the easiest.  The second experiment (9900 trials, 15 participants) focuses on dual task performance, exploring users' abilities to perceive three incoming alerts from two mobile devices (WTD and mobile phone) with and without visual distraction. The second experiment reveals that, when visually distracted, users' reactions to incoming alerts become slower for the  mobile phone but not for the WTD.</span></div></div><div class="paper"><span class="title">i*CATch: A Scalable, Plug-n-Play Wearable Computing Framework for Novices and Children</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Grace Ngai" class="author">Grace Ngai</a> <a href="byAffiliation.html#Hong Kong Polytechnic University" class="affiliation">Hong Kong Polytechnic University</a>,<br /><a href="byAuthors.html#Stephen C.F. Chan" class="author">Stephen C.F. Chan</a> <a href="byAffiliation.html#Hong Kong Polytechnic University" class="affiliation">Hong Kong Polytechnic University</a>,<br /><a href="byAuthors.html#Vincent T.Y. Ng" class="author">Vincent T.Y. Ng</a> <a href="byAffiliation.html#Hong Kong Polytechnic University" class="affiliation">Hong Kong Polytechnic University</a>,<br /><a href="byAuthors.html#Joey C.Y. Cheung" class="author">Joey C.Y. Cheung</a> <a href="byAffiliation.html#Hong Kong Polytechnic University" class="affiliation">Hong Kong Polytechnic University</a>,<br /><a href="byAuthors.html#Sam S.S. Choy" class="author">Sam S.S. Choy</a> <a href="byAffiliation.html#Hong Kong Polytechnic University" class="affiliation">Hong Kong Polytechnic University</a>,<br /><a href="byAuthors.html#Winnie W.Y. Lau" class="author">Winnie W.Y. Lau</a> <a href="byAffiliation.html#Hong Kong Polytechnic University" class="affiliation">Hong Kong Polytechnic University</a>,<br /><a href="byAuthors.html#Jason T.P. Tse" class="author">Jason T.P. Tse</a> <a href="byAffiliation.html#Hong Kong Polytechnic University" class="affiliation">Hong Kong Polytechnic University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">There has been much recent work in wearable computing that is directed at democratization of the field, to make it more accessible to the general public and more easily used by the hobbyist user. As the field becomes more diversified, there has also been a shift away from the highly specialized functionality of earlier applications towards aesthetics, creativity, design and self-expression, as well as a push towards using wearable computing as an outreach tool to broaden interest and exposure in engineering and computing.  This paper presents the design and development of the i*CATch wearable computing framework, which was developed specifically for children and novices to the field. The i*CATch framework is based upon a bus-based architecture, and is more scalable than the current alternatives. It consists of a set of plug-and-play components, a construction platform with a standardized interface, and an easy-to-use hybrid text-graphical integrated development environment. We will also present results of the evaluation of the i*CATch framework in real teaching environments.</span></div></div><div class="paper"><span class="title">Skinput: Appropriating the Body as an Input Surface</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Chris Harrison" class="author">Chris Harrison</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Desney Tan" class="author">Desney Tan</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Dan Morris" class="author">Dan Morris</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present Skinput, a technology that appropriates the human body for acoustic transmission, allowing the skin to be used as an input surface. In particular, we resolve the location of finger taps on the arm and hand by analyzing mechanical vibrations that propagate through the body. We collect these signals using a novel array of sensors worn as an armband. This approach provides an always available, naturally portable, and on-body finger input system. We assess the capabilities, accuracy and limitations of our technique through a two-part, twenty-participant user study. To further illustrate the utility of our approach, we conclude with several proof-of-concept applications we developed. </span></div></div></td>

<td colspan="10" class="session_details" id="S54_details"><div class="paper"><span class="title">Timeline Collaboration</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Morten Bohøj" class="author">Morten Bohøj</a> <a href="byAffiliation.html#UNIVERSITY OF AARHUS and Alexandra Institute" class="affiliation">UNIVERSITY OF AARHUS and Alexandra Institute</a>,<br /><a href="byAuthors.html#Nikolaj Gandrup Borchorst" class="author">Nikolaj Gandrup Borchorst</a> <a href="byAffiliation.html#UNIVERSITY OF AARHUS" class="affiliation">UNIVERSITY OF AARHUS</a>,<br /><a href="byAuthors.html#Niels Olof Bouvin" class="author">Niels Olof Bouvin</a> <a href="byAffiliation.html#UNIVERSITY OF AARHUS" class="affiliation">UNIVERSITY OF AARHUS</a>,<br /><a href="byAuthors.html#Susanne Bødker" class="author">Susanne Bødker</a> <a href="byAffiliation.html#UNIVERSITY OF AARHUS" class="affiliation">UNIVERSITY OF AARHUS</a>,<br /><a href="byAuthors.html#Par-Ola Zander" class="author">Par-Ola Zander</a> <a href="byAffiliation.html#UNIVERSITY OF AARHUS" class="affiliation">UNIVERSITY OF AARHUS</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper explores timelines as a web-based tool for collaboration between citizens and municipal caseworkers. The paper takes its outset in a case study of planning and control of parental leave; a process that may involve surprisingly many actors. As part of the case study, a web-based timeline, CaseLine, was designed. This design crosses the boundaries between leisure and work, in ways that are different from what is often seen in current HCI. The timeline has several roles on these boundaries: It is a shared planning and visualization tool that may be used by parents and caseworkers alone or together, it serves as a contract and a sandbox, as a record and a plan, as inspiration for planning and an authoritative road, as a common information space and a fragmented exchange. Serving all these roles does not happen smoothly, and the paper discusses the challenges of such timeline interaction in, and beyond this case.</span></div></div><div class="paper"><span class="title">Informal Interactions in Nonprofit Networks</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jennifer Stoll" class="author">Jennifer Stoll</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#W. Keith Edwards" class="author">W. Keith Edwards</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Elizabeth D. Mynatt" class="author">Elizabeth D. Mynatt</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Nonprofit organizations often need to excel in coordinating with other organizations and must do so in a variety of contexts and levels from the informal to the formal. Their ability to accomplish their mission can critically depend on their efficacy in managing dependencies on others for tasks, accessing needed resources, raising their profile in the community, and achieving their goals. Although much research has been done to understand systems for supporting formal coordination between organizations, there is a gap in understanding how informal coordination can be supported by systems. As a first step towards addressing this gap, we conducted a field study of a network of nonprofit organizations, focusing specifically on informal interactions among them. Based on this study, we characterize informal coordination between organizations and the context for such interactions. Our findings point to a need to further explore a class of interorganizational interactions that may not be adequately explored or understood by our research community.</span></div></div><div class="paper"><span class="title">Managing Nomadic Knowledge: A Case Study of the European Social Forum</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Saqib Saeed" class="author">Saqib Saeed</a> <a href="byAffiliation.html#University of Siegen, Germany" class="affiliation">University of Siegen, Germany</a>,<br /><a href="byAuthors.html#Volkmar Pipek" class="author">Volkmar Pipek</a> <a href="byAffiliation.html#University of Siegen, Germany" class="affiliation">University of Siegen, Germany</a>,<br /><a href="byAuthors.html#Markus Rohde" class="author">Markus Rohde</a> <a href="byAffiliation.html#University of Siegen" class="affiliation">University of Siegen</a>,<br /><a href="byAuthors.html#Volker Wulf" class="author">Volker Wulf</a> <a href="byAffiliation.html#University of Siegen, Germany" class="affiliation">University of Siegen, Germany</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we portray a specific type of knowledge which we term nomadic knowledge'. It is required periodically by different actors and travels along foreseeable paths between groups or communities of actors. This type of knowledge lets us question generally held assumptions about the way knowledge is enacted. We illustrate our point with an ethnographical field study analyzing the European Social Forum (ESF), a network of political activist organizations. In this network different actors organize a periodic (biannual) event in which some 13,000 activists participated in 2008. We investigate how knowledge about organizing and managing the ESF is transferred between two events respectively, the actors and communities involved. Our study highlights the specific challenges in sharing nomadic knowledge and the consequences of deficiencies on the organizing process. The paper contributes to a better understanding of knowledge sharing practices and opens new directions for technical support.</span></div></div></td>

<td colspan="10" class="session_details" id="S8_details"><div class="paper"><span class="title">Can we all stand under our umbrella? The Arts and Design Research in HCI</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Gilbert Cockton" class="author">Gilbert Cockton</a> <a href="byAffiliation.html#Northumbria University" class="affiliation">Northumbria University</a>,<br /><a href="byAuthors.html#Bardzell Shaowen" class="author">Bardzell Shaowen</a> <a href="byAffiliation.html#Indiana University" class="affiliation">Indiana University</a>,<br /><a href="byAuthors.html#Blythe Mark" class="author">Blythe Mark</a> <a href="byAffiliation.html#University of York" class="affiliation">University of York</a>,<br /><a href="byAuthors.html#Bardzell Jeffrey" class="author">Bardzell Jeffrey</a> <a href="byAffiliation.html#Indiana University" class="affiliation">Indiana University</a></div></div></td>

<td colspan="10" class="session_details" id="S57_details"><div class="paper"><span class="title">NiCEBook - Supporting Natural Note Taking</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Peter Brandl" class="author">Peter Brandl</a> <a href="byAffiliation.html#Media Interaction Lab, Upper Austria University of Applied Sciences" class="affiliation">Media Interaction Lab, Upper Austria University of Applied Sciences</a>,<br /><a href="byAuthors.html#Michael Haller" class="author">Michael Haller</a> <a href="byAffiliation.html#Media Interaction Lab, Upper Austria University of Applied Sciences" class="affiliation">Media Interaction Lab, Upper Austria University of Applied Sciences</a>,<br /><a href="byAuthors.html#Christoph Richter" class="author">Christoph Richter</a> <a href="byAffiliation.html#Media Interaction Lab, Upper Austria University of Applied Sciences" class="affiliation">Media Interaction Lab, Upper Austria University of Applied Sciences</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper, we present NiCEBook, a paper notebook that supports taking, structuring and reusing notes. Through a study of note-taking habits, we observed that different strategies are used to organize and share notes. Based on these observations, we developed a design for a notebook that combines different approaches to better support these activities. The details of our design were informed by an additional online survey. We emphasize the need to examine the characteristics of taking notes with paper notebooks in order to develop a digital system that resembles the quality of traditional writing. With NiCEBook, we present a solution that combines the flexibility and simplicity of taking notes on paper with the benefits of a digital representation. We demonstrate the capabilities of our system through customized views, searching and sharing functionality.</span></div></div><div class="paper"><span class="title">The NiCE Discussion Room: Integrating Paper and Digital Media to Support Co-Located Group Meetings</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Michael Haller" class="author">Michael Haller</a> <a href="byAffiliation.html#Upper Austria University of Applied Sciences" class="affiliation">Upper Austria University of Applied Sciences</a>,<br /><a href="byAuthors.html#Jakob Leitner" class="author">Jakob Leitner</a> <a href="byAffiliation.html#Upper Austria University of Applied Sciences" class="affiliation">Upper Austria University of Applied Sciences</a>,<br /><a href="byAuthors.html#Thomas Seifried" class="author">Thomas Seifried</a> <a href="byAffiliation.html#Upper Austria University of Applied Sciences" class="affiliation">Upper Austria University of Applied Sciences</a>,<br /><a href="byAuthors.html#Peter Brandl" class="author">Peter Brandl</a> <a href="byAffiliation.html#Upper Austria University of Applied Sciences" class="affiliation">Upper Austria University of Applied Sciences</a>,<br /><a href="byAuthors.html#Christoph Richter" class="author">Christoph Richter</a> <a href="byAffiliation.html#Upper Austria University of Applied Sciences" class="affiliation">Upper Austria University of Applied Sciences</a>,<br /><a href="byAuthors.html#Adam Gokcezade" class="author">Adam Gokcezade</a> <a href="byAffiliation.html#Upper Austria University of Applied Sciences" class="affiliation">Upper Austria University of Applied Sciences</a>,<br /><a href="byAuthors.html#Stacey D. Scott" class="author">Stacey D. Scott</a> <a href="byAffiliation.html#University of Waterloo" class="affiliation">University of Waterloo</a>,<br /><a href="byAuthors.html#James Wallace" class="author">James Wallace</a> <a href="byAffiliation.html#University of Waterloo" class="affiliation">University of Waterloo</a>,<br /><a href="byAuthors.html#Seth Hunter" class="author">Seth Hunter</a> <a href="byAffiliation.html#Massachusetts Institute of Technology" class="affiliation">Massachusetts Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Current technological solutions that enable content creation and sharing during group discussion meetings are often cumbersome to use, and are commonly abandoned for traditional paper-based tools, which provide flexibility in supporting a wide range of working styles and task activities that may occur in a given meeting. Paper-based tools, however, have their own drawbacks; paper-based content is difficult to modify or replicate. We introduce a novel digital meeting room design, the NiCE Discussion Room, which integrates digital and paper tools into a cohesive system with an intuitive pen-based interface. The combination of digital and paper media provides groups with a flexible design solution that enables them to create, access, and share information and media from a variety of sources to facilitate group discussions. This paper describes the design solution, along with results from a user study conducted to evaluate the usability and utility of the system.</span></div></div><div class="paper"><span class="title">Weightless Walls and the Future Office</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Yuichiro Takeuchi" class="author">Yuichiro Takeuchi</a> <a href="byAffiliation.html#Sony Computer Science Laboratories, Inc." class="affiliation">Sony Computer Science Laboratories, Inc.</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we describe how future office environments can benefit from the addition of weightless wallsvirtual, sound blocking walls created using headsets. We particularly focus on exploring how different interaction techniques can be employed to efficiently create, erase, or edit the layouts of these walls, and envisioning how they could impact the overall office experience. Metaphorically, the end effect of integrating weightless walls into offices is that space will be treated in a way similar to how random access memory is treated in PCs; as a shared resource open to dynamic allocations, and whose usage is periodically optimized in real time according to the collective activities of the occupants. Furthermore, we view weightless walls as harbingers of the emergence of synthetic spacethe eventual fusion of the architectural environment with the distinctive properties of digital bits.</span></div></div></td>

<td colspan="10" class="session_details" id="S56_details"><div class="paper"><span class="title">FingerCloud: Uncertainty and autonomy handover in capactive sensing</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Simon Rogers" class="author">Simon Rogers</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#John Williamson" class="author">John Williamson</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Craig Stewart" class="author">Craig Stewart</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Rod Murray-Smith" class="author">Rod Murray-Smith</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We describe a particle filtering approach to inferring finger  movements on capacitive sensing arrays. This technique allows  the efficient combination of human movement models  with accurate sensing models, and gives high-fidelity results  with low-resolution sensor grids and tracks finger height.  Our model provides uncertainty estimates, which can be linked  to the interaction to provide appropriately smoothed responses  as sensing perfomance degrades; system autonomy is increased  as estimates of user behaviour become less certain.  We demonstrate the particle filter approach with a map browser  running with a very small sensor board, where finger position  uncertainty is linked to autonomy handover</span></div></div><div class="paper"><span class="title">The Generalized Perceived Input Point Model and How to Double Touch Accuracy by Extracting Fingerprints</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Christian Holz" class="author">Christian Holz</a> <a href="byAffiliation.html#Hasso Plattner Institute" class="affiliation">Hasso Plattner Institute</a>,<br /><a href="byAuthors.html#Patrick Baudisch" class="author">Patrick Baudisch</a> <a href="byAffiliation.html#Hasso Plattner Institute" class="affiliation">Hasso Plattner Institute</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">It is generally assumed that touch input cannot be accurate because of the fat finger problem, i.e., the softness of the fingertip combined with the occlusion of the target by the finger. In this paper, we show that this is not the case. We base our argument on a new model of touch inaccuracy. Our model is not based on the fat finger problem, but on the perceived input point model. In its published form, this model states that touch screens report touch location at an offset from the intended target. We generalize this model so that it represents offsets for individual finger postures and users. We thereby switch from the traditional 2D model of touch to a model that considers touch a phenomenon in 3-space. We report a user study, in which the generalized model explained 67% of the touch inaccuracy that was previously attributed to the fat finger problem.    In the second half of this paper, we present two devices that exploit the new model in order to improve touch accuracy. Both model touch on per-posture and per-user basis in order to increase accuracy by applying respective offsets. Our RidgePad prototype extracts posture and user ID from the user's fingerprint during each touch interaction. In a user study, it achieved 1.8 times higher accuracy than a simulated capacitive baseline condition. A prototype based on optical tracking achieved even 3.3 times higher accuracy. The increase in accuracy can be used to make touch interfaces more reliable, to pack up to 3.3^2 &gt; 10 times more controls into the same surface, or to bring touch input to very small mobile devices.   </span></div></div><div class="paper"><span class="title">Finger-Count &amp; Radial-Stroke Shortcuts: 2 Techniques for Augmenting Linear Menus on Multi-Touch Surfaces</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Gilles Bailly" class="author">Gilles Bailly</a> <a href="byAffiliation.html#Telecom ParisTech" class="affiliation">Telecom ParisTech</a>,<br /><a href="byAuthors.html#Eric Lecolinet" class="author">Eric Lecolinet</a> <a href="byAffiliation.html#Telecom ParisTech" class="affiliation">Telecom ParisTech</a>,<br /><a href="byAuthors.html#Yves Guiard" class="author">Yves Guiard</a> <a href="byAffiliation.html#Telecom ParisTech" class="affiliation">Telecom ParisTech</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We propose Radial-Stroke and Finger-Count Shortcuts, two techniques aimed at augmenting the menubar on multi-touch surfaces. We designed these multi-finger two-handed interaction techniques in an attempt to overcome the limitations of direct pointing on interactive surfaces, while maintaining compatibility with traditional interaction techniques. While Radial-Stroke Shortcuts exploit the well-known advantages of Radial Strokes, Finger-Count Shortcuts exploit multi-touch by simply counting the number of fingers of each hand in contact with the surface. We report the results of an experimental evaluation of our technique, focusing on expert-mode performance. Finger-Count Shortcuts outperformed Radial-Stroke Shortcuts in terms of both easiness of learning and performance speed.</span></div></div><div class="paper"><span class="title">Speech Dasher: Fast Writing using Speech and Gaze</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Keith Vertanen" class="author">Keith Vertanen</a> <a href="byAffiliation.html#University of Cambridge" class="affiliation">University of Cambridge</a>,<br /><a href="byAuthors.html#David J.C. MacKay" class="author">David J.C. MacKay</a> <a href="byAffiliation.html#University of Cambridge" class="affiliation">University of Cambridge</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Speech Dasher allows writing using a combination of speech and a zooming interface.  Users first speak what they want to write and then they navigate through the space of  recognition hypotheses to correct any errors.  Speech Dasher's model combines information from a speech recognizer, from the user, and from a letter-based language model.  This allows fast writing of anything predicted by the recognizer while also providing seamless fallback to letter-by-letter spelling for words not in the recognizer's predictions.  In a formative user study, expert users wrote at 40 (corrected) words per minute.  They did this despite a recognition word error rate of 22%.  Furthermore, they did this using only speech and the direction of their gaze (obtained via an eye tracker).</span></div></div></td>

<td colspan="10" class="session_details" id="S53_details"><div class="paper"><span class="title">d.note: Revising User Interfaces Through Change Tracking,  Annotations, and Alternatives</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Björn Hartmann" class="author">Björn Hartmann</a> <a href="byAffiliation.html#UC Berkeley" class="affiliation">UC Berkeley</a>,<br /><a href="byAuthors.html#Sean Follmer" class="author">Sean Follmer</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Antonio Ricciardi" class="author">Antonio Ricciardi</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Timothy Cardenas" class="author">Timothy Cardenas</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Scott R. Klemmer" class="author">Scott R. Klemmer</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Interaction designers typically revise user interface prototypes by adding unstructured notes to storyboards and screen printouts. How might computational tools increase the efficacy of UI revision? This paper introduces d.note, a revision tool for user interfaces expressed as control flow diagrams. d.note introduces a command set for modifying and annotating both appearance and behavior of user interfaces; it also defines execution semantics so proposed changes can be tested immediately. The paper reports two studies that compare production and interpretation of revisions in d.note to freeform sketching on static images (the status quo). The revision production study showed that testing of ideas during the revision process led to more concrete revisions, but that the tool also affected the type and number of suggested changes. The revision interpretation study showed that d.note revisions required fewer clarifications, and that additional techniques for expressing revision intent could be beneficial.</span></div></div><div class="paper"><span class="title">FrameWire: A Tool for Automatically Extracting Interaction Logic from Paper Prototyping Tests</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Yang Li" class="author">Yang Li</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Xiang Cao" class="author">Xiang Cao</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Katherine Everitt" class="author">Katherine Everitt</a> <a href="byAffiliation.html#University of Washington " class="affiliation">University of Washington </a>,<br /><a href="byAuthors.html#Morgan Dixon" class="author">Morgan Dixon</a> <a href="byAffiliation.html#University of Washington " class="affiliation">University of Washington </a>,<br /><a href="byAuthors.html#James Landay" class="author">James Landay</a> <a href="byAffiliation.html#University of Washington " class="affiliation">University of Washington </a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Paper prototyping offers unique affordances for interface design. However, due to its spontaneous nature and the limitations of paper, it is difficult to distill and communicate a paper prototype design and its user test findings to a wide audience. To address these issues, we created FrameWire, a computer vision-based system that automatically extracts interaction flows from the video recording of paper prototype user tests. Based on the extracted logic, FrameWire offers two distinct benefits for designers: a structural view of the video recording that allows a designer or a stakeholder to easily distill and understand the design concept and user interaction behaviors, and automatic generation of interactive HTML-based prototypes that can be easily tested with a larger group of users as well as walked through by other stakeholders. The extraction is achieved by automatically aggregating video frame sequences into an interaction flow graph based on frame similarities and a designer-guided clustering process. The results of evaluating FrameWire with realistic paper prototyping tests show that our extraction approach is feasible and FrameWire is a promising tool for enhancing existing prototyping practice.</span></div></div><div class="paper"><span class="title">Example-Centric Programming: Integrating Web Search into the Development Environment</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Joel Brandt" class="author">Joel Brandt</a> <a href="byAffiliation.html#Stanford University  Adobe Systems" class="affiliation">Stanford University  Adobe Systems</a>,<br /><a href="byAuthors.html#Mira Dontcheva" class="author">Mira Dontcheva</a> <a href="byAffiliation.html#Adobe Systems" class="affiliation">Adobe Systems</a>,<br /><a href="byAuthors.html#Marcos Weskamp" class="author">Marcos Weskamp</a> <a href="byAffiliation.html#Adobe Systems" class="affiliation">Adobe Systems</a>,<br /><a href="byAuthors.html#Scott Klemmer" class="author">Scott Klemmer</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The ready availability of online source-code examples has fundamentally changed programming practices. However, current search tools are not designed to assist with programming tasks and are wholly separate from editing tools. This paper proposes that embedding a task-specific search engine in the development environment can significantly reduce the cost of finding information and thus enable programmers to write better code more easily. This paper describes the design, implementation, and evaluation of Blueprint, a Web search interface integrated into the Adobe Flex Builder development environment that helps users locate example code. Blueprint automatically augments queries with code context, presents a code-centric view of search results, embeds the search experience into the editor, and retains a link between copied code and its source. A comparative laboratory study found that Blueprint enables participants to write significantly better code and find example code significantly faster than with a standard Web browser. Analysis of three months of usage logs with 2,024 users suggests that task-specific search interfaces can significantly change how and when people search the Web.</span></div></div></td>

<td colspan="10" class="session_details" id="S55_details"><div class="paper"><span class="title">Eliza meets the Wizard-of-Oz: Blending Machine and Human Control of Embodied Characters</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Steven Dow" class="author">Steven Dow</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Manish Mehta" class="author">Manish Mehta</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Blair MacIntyre" class="author">Blair MacIntyre</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Michael Mateas" class="author">Michael Mateas</a> <a href="byAffiliation.html#University of California Santa Cruz" class="affiliation">University of California Santa Cruz</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">What authoring possibilities arise by blending machine and human control of live embodied character experiences? This paper explores two different behind-the-scenes roles for human operators during a three-month gallery installation of an embodied character experience. In the Transcription role, human operators type players' spoken utterances; then, algorithms interpret the player's intention, choose from pre-authored dialogue based on local and global narrative contexts, and procedurally animate two embodied characters. In the Discourse role, human operators select from semantic categories to interpret player intention; algorithms use this discourse act to automate character dialogue and animation. We compare these two methods of blending control using game logs and interviews, and document how the amateur operators initially resisted having to learn the Discourse version, but eventually preferred having the authorial control it afforded. This paper also outlines a design space for blending machine and human control in live character experiences.</span></div></div><div class="paper"><span class="title">A Stage-Based Model of Personal Informatics Systems</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ian Li" class="author">Ian Li</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Anind Dey" class="author">Anind Dey</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Jodi Forlizzi" class="author">Jodi Forlizzi</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">People strive to obtain self-knowledge. A class of systems called personal informatics is appearing that help people collect and reflect on personal information. However, there is no comprehensive list of problems that users experience using these systems, and no guidance for making these systems more effective. To address this, we conducted surveys and interviews with people who collect and reflect on personal information. We derived a stage-based model of personal informatics systems composed of five stages  (preparation, collection, integration, reflection, and action) and identified barriers in each of the stages. These stages have four essential properties: barriers cascade to later stages; they are iterative; they are user-driven and/or system-driven; and they are uni-faceted or multi-faceted. From these properties, we recommend that personal informatics systems should 1) be designed in a holistic manner across the stages; 2) allow iteration between stages; 3) apply an appropriate balance of automated technology and user control within each stage to facilitate the user experience; and 4) provide support for associating multiple facets of people's lives, to enrich the value of systems.</span></div></div><div class="paper"><span class="title">Deception and Magic in Collaborative Interaction</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Joe Marshall" class="author">Joe Marshall</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Steve Benford" class="author">Steve Benford</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Tony Pridmore" class="author">Tony Pridmore</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We explore the ways in which interfaces can be designed to deceive users so as to create the illusion of magic. We present a study of an experimental performance in which a magician used a computer vision system to conduct a series of illusions based on the well-known three cups' magic trick. We explain our findings in terms of the two broad strategies of misdirecting attention and setting false expectations, articulating specific tactics that were employed in each case. We draw on existing theories of collaborative and spectator interfaces, ambiguity and interpretation, and trajectories through experiences to explain our findings in broader HCI terms. We also extend and integrate current theory to provide refined sensitising concepts for analysing deceptive interactions.</span></div></div></td>

</tr>
</table>
</div>
<div class="day" id="04/13/10">
<h1>Tuesday, April 13</h1>
<table cellspacing="0" class="program">
<tr class="timeslot">
<td class="time">9:00&nbsp;AM<br/><em>to</em><br/>10:30&nbsp;AM</td>
<td class="session" id="S59">
<span class="type">Papers/Notes</span>
<span class="title">Browsing</span>
<span class="location">Centennial 3</span>
</td>
<td class="session" id="S58">
<span class="type">Papers/Notes</span>
<span class="title">At Home With Computing</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S9">
<span class="type">SIG</span>
<span class="title">Best Practices in Longitudinal Research</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S63">
<span class="type">Papers/Notes</span>
<span class="title">Tactile Interaction</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S64">
<span class="type">Papers/Notes</span>
<span class="title">User Characteristics and Large-Scale Tracking</span>
<span class="location">Hanover FG</span>
</td>
<td class="session" id="S60">
<span class="type">Papers/Notes</span>
<span class="title">End-User Programming II</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S62">
<span class="type">Papers/Notes</span>
<span class="title">Sharing in Social Media</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S61">
<span class="type">Papers/Notes</span>
<span class="title">HCI and India</span>
<span class="location">Regency 7</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
</tr>
<tr class="details_row">

<td colspan="8" class="session_details" id="S59_details"><div class="paper"><span class="title">A Study of Tabbed Browsing Among Mozilla Firefox Users</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Patrick Dubroy" class="author">Patrick Dubroy</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a>,<br /><a href="byAuthors.html#Ravin Balakrishnan" class="author">Ravin Balakrishnan</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present a study which investigated how and why users of Mozilla Firefox use multiple tabs and windows during web browsing. The detailed web browsing usage of 21 participants was logged over a period of 13 to 21 days each, and was supplemented by qualitative data from diary entries and interviews. Through an examination of several measures of their tab usage, we show that our participants had a strong preference for the use of tabs rather than multiple windows. We report the reasons they cited for using tabs, and the advantages over multiple windows. We identify several common tab usage patterns which browsers could explicitly support. Finally, we look at how tab usage affects web page revisitation. Most of our participants switched tabs more often than they used the back button, making tab switching the second most important navigation mechanism in the browser, after link clicking.</span></div></div><div class="paper"><span class="title">Using Text Animated Transitions to Support Navigation in Document Histories</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Fanny Chevalier" class="author">Fanny Chevalier</a> <a href="byAffiliation.html#Microsoft-INRIA joint center" class="affiliation">Microsoft-INRIA joint center</a>,<br /><a href="byAuthors.html#Pierre Dragicevic" class="author">Pierre Dragicevic</a> <a href="byAffiliation.html#INRIA" class="affiliation">INRIA</a>,<br /><a href="byAuthors.html#Anastasia Bezerianos" class="author">Anastasia Bezerianos</a> <a href="byAffiliation.html#Ecole Centrale Paris" class="affiliation">Ecole Centrale Paris</a>,<br /><a href="byAuthors.html#Jean-Daniel Fekete" class="author">Jean-Daniel Fekete</a> <a href="byAffiliation.html#INRIA" class="affiliation">INRIA</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This article examines the benefits of using text animated transitions for navigating in the revision history of textual documents. We propose an animation technique for smoothly transitioning between different text revisions, then present the Diffamation system. Diffamation supports rapid exploration of revision histories by combining text animated transitions with simple navigation and visualization tools. We finally describe a user study showing that smooth text animation allows users to track changes in the evolution of textual documents more effectively than flipping pages.</span></div></div><div class="paper"><span class="title">Dynamic Query Interface for Spatial Proximity Query with Degree-of-Interest Varied by Distance to Query Point</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Myoungsu Cho" class="author">Myoungsu Cho</a> <a href="byAffiliation.html#Seoul National University" class="affiliation">Seoul National University</a>,<br /><a href="byAuthors.html#Bohyoung Kim" class="author">Bohyoung Kim</a> <a href="byAffiliation.html#Seoul National University" class="affiliation">Seoul National University</a>,<br /><a href="byAuthors.html#Dong Kyun Jeong" class="author">Dong Kyun Jeong</a> <a href="byAffiliation.html#Samsung Advanced Institute of Technology" class="affiliation">Samsung Advanced Institute of Technology</a>,<br /><a href="byAuthors.html#Yeong-Gil Shin" class="author">Yeong-Gil Shin</a> <a href="byAffiliation.html#Seoul National University" class="affiliation">Seoul National University</a>,<br /><a href="byAuthors.html#Jinwook Seo" class="author">Jinwook Seo</a> <a href="byAffiliation.html#Seoul National University" class="affiliation">Seoul National University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we present an interactive query interface called TrapezoidBox to support spatial proximity queries where users' degree of interest varies depending upon the degree of separation from the point of interest. Spatial proximity queries are commonly built in information seeking tasks especially on online maps. If not impossible, it is hard to formulate spatial proximity queries using existing dynamic query widgets such as range sliders. TrapezoidBox allows users to easily build spatial proximity queries by interactively adjusting a trapezoidal function. Our controlled user study results show that TrapezoidBox has several advantages over a baseline interface with range sliders. </span></div></div></td>

<td colspan="8" class="session_details" id="S58_details"><div class="paper"><span class="title">Access Control for Home Data Sharing: Attitudes, Needs and Practices</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Michelle L. Mazurek" class="author">Michelle L. Mazurek</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#J.P. Arsenault" class="author">J.P. Arsenault</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Joanna Bresee" class="author">Joanna Bresee</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Nitin Gupta" class="author">Nitin Gupta</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Iulia Ion" class="author">Iulia Ion</a> <a href="byAffiliation.html#ETH-Zurich" class="affiliation">ETH-Zurich</a>,<br /><a href="byAuthors.html#Christina Johns" class="author">Christina Johns</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Daniel Jonggyu Lee" class="author">Daniel Jonggyu Lee</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Yuan Liang" class="author">Yuan Liang</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Jennifer Olsen" class="author">Jennifer Olsen</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Brandon Salmon" class="author">Brandon Salmon</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Rich Shay" class="author">Rich Shay</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Kami Vaniea" class="author">Kami Vaniea</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Lujo Bauer" class="author">Lujo Bauer</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Lorrie Faith Cranor" class="author">Lorrie Faith Cranor</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Gregory R. Ganger" class="author">Gregory R. Ganger</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">As digital content becomes more prevalent in the home, non-technical users are increasingly interested in sharing that content with others and accessing it from multiple devices. Not much is known about how these users think about controlling access to this data. To better understand this, we conducted semi-structured, in-situ interviews with 33 users in 15 households. We found that users create ad-hoc access-control mechanisms that do not always work; that their ideal policies are complex and multi-dimensional; that a priori policy specification is often insufficient; and that people's mental models of access control and security are often misaligned with current systems. We detail these findings and present a set of associated guidelines for designing usable access-control systems for the home environment.</span></div></div><div class="paper"><span class="title">Sharing Conversation and Sharing Life: Video Conferencing in the Home</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Tejinder K. Judge" class="author">Tejinder K. Judge</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a>,<br /><a href="byAuthors.html#Carman Neustaedter" class="author">Carman Neustaedter</a> <a href="byAffiliation.html#Kodak Research Labs" class="affiliation">Kodak Research Labs</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Video conferencing is a technology that families and friends use to connect with each other over distance. However, even with such technology readily available, we still do not have a good understanding of how video conferencing systems are used by people as a part of their domestic communication practices. For this reason, we have conducted interviews with 21 adults in the United States to understand video conferencing routines in the home and to inform the design of future domestic communication technologies. Our findings illustrate the importance of discerning availability and willingness to video conference prior to calling, the need to share everyday life activities in addition to conversation, and a need for new privacy protecting strategies that focus on autonomy and solitude as opposed to confidentiality. </span></div></div><div class="paper"><span class="title">Who's Hogging the Bandwidth: The Consequences of Revealing the Invisible in the Home</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Marshini Chetty" class="author">Marshini Chetty</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Richard Banks" class="author">Richard Banks</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Richard Harper" class="author">Richard Harper</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Tim Regan" class="author">Tim Regan</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Abigail Sellen" class="author">Abigail Sellen</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Christos Gkantsidis" class="author">Christos Gkantsidis</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Thomas Karagiannis" class="author">Thomas Karagiannis</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Peter Key" class="author">Peter Key</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">As more technologies enter the home, householders are burdened with the task of digital housekeepingmanaging and sharing digital resources like bandwidth. In response to this, we created and evaluated a domestic tool for bandwidth management called Home Watcher. Our field trial showed that when resource contention amongst different household members is made visible, people's understanding of bandwidth changes and household politics are revealed. In this paper, we describe the consequences of showing real time resource usage in a home, and how this varies depending on the social make up of the household.</span></div></div><div class="paper"><span class="title">Investigating Narrative Structure in Mobile Games for Seniors</span> - <span class="type">Note</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Sharon Lynn Chu Yew Yee" class="author">Sharon Lynn Chu Yew Yee</a> <a href="byAffiliation.html#National University of Singapore" class="affiliation">National University of Singapore</a>,<br /><a href="byAuthors.html#Henry Been-Lirn Duh" class="author">Henry Been-Lirn Duh</a> <a href="byAffiliation.html#National University of Singapore" class="affiliation">National University of Singapore</a>,<br /><a href="byAuthors.html#Francis Quek" class="author">Francis Quek</a> <a href="byAffiliation.html#Virginia Polytechnic Institute and  State University" class="affiliation">Virginia Polytechnic Institute and  State University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Narratives are an intimate part of our lives. Based on beha-vioral research suggesting that older adults tend to process text better at discourse level, this study investigates the im-pact of narrative structure on the enjoyment level of older game players.  Two variations of a casual memory mobile game were built, one with a narrative and the other one without. Nineteen senior citizens, differentiated according to their play orientation, play-tested the games. Results show that embedding narratives in mobile games enhances the play experience of older adults, irrespective of their play style. This may have implications both for game developers and for seniors' acceptance of casual games.  </span></div></div></td>

<td colspan="8" class="session_details" id="S9_details"><div class="paper"><span class="title">Best Practices in Longitudinal Research</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jhilmil Jain" class="author">Jhilmil Jain</a> <a href="byAffiliation.html#Hewlett Packard Laboratories" class="affiliation">Hewlett Packard Laboratories</a>,<br /><a href="byAuthors.html#Stephanie Rosenbaum" class="author">Stephanie Rosenbaum</a> <a href="byAffiliation.html#Tec-Ed, Inc" class="affiliation">Tec-Ed, Inc</a>,<br /><a href="byAuthors.html#Catherine Courage" class="author">Catherine Courage</a> <a href="byAffiliation.html#Citrix Systems" class="affiliation">Citrix Systems</a></div></div></td>

<td colspan="8" class="session_details" id="S63_details"><div class="paper"><span class="title">Mobile Music Touch: Mobile Tactile Stimulation For Passive Learning</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kevin Huang" class="author">Kevin Huang</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Daniel Kohlsdorf" class="author">Daniel Kohlsdorf</a> <a href="byAffiliation.html#University of Bremen" class="affiliation">University of Bremen</a>,<br /><a href="byAuthors.html#Claas Ahlrichs" class="author">Claas Ahlrichs</a> <a href="byAffiliation.html#University of Bremen" class="affiliation">University of Bremen</a>,<br /><a href="byAuthors.html#Thad Starner" class="author">Thad Starner</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Ruediger Leibrandt" class="author">Ruediger Leibrandt</a> <a href="byAffiliation.html#University of Bremen" class="affiliation">University of Bremen</a>,<br /><a href="byAuthors.html#Ellen Do" class="author">Ellen Do</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Gil Weinberg" class="author">Gil Weinberg</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Mobile Music Touch (MMT) helps teach users to play piano melodies while they perform other tasks.  MMT is a lightweight, wireless haptic music instruction system consisting of fingerless gloves and a mobile Bluetooth enabled computing device, such as a mobile phone.  Passages to be learned are loaded into the mobile phone and are played repeatedly while the user performs other tasks.  As each note of the music plays, vibrators on each finger in the gloves activate, indicating which finger is used to play each note.  We present two studies on the efficacy of MMT.  The first measures 16 subjects' ability to play a passage after using MMT for 30 minutes while performing a reading comprehension test.  The MMT system was significantly more effective than a control condition where the passage was played repeatedly but the subjects' fingers were not vibrated.  The second study compares the amount of time required for 10 subjects to replay short, randomly generated passages using passive training versus active training. Participants with no piano experience could repeat the passages after passive training while subjects with piano experience often could not.    </span></div></div><div class="paper"><span class="title">Characteristics of Pressure-Based Input for Mobile Devices</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Craig Stewart" class="author">Craig Stewart</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Michael Rohs" class="author">Michael Rohs</a> <a href="byAffiliation.html#Deutsche Telekom Laboratories, TU Berlin" class="affiliation">Deutsche Telekom Laboratories, TU Berlin</a>,<br /><a href="byAuthors.html#Georg Essl" class="author">Georg Essl</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Sven Kratz" class="author">Sven Kratz</a> <a href="byAffiliation.html#Deutsche Telekom Laboratories, TU Berlin" class="affiliation">Deutsche Telekom Laboratories, TU Berlin</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We conducted a series of user studies to understand and clarify the fundamental characteristics of pressure in user interfaces for mobile devices. We seek to provide insight to clarify a longstanding discussion on mapping functions for pressure input. Previous literature is conflicted about the correct transfer function to optimize user performance. Our study results suggest that the discrepancy can be explained by different signal conditioning circuitry and with improved signal conditioning the user-performed precision relationship is linear. We also explore the effects of hand pose when applying pressure to a mobile device from the front, the back, or simultaneously from both sides in a pinching movement. Our results indicate that grasping type input outperforms single-sided input and is competitive with pressure input against solid surfaces. Finally we provide an initial exploration of non-visual multimodal feedback, motivated by the desire for eyes-free use of mobile devices. The findings suggest that non-visual pressure input can be executed without degradation in selection time but suffers from accuracy problems.</span></div></div><div class="paper"><span class="title">LayerPaint: A Multi-layer Interactive 3D Painting Interface</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Chi-Wing Fu" class="author">Chi-Wing Fu</a> <a href="byAffiliation.html#Nanyang Technological University" class="affiliation">Nanyang Technological University</a>,<br /><a href="byAuthors.html#Jiazhi Xia" class="author">Jiazhi Xia</a> <a href="byAffiliation.html#Nanyang Technological University" class="affiliation">Nanyang Technological University</a>,<br /><a href="byAuthors.html#Ying He" class="author">Ying He</a> <a href="byAffiliation.html#Nanyang Technological University" class="affiliation">Nanyang Technological University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Painting on 3D surfaces is an important operation in computer graphics, virtual reality, and computer aided design.  The painting styles in existing WYSIWYG systems can be awkward, due to the difficulty in rotating or aligning an object for proper viewing during the painting.  This paper proposes a multi-layer approach to building a practical, robust, and novel WYSIWYG interface for efficient painting on 3D models.  The paintable area is not limited to the front-most visible surface on the screen as in conventional WYSIWYG interfaces.  We can efficiently and interactively draw long strokes across different depth layers, and unveil occluded regions that one would like to see or paint on.  In addition, since the painting is now depth-sensitive, we can avoid various potential painting artifacts and limitations in the conventional painting interfaces.  This multi-layer approach brings in several novel painting operations that contribute to a more compelling WYSIWYG 3D painting interface; this is particular useful when dealing with complicated objects with occluded parts and objects that cannot be easily parameterized.  We evaluated our system with 23 users, including both artists and novice painters, and obtained positive experimental results and feedback from them.  The user study results demonstrate the efficacy of our novel interface over conventional painting interfaces.</span></div></div></td>

<td colspan="8" class="session_details" id="S64_details"><div class="paper"><span class="title">The Effects of Diversity on Group Productivity and Member Withdrawal in Online Volunteer Groups</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jilin Chen" class="author">Jilin Chen</a> <a href="byAffiliation.html#University of Minnesota" class="affiliation">University of Minnesota</a>,<br /><a href="byAuthors.html#Yuqing Ren" class="author">Yuqing Ren</a> <a href="byAffiliation.html#University of Minnesota" class="affiliation">University of Minnesota</a>,<br /><a href="byAuthors.html#John Riedl" class="author">John Riedl</a> <a href="byAffiliation.html#University of Minnesota" class="affiliation">University of Minnesota</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The wisdom of crowds argument emphasizes the importance of diversity in online collaborations, such as open source projects and Wikipedia. However, decades of research on diversity in offline work groups have painted an inconclusive picture. On the one hand, the broader range of insights from a diverse group can lead to improved outcomes. On the other hand, individual differences can lead to conflict and diminished performance. In this paper, we examine the effects of group diversity on the amount of work accomplished and on member withdrawal behaviors in the context of WikiProjects. We find that increased diversity in experience with Wikipedia increases group productivity and decreases member withdrawal - up to a point. Beyond that point, group productivity remains high, but members are more likely to withdraw. Strikingly, no such diminishing returns were observed for differences in member interest, which increases productivity and decreases member withdrawal in a linear fashion. Our results suggest that the low visibility of individual differences in online groups may allow them to harvest more of the benefits of diversity while bearing less of the cost. We discuss how our findings can inform further research of online collaboration.</span></div></div><div class="paper"><span class="title">Gender Demographic Targeting in Sponsored Search</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Bernard J. Jansen" class="author">Bernard J. Jansen</a> <a href="byAffiliation.html#The Pennsylvania State University" class="affiliation">The Pennsylvania State University</a>,<br /><a href="byAuthors.html#Lauren Solomon" class="author">Lauren Solomon</a> <a href="byAffiliation.html#The Pennsylvania State University" class="affiliation">The Pennsylvania State University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this research, we evaluate the effect of gender in analyzing the performance of sponsored search advertising. We examine a log file with data comprised of nearly 7,000,000 records spanning 33 consecutive months of a search engine marketing campaign from a major US retailer. We classify key phrases selected for the campaign with a probability of being targeted for a specific gender and then compare the consumer actions using the critical sponsored search metrics of impressions, clicks, cost-per-click, sales revenue, orders, and items sold. Findings from our analysis show that the gender-orientation of the key phrase is a significant determinant in predicting behaviors and performance, with statistically different consumer behaviors for all attributes as the probability of a male or female keyword phrase changes. However, gender neutral phrases perform the best overall, calling into question the benefits of demographic targeting. Insight from this research could result in sponsored results being more effectively targeted to searchers and potential consumers.</span></div></div><div class="paper"><span class="title">Exploring the Workplace Communication Ecology</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Thea Turner" class="author">Thea Turner</a> <a href="byAffiliation.html#FXPAL" class="affiliation">FXPAL</a>,<br /><a href="byAuthors.html#Pernilla Qvarfordt" class="author">Pernilla Qvarfordt</a> <a href="byAffiliation.html#FXPAL" class="affiliation">FXPAL</a>,<br /><a href="byAuthors.html#Jake T. Biehl" class="author">Jake T. Biehl</a> <a href="byAffiliation.html#FXPAL" class="affiliation">FXPAL</a>,<br /><a href="byAuthors.html#Gene Golovchinsky" class="author">Gene Golovchinsky</a> <a href="byAffiliation.html#FXPAL" class="affiliation">FXPAL</a>,<br /><a href="byAuthors.html#Maribeth Back" class="author">Maribeth Back</a> <a href="byAffiliation.html#FXPAL" class="affiliation">FXPAL</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The modern workplace is inherently collaborative, and this collaboration relies on effective communication among co-workers. Many communication tools - email, blogs, wikis, Twitter, etc. - have become increasingly available and accepted in workplace communications. In this paper, we report on a study of communications technologies used over a one year period in a small US corporation. We found that participants used a large number of communication tools for different purposes, and that the introduction of new tools did not impact significantly the use of previously-adopted technologies. Further, we identified distinct classes of users based on patterns of tool use. This work has implications for the design of technology in the evolving ecology of communication tools.</span></div></div></td>

<td colspan="8" class="session_details" id="S60_details"><div class="paper"><span class="title">Learning on the Job:  Characterizing the Programming Knowledge and Learning Strategies of Web Designers</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Brian Dorn" class="author">Brian Dorn</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Mark Guzdial" class="author">Mark Guzdial</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper reports on a study of professional web designers and developers.  We provide a detailed characterization of their knowledge of fundamental programming concepts elicited through card sorting.  Additionally, we present qualitative findings regarding their motivation to learn new concepts and the learning strategies they employ.  We find a high level of recognition of basic concepts, but we identify a number of concepts that they do not fully understand, consider difficult to learn, and use infrequently.  We also note that their learning process is motivated by work projects and often follows a pattern of trial and error.  We conclude with implications for end-user programming researchers.</span></div></div><div class="paper"><span class="title">A Strategy-Centric Approach to the Design of End-User Debugging Tools</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Valentina I. Grigoreanu" class="author">Valentina I. Grigoreanu</a> <a href="byAffiliation.html#Oregon State University,  Microsoft Corporation" class="affiliation">Oregon State University,  Microsoft Corporation</a>,<br /><a href="byAuthors.html#Margaret M. Burnett" class="author">Margaret M. Burnett</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#George G. Robertson" class="author">George G. Robertson</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">End-user programmers' code is notoriously buggy. This problem is amplified by the increasing complexity of end users' programs. To help end users catch errors early and reliably, we employ a novel approach for the design of end-user debugging tools: a focus on supporting end users' effective debugging strategies. This paper makes two contributions. We first demonstrate the potential of a strategy-centric approach to tool design by presenting StratCel, an add-in for Excel. Second, we show the benefits of this design approach: participants using StratCel found twice as many bugs as participants using standard Excel, they fixed four times as many bugs, and all this in only a small fraction of the time. Other contributions included: a boost in novices' debugging performance near experienced participants' improved levels, validated design guidelines, a discussion of the generalizability of this approach, and several opportunities for future research.</span></div></div><div class="paper"><span class="title">Here's What I Did: Sharing and Reusing Web Activity with ActionShot</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ian Li" class="author">Ian Li</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Jeffrey Nichols" class="author">Jeffrey Nichols</a> <a href="byAffiliation.html#IBM Research - Almaden" class="affiliation">IBM Research - Almaden</a>,<br /><a href="byAuthors.html#Tessa Lau" class="author">Tessa Lau</a> <a href="byAffiliation.html#IBM Research - Almaden" class="affiliation">IBM Research - Almaden</a>,<br /><a href="byAuthors.html#Clemens Drews" class="author">Clemens Drews</a> <a href="byAffiliation.html#IBM Research - Almaden" class="affiliation">IBM Research - Almaden</a>,<br /><a href="byAuthors.html#Allen Cypher" class="author">Allen Cypher</a> <a href="byAffiliation.html#IBM Research - Almaden" class="affiliation">IBM Research - Almaden</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">ActionShot is an integrated web browser tool that creates a fine-grained history of users' browsing activities by continually recording their browsing actions at the level of interactions, such as button clicks and entries into form fields. ActionShot provides interfaces to facilitate browsing and searching through this history, sharing portions of the history through established social networking tools such as Facebook, and creating scripts that can be used to repeat previous interactions at a later time. ActionShot can also create short textual summaries for sequences of interactions. In this paper, we describe the ActionShot and our initial explorations of the tool through field deployments within our organization and a lab study. Overall, we found that ActionShot's history features provide value beyond typical browser history interfaces.</span></div></div></td>

<td colspan="8" class="session_details" id="S62_details"><div class="paper"><span class="title">Patterns of Usage in an Enterprise File-Sharing Service: Publicizing, Discovering, and Telling the News</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Michael Muller" class="author">Michael Muller</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a>,<br /><a href="byAuthors.html#David R Millen" class="author">David R Millen</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a>,<br /><a href="byAuthors.html#Jonathan Feinberg" class="author">Jonathan Feinberg</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">How do people use an enterprise file-sharing service? We describe patterns of usage in a social file-sharing service that was deployed in a large multinational enterprise.  Factor analyses revealed four factors:  Upload &amp; Publicize (regarding one's own files); Annotate &amp; Watch (add information to files and maintain awareness); Discover &amp; Tell (find files uploaded by other users, and communicate to additional users about those files); and Refind (re-use one's own files). We explore the attributes of users who score highly on each of these factors, and we propose implications for design to encourage innovation in usage.</span></div></div><div class="paper"><span class="title">The Life and Times of Files and Information: A Study of Desktop Provenance</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Carlos Jensen" class="author">Carlos Jensen</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Heather Lonsdale" class="author">Heather Lonsdale</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Eleanor Wynn" class="author">Eleanor Wynn</a> <a href="byAffiliation.html#Intel Corporation" class="affiliation">Intel Corporation</a>,<br /><a href="byAuthors.html#Jill Cao" class="author">Jill Cao</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Michael Slater" class="author">Michael Slater</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Thomas G. Dietterich" class="author">Thomas G. Dietterich</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In the field of Human-Computer Interaction, provenance refers to the history and genealogy of a document or file.  Provenance helps us to understand the evolution and relationships of files; how and when different versions of a document were created, or how different documents in a collection build on each other through copy-paste events.  Though methods for tracking provenance and the subsequent use of this meta-data have been proposed and developed into tools, there have been no studies documenting the types and frequency of provenance events in typical computer use.  This is knowledge essential for the design of efficient query methods and information displays. We conducted a longitudinal study of knowledge workers at Intel Corporation tracking provenance events in their computer use.  We also interviewed knowledge workers to determine the effectiveness of provenance cues for document recall.  Our data shows that provenance relationships are common, and provenance cues aid recall.</span></div></div><div class="paper"><span class="title">The Effect of Audience Design on Labeling, Organizing, and Finding Shared Files</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Emilee Rader" class="author">Emilee Rader</a> <a href="byAffiliation.html#Northwestern University" class="affiliation">Northwestern University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In an online experiment, I apply theory from psychology and communications to find out whether group information management tasks are governed by the same communication processes as conversation. This paper describes results that replicate previous research, and expand our knowledge about audience design and packaging for future reuse when communication is mediated by a co-constructed artifact like a file-and-folder hierarchy. Results indicate that it is easier for information consumers to search for files in hierarchies created by information producers who imagine their intended audience to be someone similar to them, independent of whether the producer and consumer actually share common ground. This research helps us better understand packaging choices made by information producers, and the direct implications of those choices for other users of group information systems.</span></div></div><div class="paper"><span class="title">Fitting an Activity-Centric System into an Ecology of Workplace Tools</span> - <span class="type">Note</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Aruna Balakrishnan" class="author">Aruna Balakrishnan</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Tara Matthews" class="author">Tara Matthews</a> <a href="byAffiliation.html#IBM Research - Almaden" class="affiliation">IBM Research - Almaden</a>,<br /><a href="byAuthors.html#Thomas Moran" class="author">Thomas Moran</a> <a href="byAffiliation.html#IBM Research - Almaden" class="affiliation">IBM Research - Almaden</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Knowledge workers expend considerable effort managing fragmentation, characterized by constant switching among digital artifacts, when executing work activities. Activity-centric computing (ACC) systems attempt to address this problem by organizing activity-related artifacts together. But are ACC systems effective at reducing fragmentation? In this paper, we present a two-part study of workers using Lotus Activities, an ACC system deployed for over two years in a large company. First, we surveyed workers to understand the ecology of workplace tools they use for various tasks. Second, we interviewed 22 Lotus Activities users to investigate how this ACC tool fits amongst their ecology of existing collaboration tools and affects work fragmentation. Our results indicate that Lotus Activities works in concert with certain other tools to successfully ease fragmentation for a specific type of activity. We identify design characteristics that contribute to this result.</span></div></div></td>

<td colspan="8" class="session_details" id="S61_details"><div class="paper"><span class="title">Avaaj Otalo  A Field Study of an Interactive Voice Forum for Small Farmers in Rural India</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Neil Patel" class="author">Neil Patel</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Deepti Chittamuru" class="author">Deepti Chittamuru</a> <a href="byAffiliation.html#UC Berkeley School of Information" class="affiliation">UC Berkeley School of Information</a>,<br /><a href="byAuthors.html#Anupam Jain" class="author">Anupam Jain</a> <a href="byAffiliation.html#IBM India Research Laboratory" class="affiliation">IBM India Research Laboratory</a>,<br /><a href="byAuthors.html#Paresh Dave" class="author">Paresh Dave</a> <a href="byAffiliation.html#Development Support Center" class="affiliation">Development Support Center</a>,<br /><a href="byAuthors.html#Tapan S. Parikh" class="author">Tapan S. Parikh</a> <a href="byAffiliation.html#UC Berkeley School of Information" class="affiliation">UC Berkeley School of Information</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we present the results of a eld study  of Avaaj Otalo (literally, voice stoop&quot;), an interactive  voice application for small-scale farmers in Gujarat, In-  dia. Through usage data and interviews, we describe  how 51 farmers used the system over a seven month  pilot deployment. The most popular feature of Avaaj  Otalo was a forum for asking questions and browsing  others' questions and responses on a range of agricul-  tural topics. The forum developed into a lively social  space with the emergence of norms, persistent modera-  tion, and a desire for both structured interaction with  institutionally sanctioned authorities and open discus-  sion with peers. For all 51 users this was the rst ex-  perience participating in an online community of any  sort. In terms of usability, simple menu-based naviga-  tion was readily learned, with users preferring numeric  input over speech. We conclude by discussing implica-  tions of our ndings for designing voice-based social me-  dia serving rural communities in India and elsewhere.</span></div></div><div class="paper"><span class="title">An Exploratory Study of Unsupervised Mobile Learning in Rural India</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Anuj Kumar" class="author">Anuj Kumar</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Anuj Tewari" class="author">Anuj Tewari</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#Geeta Shroff" class="author">Geeta Shroff</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Deepti Chittamuru" class="author">Deepti Chittamuru</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#Matthew Kam" class="author">Matthew Kam</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#John Canny" class="author">John Canny</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Cellphones have the potential to improve education for the millions of underprivileged users in the developing world. However, mobile learning in developing countries remains under-studied. In this paper, we argue that cellphones are a perfect vehicle for making educational opportunities accessible to rural children in places and times that are more convenient than formal schooling. We carried out participant observations to identify the opportunities in their everyday lives for mobile learning. We next conducted a 26-week study to investigate the extent to which rural children will voluntarily make use of cellphones to access educational content. Our results show a reasonable level of academic learning and motivation. We also report on the social context around these results. Our goal is to examine the feasibility of mobile learning in out-of-school settings in rural, underdeveloped areas, and to help more researchers learn how to undertake similarly difficult studies around mobile computing in the developing world.</span></div></div><div class="paper"><span class="title">Where There's a Will There's a Way: Mobile Media Sharing in Urban India</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Thomas N. Smyth" class="author">Thomas N. Smyth</a> <a href="byAffiliation.html#School of Interactive Computing, Georgia Institute of Technology" class="affiliation">School of Interactive Computing, Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Satish Kumar" class="author">Satish Kumar</a> <a href="byAffiliation.html#Microsoft Research India" class="affiliation">Microsoft Research India</a>,<br /><a href="byAuthors.html#Indrani Medhi" class="author">Indrani Medhi</a> <a href="byAffiliation.html#Microsoft Research India" class="affiliation">Microsoft Research India</a>,<br /><a href="byAuthors.html#Kentaro Toyama" class="author">Kentaro Toyama</a> <a href="byAffiliation.html#School of Information, University of California, Berkeley" class="affiliation">School of Information, University of California, Berkeley</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present the results of a qualitative study of the sharing and consumption of entertainment media on low-cost mobile phones in urban India, a practice which has evolved into a vibrant, informal socio-technical ecosystem. This wide-ranging phenomenon includes end users, mobile phone shops, and content distributors, and exhibits remarkable ingenuity. Even more impressive is the number of obstacles which have been surmounted in its establishment, from the technical (interface complexity, limited Internet access, viruses), to the broader socioeconomic (cost, language, legality, institutional rules, lack of privacy), all seemingly due to a strong desire to be entertained.    Our findings carry two implications for projects in HCI seeking to employ technology in service of social and economic development. First, although great attention is paid to the details of UI in many such projects, we find that sufficient user motivation towards a goal turns UI barriers into mere speed bumps. Second, we suggest that needs assessments carry an inherent bias towards what outsiders consider needs, and that identified needs may not be as strongly felt as perceived.  </span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">11:30&nbsp;AM<br/><em>to</em><br/>1:00&nbsp;PM</td>
<td class="session" id="S67">
<span class="type">Papers/Notes</span>
<span class="title">Medical Exploration</span>
<span class="location">Centennial 1</span>
</td>
<td class="session" id="S22">
<span class="type">Panel</span>
<span class="title">Computing Technology in International Development: Who, What, Where, When, Why and How?</span>
<span class="location">Centennial 2</span>
</td>
<td class="session" id="S71">
<span class="type">Papers/Notes</span>
<span class="title">Understanding and Supporting Programming</span>
<span class="location">Centennial 3</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S70">
<span class="type">Papers/Notes</span>
<span class="title">Tagging</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S10">
<span class="type">SIG</span>
<span class="title">Branding the Changing Enterprise - Impact of Mergers &amp; Acquisitions on User Experience Organizations</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S1">
<span class="type">alt.chi</span>
<span class="title">Monsters Attack!</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S66">
<span class="type">Papers/Notes</span>
<span class="title">Gesturing and Drawing</span>
<span class="location">Hanover FG</span>
</td>
<td class="session" id="S68">
<span class="type">Papers/Notes</span>
<span class="title">Sense and Sustainability</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S65">
<span class="type">Papers/Notes</span>
<span class="title">Brains and Brawn</span>
<span class="location">Regency 6</span>
</td>
<td class="session" id="S69">
<span class="type">Papers/Notes</span>
<span class="title">Sharing Content and Searches</span>
<span class="location">Regency 7</span>
</td>
</tr>
<tr class="details_row">

<td colspan="10" class="session_details" id="S67_details"><div class="paper"><span class="title">Exploring the Accessibility and Appeal of Surface Computing for Older Adult Health Care Support</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Anne Marie Piper" class="author">Anne Marie Piper</a> <a href="byAffiliation.html#University of California, San Diego" class="affiliation">University of California, San Diego</a>,<br /><a href="byAuthors.html#Ross Campbell" class="author">Ross Campbell</a> <a href="byAffiliation.html#University of California, San Diego" class="affiliation">University of California, San Diego</a>,<br /><a href="byAuthors.html#James D. Hollan" class="author">James D. Hollan</a> <a href="byAffiliation.html#University of California, San Diego" class="affiliation">University of California, San Diego</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper examines accessibility issues of surface computing with older adults and explores the appeal of surface computing for health care support. We present results from a study involving 20 older adults (age 60 to 88) performing gesture-based interactions on a multitouch surface. Older adults were able to successfully perform all actions on the surface computer, but some gestures that required two fingers (resize) and fine motor movement (rotate) were problematic. Ratings for ease of use and ease of performing each action as well as time required to figure out an action were similar to that of younger adults. Older adults reported that the surface computer was less intimidating, less frustrating, and less overwhelming than a traditional computer. The idea of using a surface computer for health care support was well-received by participants. We conclude with a discussion of design issues involving surface computing for older adults and use of this technology for health care.</span></div></div><div class="paper"><span class="title">Patients, Pacemakers, and Implantable Defibrillators: Human Values and Security for Wireless Implantable Medical Devices</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Tamara Denning" class="author">Tamara Denning</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Alan Borning" class="author">Alan Borning</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Batya Friedman" class="author">Batya Friedman</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Brian Gill" class="author">Brian Gill</a> <a href="byAffiliation.html#Seattle Pacific University" class="affiliation">Seattle Pacific University</a>,<br /><a href="byAuthors.html#Tadayoshi Kohno" class="author">Tadayoshi Kohno</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#William H. Maisel" class="author">William H. Maisel</a> <a href="byAffiliation.html#Medical Device Safety Institute,  Beth Israel Deaconess Medical Center, and  Harvard Medical School" class="affiliation">Medical Device Safety Institute,  Beth Israel Deaconess Medical Center, and  Harvard Medical School</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Implantable medical devices (IMDs) improve patients' quality of life  and help sustain their lives. In this study, we explore patient views  and values regarding their devices to inform the design of  computer security for wireless IMDs. We interviewed 13 individuals  with implanted cardiac devices. Key questions concerned the evaluation  of 8 mockups of IMD security systems. Our results suggest that some  systems that are technically viable are nonetheless undesirable to  patients. Patients called out a number of values that affected their  attitudes towards the systems, including perceived security, safety,  freedom from unwanted cultural and historical associations, and self-image. In our analysis, we extend the  Value Sensitive Design value dams and flows technique in order to suggest multiple, complementary systems; in our  discussion, we highlight some of the usability, regulatory, and  economic complexities that arise from offering multiple options. We  conclude by offering design guidelines for future security systems for  IMDs.</span></div></div><div class="paper"><span class="title">Rehabilitation Centred Design</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Madeline Balaam" class="author">Madeline Balaam</a> <a href="byAffiliation.html#University of Sussex" class="affiliation">University of Sussex</a>,<br /><a href="byAuthors.html#Stefan Rennick Egglestone" class="author">Stefan Rennick Egglestone</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Ann-Marie Hughes" class="author">Ann-Marie Hughes</a> <a href="byAffiliation.html#University of Southampton" class="affiliation">University of Southampton</a>,<br /><a href="byAuthors.html#Thomas Nind" class="author">Thomas Nind</a> <a href="byAffiliation.html#University of Dundee" class="affiliation">University of Dundee</a>,<br /><a href="byAuthors.html#Anna Wilkinson" class="author">Anna Wilkinson</a> <a href="byAffiliation.html#Sheffield Hallam University" class="affiliation">Sheffield Hallam University</a>,<br /><a href="byAuthors.html#Eric Harris" class="author">Eric Harris</a> <a href="byAffiliation.html#University of Sussex" class="affiliation">University of Sussex</a>,<br /><a href="byAuthors.html#Lesley Axelrod" class="author">Lesley Axelrod</a> <a href="byAffiliation.html#University of Sussex" class="affiliation">University of Sussex</a>,<br /><a href="byAuthors.html#Geraldine Fitzpatrick" class="author">Geraldine Fitzpatrick</a> <a href="byAffiliation.html#Vienna Technical University" class="affiliation">Vienna Technical University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Stroke is a significant cause of disability, and is predicted to become a greater burden as population demographics shift. Research suggests that the completion of rehabilitation exercises can considerably improve function in damaged limbs, yet these exercises can be both boring and frustrating for patients to complete at home. New technologies create possibilities to support rehabilitation in motivating and entertaining ways, and, in this paper, we present a case study that illustrates the work of designing such technologies for a single user. Participation in this case study has highlighted some interesting tensions between designing for rehabilitation and designing for the user.</span></div></div></td>

<td colspan="10" class="session_details" id="S22_details"><div class="paper"><span class="title">Computing Technology in International Development: Who, What, Where, When, Why and How?</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Matthew Kam" class="author">Matthew Kam</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Susan Dray" class="author">Susan Dray</a> <a href="byAffiliation.html#Dray and Associates" class="affiliation">Dray and Associates</a>,<br /><a href="byAuthors.html#Kentaro Toyama" class="author">Kentaro Toyama</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Gary Marsden" class="author">Gary Marsden</a> <a href="byAffiliation.html#University of Cape Town" class="affiliation">University of Cape Town</a>,<br /><a href="byAuthors.html#Tapan Parikh" class="author">Tapan Parikh</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#Ed Cutrell" class="author">Ed Cutrell</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Building on the successes of prior workshops at CHI and other HCI conferences on computing in international development, we propose a panel to engage with the broader CHI community. Topics to be discussed include why international development is important to HCI as a discipline, and how CHI researchers and practitioners who are not already involved in international development can contribute.</span></div></div></td>

<td colspan="10" class="session_details" id="S71_details"><div class="paper"><span class="title">Perceptions and Practices of Usability in the Free/Open Source Software (FOSS) Community</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Michael Terry" class="author">Michael Terry</a> <a href="byAffiliation.html#University of Waterloo" class="affiliation">University of Waterloo</a>,<br /><a href="byAuthors.html#Matthew Kay" class="author">Matthew Kay</a> <a href="byAffiliation.html#University of Waterloo" class="affiliation">University of Waterloo</a>,<br /><a href="byAuthors.html#Ben Lafreniere" class="author">Ben Lafreniere</a> <a href="byAffiliation.html#University of Waterloo" class="affiliation">University of Waterloo</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper presents results from a study examining perceptions and practices of usability in the free/open source software (FOSS) community. 27 individuals associated with 11 different FOSS projects were interviewed to understand how they think about, act on, and are motivated to address usability issues. Our results indicate that FOSS project members possess rather sophisticated notions of software usability, which collectively mirror definitions commonly found in HCI textbooks. Our study also uncovered a wide range of practices that ultimately work to improve software usability. Importantly, these activities are typically based on close, direct interpersonal relationships between developers and their core users, a group of users who closely follow the project and provide high quality, respected feedback. These relationships, along with positive feedback from other users, generate social rewards that serve as the primary motivations for attending to usability issues on a day-to-day basis. These findings suggest a need to reconceptualize HCI methods to better fit this culture of practice and its corresponding value system.</span></div></div><div class="paper"><span class="title">End-User Mashup Programming: Through the Design Lens</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Jill Cao" class="author">Jill Cao</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Yann Riche" class="author">Yann Riche</a> <a href="byAffiliation.html#Riche Design" class="affiliation">Riche Design</a>,<br /><a href="byAuthors.html#Susan Wiedenbeck" class="author">Susan Wiedenbeck</a> <a href="byAffiliation.html#Drexel University" class="affiliation">Drexel University</a>,<br /><a href="byAuthors.html#Margaret Burnett" class="author">Margaret Burnett</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Valentina Grigoreanu" class="author">Valentina Grigoreanu</a> <a href="byAffiliation.html#Oregon State University, Microsoft Corporation" class="affiliation">Oregon State University, Microsoft Corporation</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Programming has recently become more common among ordinary end users of computer systems. We believe that these end-user programmers are not just coders but also designers, in that they interlace making design decisions with coding rather than treating them as two separate phases. To better understand and provide support for the programming and design needs of end users, we propose a design theory-based approach to look at end-user programming. Toward this end, we conducted a think-aloud study with ten end users creating a web mashup. By analyzing users verbal and behavioral data using Schöns reflection-in-action design model and the notion of ideations from creativity literature, we discovered insights into end-user programmers problem-solving attempts, successes, and obstacles, with accompanying implications for the design of end-user programming environments for mashups. The contribution of our work is three-fold: 1) the methodology of using a design lens to view programming, 2) evidence, through insights gained, of the usefulness of this approach, and 3) the implications themselves. </span></div></div><div class="paper"><span class="title">What Would Other Programmers Do? Suggesting Solutions to Error Messages</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Björn Hartmann" class="author">Björn Hartmann</a> <a href="byAffiliation.html#UC Berkeley" class="affiliation">UC Berkeley</a>,<br /><a href="byAuthors.html#Daniel MacDougall" class="author">Daniel MacDougall</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Joel Brandt" class="author">Joel Brandt</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Scott R. Klemmer" class="author">Scott R. Klemmer</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Interpreting compiler errors and exception messages is challenging for novice programmers. Presenting examples of how other programmers have corrected similar errors may help novices understand and correct such errors. This paper introduces HelpMeOut, a social recommender system that aids the debugging of error messages by suggesting solutions that peers have applied in the past. HelpMeOut comprises IDE instrumentation to collect examples of code changes that fix errors; a central database that stores fix reports from many users; and a suggestion interface that, given an error, queries the database for a list of relevant fixes and presents these to the programmer. We report on implementations of this architecture for two programming languages. An evaluation with novice programmers found that the technique can suggest useful fixes for 47% of errors after 39 person-hours of programming in an instrumented environment.  </span></div></div></td>

<td colspan="10" class="session_details" id="S70_details"><div class="paper"><span class="title">Cultural Difference in Image Tagging</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Wei Dong" class="author">Wei Dong</a> <a href="byAffiliation.html#University of Illinois, Urbana-Champaign" class="affiliation">University of Illinois, Urbana-Champaign</a>,<br /><a href="byAuthors.html#Wai-Tat Fu" class="author">Wai-Tat Fu</a> <a href="byAffiliation.html#University of Illinois, Urbana-Champaign" class="affiliation">University of Illinois, Urbana-Champaign</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Do people from different cultures tag digital images differently? The current study compared the content of tags for digital images created by two cultural groups: European Americans and Chinese. In line with previous findings on cultural differences in attentional patterns, we found similar cultural differences in the order of the image parts (e.g., foreground or background objects) that people tag. We found that for European Americans, the first tag was more likely assigned to the main objects than that by Chinese; but for Chinese, the first tag was more likely assigned to the overall description or relations between objects in the images. The findings had significant implications for designing cultural-sensitive tools to facilitate the tagging and search process of digital media, as well as for developing data-mining tools that identify user profiles based on their tagging patterns and cultural origins.</span></div></div><div class="paper"><span class="title">Social Tagging Revamped: Supporting the Users' Need of Self-promotion through Social Filtering</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Mauro Cherubini" class="author">Mauro Cherubini</a> <a href="byAffiliation.html#Telefónica Research" class="affiliation">Telefónica Research</a>,<br /><a href="byAuthors.html#Alejandro Gutierrez" class="author">Alejandro Gutierrez</a> <a href="byAffiliation.html#University of Illinois at Urbana-Champaign" class="affiliation">University of Illinois at Urbana-Champaign</a>,<br /><a href="byAuthors.html#Rodrigo De Oliveira" class="author">Rodrigo De Oliveira</a> <a href="byAffiliation.html#Telefónica Research" class="affiliation">Telefónica Research</a>,<br /><a href="byAuthors.html#Nuria Oliver" class="author">Nuria Oliver</a> <a href="byAffiliation.html#Telefónica Research" class="affiliation">Telefónica Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">People share pictures online to increase their social presence. However, recent studies have shown that most of the content shared in social networks is not looked at by peers. Proper metadata can be generated and used to improve the retrieval of this content. In spite of this, we still lack solutions for collecting valid descriptors of content that can be used effectively in the context of social information navigation. In this paper, we propose a mechanism based on persuasive techniques to support peers in providing metadata for multimedia content that can be used for a person's self-promotion. Through an iterative design and experimentation process, we demonstrate how this methodology can be used effectively to increase one's social presence thus building more enjoyable, rich, and creative content that is shared in the social network. In addition, we highlight implications that inform the design of social games with a purpose.</span></div></div><div class="paper"><span class="title">Some Observations on the Live Collaborative Tagging of Audio Conferences in the Enterprise</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Shreeharsh Kelkar" class="author">Shreeharsh Kelkar</a> <a href="byAffiliation.html#Avaya Labs Research" class="affiliation">Avaya Labs Research</a>,<br /><a href="byAuthors.html#Ajita John" class="author">Ajita John</a> <a href="byAffiliation.html#Avaya Labs Research" class="affiliation">Avaya Labs Research</a>,<br /><a href="byAuthors.html#Doree Duncan Seligmann" class="author">Doree Duncan Seligmann</a> <a href="byAffiliation.html#Avaya Labs Research" class="affiliation">Avaya Labs Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper describes preliminary findings related to a system for live collaborative tagging of enterprise meetings taking place on an audio bridge between distributed participants.  Participants can apply tags to different points of the interaction as it is ongoing and can see, in near real-time, the flow of tags as they are being contributed.  Two novel types of tags are proposed: deep tags that apply to a portion of the interaction and instant tags that apply to an instant of the interaction.  Our system is being used by enterprise users and we analyze a corpus of 737 live-tags collected from 16 conversations that took place over several months.  We found that the live-tags for audio have slightly different characteristics from Web 2.0 tags: they are longer and confer affordances on the audio like description and summarization.  Some observations on the cognitive cost of live-tagging are offered.    </span></div></div><div class="paper"><span class="title">Best of Both Worlds: Improving Gmail Labels with the Affordances of Folders</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kerry Rodden" class="author">Kerry Rodden</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a>,<br /><a href="byAuthors.html#Michael Leggett" class="author">Michael Leggett</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Gmails filing system for email conversations is based around labels, which are more flexible and powerful than folders. With its original user interface, many users did not discover labels, and wondered why Gmail had no folders. The Gmail team redesigned the user interface for labeling to make it more discoverable and understandable, and to add the most useful functionality of folders. The new design works for the simple use case (a conversation with only one label), while still making the more complex use case (multiple labels) easily available. It has been launched to millions of users worldwide and has resulted in much higher adoption of labels, especially by new users of Gmail.</span></div></div></td>

<td colspan="10" class="session_details" id="S10_details"><div class="paper"><span class="title">SIG: Branding the Changing Enterprise - Impact of Mergers &amp; Acquisitions on User Experience Organizations</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Janaki Kumar" class="author">Janaki Kumar</a> <a href="byAffiliation.html#SAP Labs, LLC" class="affiliation">SAP Labs, LLC</a>,<br /><a href="byAuthors.html#Dan Rosenberg" class="author">Dan Rosenberg</a> <a href="byAffiliation.html#SAP Labs, LLC" class="affiliation">SAP Labs, LLC</a>,<br /><a href="byAuthors.html#Michael Arent" class="author">Michael Arent</a> <a href="byAffiliation.html#SAP Business Objects  SAP Labs, LLC" class="affiliation">SAP Business Objects  SAP Labs, LLC</a>,<br /><a href="byAuthors.html#Anna Wichansky" class="author">Anna Wichansky</a> <a href="byAffiliation.html#Oracle" class="affiliation">Oracle</a>,<br /><a href="byAuthors.html#Madhuri Kolhathar" class="author">Madhuri Kolhathar</a> <a href="byAffiliation.html#Oracle" class="affiliation">Oracle</a>,<br /><a href="byAuthors.html#Roman Longoria" class="author">Roman Longoria</a> <a href="byAffiliation.html#CA" class="affiliation">CA</a>,<br /><a href="byAuthors.html#Bob Hendrich" class="author">Bob Hendrich</a> <a href="byAffiliation.html#CA" class="affiliation">CA</a>,<br /><a href="byAuthors.html#Arnie Lund" class="author">Arnie Lund</a> <a href="byAffiliation.html#Mircosoft Corporation" class="affiliation">Mircosoft Corporation</a></div></div></td>

<td colspan="10" class="session_details" id="S1_details"><div class="paper"><span class="title">Sequential Art for Science and CHI</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Duncan Rowland" class="author">Duncan Rowland</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Dan Porter" class="author">Dan Porter</a> <a href="byAffiliation.html#Giant Thumb" class="affiliation">Giant Thumb</a>,<br /><a href="byAuthors.html#Mel Gibson" class="author">Mel Gibson</a> <a href="byAffiliation.html#Northumbria University" class="affiliation">Northumbria University</a>,<br /><a href="byAuthors.html#Kevin Walker" class="author">Kevin Walker</a> <a href="byAffiliation.html#Knowledge Lab" class="affiliation">Knowledge Lab</a>,<br /><a href="byAuthors.html#Joshua Underwood" class="author">Joshua Underwood</a> <a href="byAffiliation.html#Knowledge Lab" class="affiliation">Knowledge Lab</a>,<br /><a href="byAuthors.html#Rose Luckin" class="author">Rose Luckin</a> <a href="byAffiliation.html#Knowledge Lab" class="affiliation">Knowledge Lab</a>,<br /><a href="byAuthors.html#Hillary Smith" class="author">Hillary Smith</a> <a href="byAffiliation.html#University of Sussex" class="affiliation">University of Sussex</a>,<br /><a href="byAuthors.html#Geraldine Fitzpatrick" class="author">Geraldine Fitzpatrick</a> <a href="byAffiliation.html#University of Sussex" class="affiliation">University of Sussex</a>,<br /><a href="byAuthors.html#Brendan Walker" class="author">Brendan Walker</a> <a href="byAffiliation.html#Aerial UK" class="affiliation">Aerial UK</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper illustrates our preliminary studies of new interactive tools that support the generation of sequential art for entertainment, learning and scientific discourse. In the first of two examples, primary school students document a practical science session through the creation of a photostory. In the second, participants in a study on the biological nature of thrill create a souvenir photostory by selecting images from a DVD. The paper is written in a comic-book format to further explore and highlight the communicative capabilities of the medium, one that can be visually attractive and facilitate rapid dissemination to a wide audience.</span></div></div><div class="paper"><span class="title">Early Explorations of CAT: Canine Amusement and Training</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Chadwick A. Wingrave" class="author">Chadwick A. Wingrave</a> <a href="byAffiliation.html#University of Central Florida" class="affiliation">University of Central Florida</a>,<br /><a href="byAuthors.html#Jeremy Rose" class="author">Jeremy Rose</a> <a href="byAffiliation.html#University of Central Florida" class="affiliation">University of Central Florida</a>,<br /><a href="byAuthors.html#Todd Langston" class="author">Todd Langston</a> <a href="byAffiliation.html#Pack Life K-9 Behavior Solutions" class="affiliation">Pack Life K-9 Behavior Solutions</a>,<br /><a href="byAuthors.html#Joseph J. LaViola Jr" class="author">Joseph J. LaViola Jr</a> <a href="byAffiliation.html#University of Central Florida" class="affiliation">University of Central Florida</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Cross-species computer applications have a history of blended science and humor, despite the real potential for improving the canine-human bond. New activities available to humans in the electronic age can be used to improve this bond. By using a serious games approach, this project motivates the human to spend time with their canine in healthy and informative ways. An iterative design process, with a canine behavior expert, has produced a prototype focused on calm, healthy and enjoyable games for both canine and human. Formative results and guidelines are reported, as are current and future directions.</span></div></div><div class="paper"><span class="title">The Coffee Lab: Developing a public usability space</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Maria Karam" class="author">Maria Karam</a> <a href="byAffiliation.html#Ryerson University" class="affiliation">Ryerson University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Introducing the Coffee Lab: a novel concept for conducting usability studies in a public space where anyone can experience and evaluate research novel interactive systems. The Coffee Lab serves as a model for the public usability lab, which extends the methods common to laboratory-based usability experiments by adapting prototypes, usability methods, and task interactions to suit different scenarios. Details on the design and implementation of public evaluation methods are discussed, along with a description of the Coffee Lab, and two ongoing public usability tests.  </span></div></div><div class="paper"><span class="title">Augmented Reality - Surface Syle</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Paul Hoover" class="author">Paul Hoover</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a>,<br /><a href="byAuthors.html#Luis E. Cabrera" class="author">Luis E. Cabrera</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Most displays can show information only on a planar surface. In some cases it is advantageous to extend the display into the third dimension or inside objects on the surface. For instance, a person on one side of an interactive table might want to read a message displayed privately to themselves. This paper describes a novel use of fiber optics to take the light from a planar surface and extend it to display into the third dimension, both vertically and in any direction that the fiber optic is bent.</span></div></div><div class="paper"><span class="title">Theres a Monster in my Kitchen: Using Aversive Feedback to Motivate Behaviour Change</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ben Kirman" class="author">Ben Kirman</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Conor Linehan" class="author">Conor Linehan</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Shaun Lawson" class="author">Shaun Lawson</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Derek Foster" class="author">Derek Foster</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Mark Doughty" class="author">Mark Doughty</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we argue that persuasive technologies, developed to motivate behaviour change in users, have so far failed to exploit the established body of empirical research within behavioural science. We propose that persuasive technologies may benefit from both adapting to individual preferences, and a constructive use of aversive, in addition to appetitive, feedback. We detail an example application that demonstrates how this approach can be incorporated into an application designed to train users to adopt more environmentally friendly behaviours in their domestic kitchens. </span></div></div><div class="paper"><span class="title">Blowtooth: Pervasive Gaming in Unique and Challenging Environments</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Conor Linehan" class="author">Conor Linehan</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Ben Kirman" class="author">Ben Kirman</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Shaun Lawson" class="author">Shaun Lawson</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Mark Doughty" class="author">Mark Doughty</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper describes Blowtooth, a Bluetooth-implemented pervasive game where players smuggle virtual drugs through real airport security with the help of unknowing bystanders. The game explores the nature of pervasive game playing in environments that are not generally regarded as playful or fun, and where people are subject to particularly high levels of intrusive surveillance and monitoring. Six participants who were travelling internationally within a two-week period were recruited to evaluate the game. Findings suggest that creating pervasive games that incorporate the unique features of their context as part of the game may provide enjoyable, novel and thought-provoking experiences for players.  </span></div></div></td>

<td colspan="10" class="session_details" id="S66_details"><div class="paper"><span class="title">Scale Detection for a priori Gesture Recognition</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Caroline Appert" class="author">Caroline Appert</a> <a href="byAffiliation.html#Universite Paris-Sud, CNRS" class="affiliation">Universite Paris-Sud, CNRS</a>,<br /><a href="byAuthors.html#Olivier Bau" class="author">Olivier Bau</a> <a href="byAffiliation.html#Universite Paris-Sud, INRIA" class="affiliation">Universite Paris-Sud, INRIA</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Gesture-based interfaces provide expert users with an efficient form of interaction but they require a learning effort for novice users. To address this problem, some on-line guiding techniques display all available gestures in response to partial input. However, partial input recognition algorithms are scale dependent while most gesture recognizers support scale independence (i.e., the same shape at different scales actually invokes the same command). We propose an algorithm for estimating the scale of any partial input in the context of a gesture recognition system and illustrate how it can be used to improve users' experience with gesture-based systems.</span></div></div><div class="paper"><span class="title">Insight into Goal-Directed Movement Strategies</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Karin Nieuwenhuizen" class="author">Karin Nieuwenhuizen</a> <a href="byAffiliation.html#Eindhoven University of Technology" class="affiliation">Eindhoven University of Technology</a>,<br /><a href="byAuthors.html#Dzmitry Aliakseyeu" class="author">Dzmitry Aliakseyeu</a> <a href="byAffiliation.html#Philips Research Eindhoven" class="affiliation">Philips Research Eindhoven</a>,<br /><a href="byAuthors.html#Jean-Bernard Martens" class="author">Jean-Bernard Martens</a> <a href="byAffiliation.html#Eindhoven University of Technology" class="affiliation">Eindhoven University of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The current paper proposes a novel method of analyzing goal-directed movements by dividing them into distinct movement intervals. We demonstrate how the description of the first and second most prominent movement intervals in terms of duration and length can provide insight into the applied movement strategies under different conditions. This method, although demonstrated for goal-directed movements, has the potential to be generalized to other types of movements, such as steering movements.</span></div></div><div class="paper"><span class="title">Usable Gestures for Mobile Interfaces:  Evaluating Social Acceptability</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Julie Rico" class="author">Julie Rico</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Stephen Brewster" class="author">Stephen Brewster</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Gesture-based mobile interfaces require users to change the way they use technology in public settings.  Since mobile phones are part of our public appearance, designers must integrate gestures that users perceive as acceptable for public use.  This topic has received little attention in the literature so far.  The studies described in this paper begin to look at the social acceptability of a set of gestures with respect to location and audience in order to investigate possible ways of measuring social acceptability.  The results of the initial survey showed that location and audience had a significant impact on a user's willingness to perform gestures.  These results were further examined through a user study where participants were asked to perform gestures in different settings (including a busy street) over repeated trials.  The results of this work provide gesture design recommendations as well as social acceptability evaluation guidelines.</span></div></div><div class="paper"><span class="title">iCanDraw? - Using Sketch Recognition and Corrective Feedback to Assist a User in Drawing Human Faces</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Daniel Dixon" class="author">Daniel Dixon</a> <a href="byAffiliation.html#Texas A&amp;M University" class="affiliation">Texas A&amp;M University</a>,<br /><a href="byAuthors.html#Manoj Prasad" class="author">Manoj Prasad</a> <a href="byAffiliation.html#Texas A&amp;M University" class="affiliation">Texas A&amp;M University</a>,<br /><a href="byAuthors.html#Tracy Hammond" class="author">Tracy Hammond</a> <a href="byAffiliation.html#Texas A&amp;M University" class="affiliation">Texas A&amp;M University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">When asked to draw, many people are hesitant because they consider themselves unable to draw well.  This paper describes the first system for a computer to provide direction and feedback for assisting a user to draw a human face as accurately as possible from an image.  Face recognition is first used to model the features of a human face in an image, which the user wishes to replicate.  Novel sketch recognition algorithms were developed to use the information provided by the face recognition to evaluate the hand-drawn face.  Two design iterations and user studies led to nine design principles for providing such instruction, presenting reference media, giving corrective feedback, and receiving actions from the user.  The result is a proof-of-concept application that can guide a person through step-by-step instruction and generated feedback toward producing his/her own sketch of a human face in a reference image.</span></div></div></td>

<td colspan="10" class="session_details" id="S68_details"><div class="paper"><span class="title">One Size Does Not Fit All: Applying the Transtheoretical Model to Energy Feedback Technology Design</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Helen Ai He" class="author">Helen Ai He</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a>,<br /><a href="byAuthors.html#Saul Greenberg" class="author">Saul Greenberg</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a>,<br /><a href="byAuthors.html#Elaine M. Huang" class="author">Elaine M. Huang</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Global warming, and the climate change it induces, is an urgent global issue. One remedy to this problem, and the focus of this paper, is to motivate sustainable energy usage behaviors by people. One approach is the development of technologies that provide real-time, continuous feedback of energy usage. However, there is one problem - most tech-nologies use a one-size-fits-all solution, providing the same feedback to differently motivated individuals at dif-ferent stages of readiness, willingness and ableness to change. In this paper, we synthesize a wide range of moti-vational psychology literature to develop a motivational framework based on the Transtheoretical (aka Stages of Behavior Change) Model. For each stage, we state the mo-tivational goal(s), and recommendation(s) for how technol-ogies can reach these goals. Each goal and recommendation is supported by a rationale based on motivational literature. Each recommendation is supported by a simple textual example illustrating one way to apply the recommendation. </span></div></div><div class="paper"><span class="title">Small Business Applications of Sourcemap: A Web Tool for Sustainable Design and Supply Chain Transparency</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Leonardo Bonanni" class="author">Leonardo Bonanni</a> <a href="byAffiliation.html#MIT Media Laboratory" class="affiliation">MIT Media Laboratory</a>,<br /><a href="byAuthors.html#Matthew Hockenberry" class="author">Matthew Hockenberry</a> <a href="byAffiliation.html#MIT Center for Future Civic Media" class="affiliation">MIT Center for Future Civic Media</a>,<br /><a href="byAuthors.html#David Zwarg" class="author">David Zwarg</a> <a href="byAffiliation.html#Avencia Inc." class="affiliation">Avencia Inc.</a>,<br /><a href="byAuthors.html#Chris Csikszentmihályi" class="author">Chris Csikszentmihályi</a> <a href="byAffiliation.html#MIT Center for Future Civic Media" class="affiliation">MIT Center for Future Civic Media</a>,<br /><a href="byAuthors.html#Hiroshi Ishii" class="author">Hiroshi Ishii</a> <a href="byAffiliation.html#MIT Media Laboratory" class="affiliation">MIT Media Laboratory</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper introduces sustainable design applications for small businesses through the Life Cycle Assessment and supply chain publishing platform Sourcemap.org. This web-based tool was developed through a year-long participatory design process with five small businesses in Scotland and in New England. Sourcemap was used as a diagnostic tool for carbon accounting, design and supply chain management. It offers a number of ways to market sustainable practices through embedded and printed visualizations. Our experiences confirm the potential of web sustainability tools and social media to expand the discourse and to negotiate the diverse goals inherent in social and environmental sustainability.</span></div></div><div class="paper"><span class="title">FeedWinnower: Layering Structures Over Collections of  Information Streams</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Lichan Hong" class="author">Lichan Hong</a> <a href="byAffiliation.html#Palo Alto Research Center (PARC)" class="affiliation">Palo Alto Research Center (PARC)</a>,<br /><a href="byAuthors.html#Gregorio Convertino" class="author">Gregorio Convertino</a> <a href="byAffiliation.html#Palo Alto Research Center (PARC)" class="affiliation">Palo Alto Research Center (PARC)</a>,<br /><a href="byAuthors.html#Bongwon Suh" class="author">Bongwon Suh</a> <a href="byAffiliation.html#Palo Alto Research Center (PARC)" class="affiliation">Palo Alto Research Center (PARC)</a>,<br /><a href="byAuthors.html#Ed H. Chi" class="author">Ed H. Chi</a> <a href="byAffiliation.html#Palo Alto Research Center (PARC)" class="affiliation">Palo Alto Research Center (PARC)</a>,<br /><a href="byAuthors.html#Sanjay Kairam" class="author">Sanjay Kairam</a> <a href="byAffiliation.html#Palo Alto Research Center (PARC)" class="affiliation">Palo Alto Research Center (PARC)</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Information overload is a growing threat to the productivity of today's knowledge workers, who need to keep track of multiple streams of information from various sources. RSS feed readers are a popular choice for syndicating information streams, but current tools tend to contribute to the overload problem instead of solving it. We introduce FeedWinnower, an enhanced feed aggregator that helps readers to filter feed items by four facets (topic, people, source, and time), thus facilitating feed triage. The combination of the four facets provides a powerful way for users to slice and dice their personal feeds. In addition, we present a formative evaluation of the prototype conducted with 15 knowledge workers in two different organizations</span></div></div></td>

<td colspan="10" class="session_details" id="S65_details"><div class="paper"><span class="title">Making Muscle-Computer Interfaces More Practical</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#T. Scott Saponas" class="author">T. Scott Saponas</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Desney S. Tan" class="author">Desney S. Tan</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Dan Morris" class="author">Dan Morris</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Jim Turner" class="author">Jim Turner</a> <a href="byAffiliation.html#Microsoft Corporation" class="affiliation">Microsoft Corporation</a>,<br /><a href="byAuthors.html#James A. Landay" class="author">James A. Landay</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Recent work in muscle sensing has demonstrated the poten-tial of human-computer interfaces based on finger gestures sensed from electrodes on the upper forearm. While this approach holds much potential, previous work has given little attention to sensing finger gestures in the context of three important real-world requirements: sensing hardware suitable for mobile and off-desktop environments, elec-trodes that can be put on quickly without adhesives or gel, and gesture recognition techniques that require no new training or calibration after re-donning a muscle-sensing armband. In this note, we describe our approach to over-coming these challenges, and we demonstrate average clas-sification accuracies as high as 86% for pinching with one of three fingers in a two-session, eight-person experiment.</span></div></div><div class="paper"><span class="title">A Novel Brain-Computer Interface Using a Multi-Touch Surface</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Beste F. Yuksel" class="author">Beste F. Yuksel</a> <a href="byAffiliation.html#University College London" class="affiliation">University College London</a>,<br /><a href="byAuthors.html#Michael Donnerer" class="author">Michael Donnerer</a> <a href="byAffiliation.html#University College London" class="affiliation">University College London</a>,<br /><a href="byAuthors.html#James Tompkin" class="author">James Tompkin</a> <a href="byAffiliation.html#University College London" class="affiliation">University College London</a>,<br /><a href="byAuthors.html#Anthony Steed" class="author">Anthony Steed</a> <a href="byAffiliation.html#University College London" class="affiliation">University College London</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present a novel integration of a brain-computer interface (BCI) with a multi-touch surface. BCIs based on the P300 paradigm often use a visual stimulus of a flashing character to elicit an event related potential in the brain's EEG signal. Traditionally, P300-based BCI paradigms use a grid layout of visual targets, commonly an alphabet, and allow users to select targets using their thoughts. In our new system a multi-touch table senses objects placed upon its surface and the system can highlight the objects on the table by flashing an area of light around them. This allows us to construct a P300-based BCI that uses a user-assembled collection of objects as targets, rather than a pre-determined grid layout. An experiment shows that our new paradigm works just as well as the traditional paradigms, thus highlighting the potential for BCIs to be integrated in a broader range of situations.  </span></div></div><div class="paper"><span class="title">The Influence of Implicit and Explicit Biofeedback in First-Person Shooter Games</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kai Kuikkaniemi" class="author">Kai Kuikkaniemi</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology" class="affiliation">Helsinki Institute for Information Technology</a>,<br /><a href="byAuthors.html#Toni Laitinen" class="author">Toni Laitinen</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology" class="affiliation">Helsinki Institute for Information Technology</a>,<br /><a href="byAuthors.html#Marko Turpeinen" class="author">Marko Turpeinen</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology" class="affiliation">Helsinki Institute for Information Technology</a>,<br /><a href="byAuthors.html#Timo Saari" class="author">Timo Saari</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology" class="affiliation">Helsinki Institute for Information Technology</a>,<br /><a href="byAuthors.html#Ilkka Kosunen" class="author">Ilkka Kosunen</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology" class="affiliation">Helsinki Institute for Information Technology</a>,<br /><a href="byAuthors.html#Niklas Ravaja" class="author">Niklas Ravaja</a> <a href="byAffiliation.html#Center for Knowledge and Innovation Research" class="affiliation">Center for Knowledge and Innovation Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">To understand how implicit and explicit biofeedback work in games, we developed a first-person shooter (FPS) game to experiment with different biofeedback techniques. While this area has seen plenty of discussion, there is little rigorous experimentation addressing how biofeedback can enhance human-computer interaction. In our two-part study, (N=36) subjects first played eight different game stages with two implicit biofeedback conditions, with two simulation-based comparison and repetition rounds, then repeated the two biofeedback stages when given explicit information on the biofeedback. The biofeedback conditions were respiration and skin-conductance (EDA) adaptations. Adaptation targets were four balanced player avatar attributes. We collected data with psycho¬physiological measures (electromyography, respiration, and EDA), a game experience questionnaire, and game-play measures.    According to our experiment, implicit biofeedback does not produce significant effects in player experience in an FPS game. In the explicit biofeedback conditions, players were more immersed and positively affected, and they were able to manipulate the game play with the biosignal interface. We recommend exploring the possibilities of using explicit biofeedback interaction in commercial games.    </span></div></div><div class="paper"><span class="title">Effects of Interactivity and 3D-motion on Mental Rotation Brain Activity in an Immersive Virtual Environment</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Daniel Sjölie" class="author">Daniel Sjölie</a> <a href="byAffiliation.html#Umeå University" class="affiliation">Umeå University</a>,<br /><a href="byAuthors.html#Kenneth Bodin" class="author">Kenneth Bodin</a> <a href="byAffiliation.html#Umeå University" class="affiliation">Umeå University</a>,<br /><a href="byAuthors.html#Eva Elgh" class="author">Eva Elgh</a> <a href="byAffiliation.html#Umeå University" class="affiliation">Umeå University</a>,<br /><a href="byAuthors.html#Johan Eriksson" class="author">Johan Eriksson</a> <a href="byAffiliation.html#Umeå University" class="affiliation">Umeå University</a>,<br /><a href="byAuthors.html#Lars-Erik Janlert" class="author">Lars-Erik Janlert</a> <a href="byAffiliation.html#Umeå University" class="affiliation">Umeå University</a>,<br /><a href="byAuthors.html#Lars Nyberg" class="author">Lars Nyberg</a> <a href="byAffiliation.html#Umeå University" class="affiliation">Umeå University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The combination of virtual reality (VR) and brain measurements is a promising development of HCI, but the maturation of this paradigm requires more knowledge about how brain activity is influenced by parameters of VR applications. To this end we investigate the influence of two prominent VR parameters, 3d-motion and interactivity, while brain activity is measured for a mental rotation task, using functional MRI (fMRI). A mental rotation network of brain areas is identified, matching previous results. The addition of interactivity increases the activation in core areas of this network, with more profound effects in frontal and preparatory motor areas. The increases from 3d-motion are restricted to primarily visual areas. We relate these effects to emerging theories of cognition and potential applications for brain-computer interfaces (BCIs). Our results demonstrate one way to provoke increased activity in task-relevant areas, making it easier to detect and use for adaptation and development of HCI.</span></div></div></td>

<td colspan="10" class="session_details" id="S69_details"><div class="paper"><span class="title">Tools-at-Hand and Learning in Multi-Session, Collaborative Search</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Robert Capra" class="author">Robert Capra</a> <a href="byAffiliation.html#University of North Carolina" class="affiliation">University of North Carolina</a>,<br /><a href="byAuthors.html#Gary Marchionini" class="author">Gary Marchionini</a> <a href="byAffiliation.html#University of North Carolina" class="affiliation">University of North Carolina</a>,<br /><a href="byAuthors.html#Javier Velasco-Martin" class="author">Javier Velasco-Martin</a> <a href="byAffiliation.html#University of North Carolina" class="affiliation">University of North Carolina</a>,<br /><a href="byAuthors.html#Katrina Muller" class="author">Katrina Muller</a> <a href="byAffiliation.html#University of North Carolina" class="affiliation">University of North Carolina</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Improving search interfaces and algorithms are major foci of HCI and information retrieval (IR) research respectively.  However, less attention has been given to understanding how users collect, manage, organize, and share the results they find from conducting searches on the Web and designing tools to support their needs.  In this paper, we present results from a study in which we interviewed 30 people in three cohorts (academic researchers, corporate workers, and people looking for medical information) about their current practices conducting, managing, and sharing information from on-going, exploratory searches.  We report results on users' current practices, tool use, areas of difficulties and associated coping strategies with emphasis on how information seekers use a variety of tools-at-hand beyond search engines and web browsers as they search, process, and share results, and on the learning processes that occur as they seek and use information over time.</span></div></div><div class="paper"><span class="title">Share: A programming environment for loosely bound cooperation</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Yannick Assogba" class="author">Yannick Assogba</a> <a href="byAffiliation.html#MIT Media Lab" class="affiliation">MIT Media Lab</a>,<br /><a href="byAuthors.html#Judith Donath" class="author">Judith Donath</a> <a href="byAffiliation.html#Harvard University Berkman Center" class="affiliation">Harvard University Berkman Center</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We introduce a programming environment entitled Share that is designed to encourage loosely bound cooperation between individuals within communities of practice through the sharing of code. Loosely bound cooperation refers to the opportunity community members have to assist and share resources with one another while maintaining their autonomy and independent practice. We contrast this model with forms of collaboration that enable large numbers of distributed individuals to collaborate on large scale works where they are guided by a shared vision of what they are collectively trying to achieve. We hypothesize that providing fine-grained, publicly visible attribution of code sharing activity within a community can provide socially motivated encouragement for code sharing. We present an overview of the design of our tool and the objectives that guided its design and a discussion of a small-scale deployment of our prototype among members of a particular community of practice.</span></div></div><div class="paper"><span class="title">Enhancing Directed Content Sharing on the Web</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Michael S. Bernstein" class="author">Michael S. Bernstein</a> <a href="byAffiliation.html#MIT CSAIL" class="affiliation">MIT CSAIL</a>,<br /><a href="byAuthors.html#Adam Marcus" class="author">Adam Marcus</a> <a href="byAffiliation.html#MIT CSAIL" class="affiliation">MIT CSAIL</a>,<br /><a href="byAuthors.html#David R. Karger" class="author">David R. Karger</a> <a href="byAffiliation.html#MIT CSAIL" class="affiliation">MIT CSAIL</a>,<br /><a href="byAuthors.html#Robert C. Miller" class="author">Robert C. Miller</a> <a href="byAffiliation.html#MIT CSAIL" class="affiliation">MIT CSAIL</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">To find interesting, personally relevant web content, people rely on friends and colleagues to pass links along as they encounter them. In this paper, we study and augment link-sharing via e-mail, the most popular means of sharing web content today. Armed with survey data indicating that active sharers of novel web content are often those that actively seek it out, we developed FeedMe, a plug-in for Google Reader that makes directed sharing of content a more salient part of the user experience. FeedMe recommends friends who may be interested in seeing content that the user is viewing, provides information on what the recipient has seen and how many emails they have received recently, and gives recipients the opportunity to provide lightweight feedback when they appreciate shared content. FeedMe introduces a novel design space within mixed-initiative social recommenders: friends who know the user voluntarily vet the material on the user's behalf. We performed a two-week field experiment (N=60) and found that FeedMe made it easier and more enjoyable to share content that recipients appreciated and would not have found otherwise.</span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">2:30&nbsp;PM<br/><em>to</em><br/>4:00&nbsp;PM</td>
<td class="session" id="S29">
<span class="type">ToCHI</span>
<span class="title">User Interface Description Languages for Next Generation User Interfaces</span>
<span class="location"></span>
</td>
<td class="session" id="S74">
<span class="type">Papers/Notes</span>
<span class="title">Input, Security, and Privacy Policies</span>
<span class="location">Centennial 1</span>
</td>
<td class="session" id="S78">
<span class="type">Papers/Notes</span>
<span class="title">Software and Methods</span>
<span class="location">Centennial 2</span>
</td>
<td class="session" id="S76">
<span class="type">Papers/Notes</span>
<span class="title">Tangible UI</span>
<span class="location">Centennial 3</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S73">
<span class="type">Papers/Notes</span>
<span class="title">Crisis Informatics</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S11">
<span class="type">SIG</span>
<span class="title">CHI 2010 Engineering Community SIG: the role of engineering work in CHI</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S2">
<span class="type">alt.chi</span>
<span class="title">alt.ernative Methods</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S72">
<span class="type">Papers/Notes</span>
<span class="title">Avatars and Virtual Environments</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S75">
<span class="type">Papers/Notes</span>
<span class="title">Seniors Using Technologies</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S77">
<span class="type">Papers/Notes</span>
<span class="title">Understanding Comments</span>
<span class="location">Regency 7</span>
</td>
</tr>
<tr class="details_row">

<td colspan="10" class="session_details" id="S29_details"><div class="paper"><span class="title">A Specification Paradigm for the Design and Implementation of Tangible User Interfaces</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Orit Shaer" class="author">Orit Shaer</a> <a href="byAffiliation.html#Wellesley College" class="affiliation">Wellesley College</a>,<br /><a href="byAuthors.html#Robert J.K. Jacob" class="author">Robert J.K. Jacob</a> <a href="byAffiliation.html#Tufts University" class="affiliation">Tufts University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Tangible interaction shows promise to significantly enhance computer-mediated activities. However, Tangible User Interfaces (TUIs) are currently considered challenging to design and build. To address TUI development challenges, we propose a specification paradigm, that enables developers to specify the structure and behavior of a TUI using high-level constructs. These specifications could be automatically converted into concrete implementations while serving as a common ground for TUI developers from different disciplines. This paper contributes a visual specification language for TUIs, an XML-compliant language, and a proof-of-concept prototype that semi-automatically translates TUI specifications into concrete implementations.</span></div></div><div class="paper"><span class="title">ICOs: a Model-Based User Interface Description Technique for Interactive Systems Engineering</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#David Navarre" class="author">David Navarre</a> <a href="byAffiliation.html#IHCS-IRIT, Université Paul Sabatier - Toulouse 3" class="affiliation">IHCS-IRIT, Université Paul Sabatier - Toulouse 3</a>,<br /><a href="byAuthors.html#Philippe Palanque" class="author">Philippe Palanque</a> <a href="byAffiliation.html#IHCS-IRIT, Université Paul Sabatier - Toulouse 3" class="affiliation">IHCS-IRIT, Université Paul Sabatier - Toulouse 3</a>,<br /><a href="byAuthors.html#Jean-Francois Ladry" class="author">Jean-Francois Ladry</a> <a href="byAffiliation.html#IHCS-IRIT, Université Paul Sabatier - Toulouse 3" class="affiliation">IHCS-IRIT, Université Paul Sabatier - Toulouse 3</a>,<br /><a href="byAuthors.html#Eric Barboni" class="author">Eric Barboni</a> <a href="byAffiliation.html#IHCS-IRIT, Université Paul Sabatier - Toulouse 3" class="affiliation">IHCS-IRIT, Université Paul Sabatier - Toulouse 3</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The design of interactive systems calls for advanced software engineering models, methods and tools in order to go beyond usability and meet reliability requirements. Conventional empirical or semi-formal techniques, although very fruitful, do not provide sufficient insight on the reliability of the human-system cooperation. The aim of this paper is to present a user interface description language for the engineering and development of usable and reliable user interfaces for various types of applications. The CASE tool supporting the ICOs notation (called Petshop) is a Petri nets based tool for the design, specification, prototyping and validation of interactive software.</span></div></div><div class="paper"><span class="title">MARIA: A Universal Language for Service-Oriented Applications in Ubiquitous Environments</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Fabio Paternò" class="author">Fabio Paternò</a> <a href="byAffiliation.html#ISTI-CNR" class="affiliation">ISTI-CNR</a>,<br /><a href="byAuthors.html#Carmen Santoro" class="author">Carmen Santoro</a> <a href="byAffiliation.html#ISTI-CNR" class="affiliation">ISTI-CNR</a>,<br /><a href="byAuthors.html#Lucio Davide Spano" class="author">Lucio Davide Spano</a> <a href="byAffiliation.html#ISTI-CNR" class="affiliation">ISTI-CNR</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">One important evolution in software applications is the spread of service-oriented architectures in ubiquitous environments. Such environments are characterized by a wide set of interactive devices, with interactive applications that exploit a number of functionalities developed beforehand and encapsulated in Web services. In this paper, we discuss how a novel model-based UIDL can provide useful support both at design and run time for these types of applications. At run-time the language is exploited to support dynamic generation of user interfaces adapted to the different devices at hand during the user interface migration process. </span></div></div><div class="paper"><span class="title">A Natural, Tiered and Executable UIDL for 3D User Interfaces Based On Concept-Oriented Design</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Chadwick Wingrave" class="author">Chadwick Wingrave</a> <a href="byAffiliation.html#UCF" class="affiliation">UCF</a>,<br /><a href="byAuthors.html#Joseph J. LaViola Jr." class="author">Joseph J. LaViola Jr.</a> <a href="byAffiliation.html#UCF" class="affiliation">UCF</a>,<br /><a href="byAuthors.html#Doug A. Bowman" class="author">Doug A. Bowman</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">3D user interface (3DUI) design and development requires practitioners (designers and developers) to represent their ideas in representations designed for machine execution rather than natural representations, hampering development of effective 3DUIs. As such, Concept-Oriented Design (COD) was created as a theory of software development for both natural and executable design and development. Instantiated in the toolkit Chasm, Chasm is a natural, tiered, executable User Interface Description Language (UIDL) for 3DUIs resulting in improved understandability, reduced complexity and reuse. Chasms utility is shown through evaluations by domain experts, case studies of long-term use and an analysis of spaces.</span></div></div></td>

<td colspan="10" class="session_details" id="S74_details"><div class="paper"><span class="title">The Secure Haptic Keypad: A Tactile Password System</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Andrea Bianchi" class="author">Andrea Bianchi</a> <a href="byAffiliation.html#Korean Advanced Institute of Science and Technology" class="affiliation">Korean Advanced Institute of Science and Technology</a>,<br /><a href="byAuthors.html#Ian Oakley" class="author">Ian Oakley</a> <a href="byAffiliation.html#Universidade da Madeira" class="affiliation">Universidade da Madeira</a>,<br /><a href="byAuthors.html#Dong-Soo Kwon" class="author">Dong-Soo Kwon</a> <a href="byAffiliation.html#Korean Advanced Institute of Science and Technology" class="affiliation">Korean Advanced Institute of Science and Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Authentication in public spaces poses significant security risks. Most significantly, passwords can be stolen, potentially leading to fraud. A common method to steal a PIN is through an observation attack, either using a camera or through direct observation (e.g. shoulder-surfing). This paper addresses this problem by presenting the design and implementation of a novel input keypad which uses tactile cues as means to compose a password. In this system, passwords are encoded as a sequence of randomized vibration patterns, making it visually impossible for an observer to detect which items are selected. An evaluation of this system shows it outperforms previous interfaces which have used tactile feedback to obfuscate passwords.</span></div></div><div class="paper"><span class="title">Multi-Touch Authentication on Tabletops</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#David Kim" class="author">David Kim</a> <a href="byAffiliation.html#Newcastle University" class="affiliation">Newcastle University</a>,<br /><a href="byAuthors.html#Paul Dunphy" class="author">Paul Dunphy</a> <a href="byAffiliation.html#Newcastle University" class="affiliation">Newcastle University</a>,<br /><a href="byAuthors.html#Pam Briggs" class="author">Pam Briggs</a> <a href="byAffiliation.html#Northumbria University" class="affiliation">Northumbria University</a>,<br /><a href="byAuthors.html#Jonathan Hook" class="author">Jonathan Hook</a> <a href="byAffiliation.html#Newcastle University" class="affiliation">Newcastle University</a>,<br /><a href="byAuthors.html#John Nicholson" class="author">John Nicholson</a> <a href="byAffiliation.html#Newcastle University" class="affiliation">Newcastle University</a>,<br /><a href="byAuthors.html#James Nicholson" class="author">James Nicholson</a> <a href="byAffiliation.html#Northumbria University" class="affiliation">Northumbria University</a>,<br /><a href="byAuthors.html#Patrick Olivier" class="author">Patrick Olivier</a> <a href="byAffiliation.html#Newcastle University" class="affiliation">Newcastle University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The introduction of tabletop interfaces has given rise to the need for the development of secure and usable authentication techniques that are appropriate for the co-located collaborative settings for which they have been designed. Most commonly, user authentication is based on something you know, but this is a particular problem for tabletop interfaces, as they are particularly vulnerable to shoulder surfing given their remit to foster co-located collaboration. In other words, tabletop users would typically authenticate in full view of a number of observers.  In this paper, we introduce and evaluate a number of novel tabletop authentication schemes that exploit the features of multi-touch interaction in order to inhibit shoulder surfing.  In our pilot work with users, and in our formal user-evaluation, one authentication scheme - Pressure-Grid - stood out, significantly enhancing shoulder surfing resistance  when participants used it to enter both PINs and graphical passwords. </span></div></div><div class="paper"><span class="title">ColorPIN - Securing PIN entry through indirect input</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Alexander De Luca" class="author">Alexander De Luca</a> <a href="byAffiliation.html#University of Munich" class="affiliation">University of Munich</a>,<br /><a href="byAuthors.html#Katja Hertzschuch" class="author">Katja Hertzschuch</a> <a href="byAffiliation.html#University of Munich" class="affiliation">University of Munich</a>,<br /><a href="byAuthors.html#Heinrich Hussmann" class="author">Heinrich Hussmann</a> <a href="byAffiliation.html#University of Munich" class="affiliation">University of Munich</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Automated teller machine (ATM) frauds are increasing drastically these days. When analyzing the most common attacks and the reasons for successful frauds, it becomes apparent that the main problem lies in the PIN based authentication which in itself does not provide any security features (besides the use of asterisks). That is, security is solely based on a user's behavior. Indirect input is one way to solve this problem. This mostly comes at the costs of adding overhead to the input process. We present ColorPIN, an authentication mechanism that uses indirect input to provide security enhanced PIN entry. At the same time, ColorPIN remains a one-to-one relationship between the length of the PIN and the required number of clicks. A user study showed that ColorPIN is significantly more secure than standard PIN entry while enabling good authentication speed in comparison with related systems.</span></div></div><div class="paper"><span class="title">Shoulder-Surfing Resistance with Eye-Gaze Entry in Click-Based Graphical Passwords</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Alain Forget" class="author">Alain Forget</a> <a href="byAffiliation.html#Carleton University" class="affiliation">Carleton University</a>,<br /><a href="byAuthors.html#Sonia Chiasson" class="author">Sonia Chiasson</a> <a href="byAffiliation.html#Carleton University" class="affiliation">Carleton University</a>,<br /><a href="byAuthors.html#Robert Biddle" class="author">Robert Biddle</a> <a href="byAffiliation.html#Carleton University" class="affiliation">Carleton University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present Cued Gaze-Points (CGP) as a shoulder-surfing resistant cued-recall graphical password scheme where users gaze instead of mouse-click. This approach has several advantages over similar eye-gaze systems, including a larger password space and its cued-recall nature that can help users remember multiple distinct passwords. Our 45-participant lab study is the first evaluation of gaze-based password entry via user-selected points on images. CGP's usability is potentially acceptable, warranting further refinement and study.</span></div></div><div class="paper"><span class="title">Visual vs. Compact: A Comparison of Privacy Policy Interfaces</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Heather Richter Lipford" class="author">Heather Richter Lipford</a> <a href="byAffiliation.html#University of North Carolina at Charlotte" class="affiliation">University of North Carolina at Charlotte</a>,<br /><a href="byAuthors.html#Jason Watson" class="author">Jason Watson</a> <a href="byAffiliation.html#University of North Carolina at Charlotte" class="affiliation">University of North Carolina at Charlotte</a>,<br /><a href="byAuthors.html#Michael Whitney" class="author">Michael Whitney</a> <a href="byAffiliation.html#University of North Carolina at Charlotte" class="affiliation">University of North Carolina at Charlotte</a>,<br /><a href="byAuthors.html#Katherine Froiland" class="author">Katherine Froiland</a> <a href="byAffiliation.html#University of Minnesota" class="affiliation">University of Minnesota</a>,<br /><a href="byAuthors.html#Robert W. Reeder" class="author">Robert W. Reeder</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper, we compare the impact of two different privacy policy representations - AudienceView and Expandable Grids - on users modifying privacy policies for a social network site. Despite the very different interfaces, there were very few differences in user performance. However, users had clear, and different, preferences and acknowledged the tradeoffs between the two representations. Our results imply that while either interface would be a usable option for policy settings, a combination may appeal to a wider audience and offer the best of both worlds.</span></div></div></td>

<td colspan="10" class="session_details" id="S78_details"><div class="paper"><span class="title">Needs Analysis: The Case of Flexible Constraints and Mutable Boundaries</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Dorrit Billman" class="author">Dorrit Billman</a> <a href="byAffiliation.html#NASA Ames Research Center  San Jose State University" class="affiliation">NASA Ames Research Center  San Jose State University</a>,<br /><a href="byAuthors.html#Feary Michael" class="author">Feary Michael</a> <a href="byAffiliation.html#NASA Ames Research Center" class="affiliation">NASA Ames Research Center</a>,<br /><a href="byAuthors.html#Schreckengost Debra" class="author">Schreckengost Debra</a> <a href="byAffiliation.html#TRAClabs" class="affiliation">TRAClabs</a>,<br /><a href="byAuthors.html#Sherry Lance" class="author">Sherry Lance</a> <a href="byAffiliation.html#George Mason University" class="affiliation">George Mason University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Needs analysis is a prerequisite to effective design, but typically is difficult and time consuming. We applied and extended our methods and tools for needs analysis in a case study helping a mission control group for the International Space Station.  This domain illustrates the challenges of information-system domains that lack rigid, immutable, physical constraints and boundaries. We report on the successes &amp; challenges of our approach and characterize the types of situations where it should prove useful.</span></div></div><div class="paper"><span class="title">Challenges of Software Recontextualization: Lessons Learned</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Monique Janneck" class="author">Monique Janneck</a> <a href="byAffiliation.html#University of Hamburg, Department of Psychology" class="affiliation">University of Hamburg, Department of Psychology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper describes the case of a complex and problem-ridden software development and deployment process: The implementation of a Campus Management system at a large university. Based on an understanding of software development as recontextualization process on the technical, organizational, human, and task level, critical factors for success or failure are analyzed. Results show that deficits in change management and organizational support account for a considerable amount of difficulties in the implementation process. Furthermore, individual characteristics and commitment of the users involved play a major role. Lessons learned for software introduction processes are discussed.</span></div></div></td>

<td colspan="10" class="session_details" id="S76_details"><div class="paper"><span class="title">Touch-Display Keyboards: Transforming Keyboards into Interactive Surfaces</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Florian Block" class="author">Florian Block</a> <a href="byAffiliation.html#Lancaster University, Computing Department" class="affiliation">Lancaster University, Computing Department</a>,<br /><a href="byAuthors.html#Hans Gellersen" class="author">Hans Gellersen</a> <a href="byAffiliation.html#Lancaster University, Computing Department" class="affiliation">Lancaster University, Computing Department</a>,<br /><a href="byAuthors.html#Nicolas Villar" class="author">Nicolas Villar</a> <a href="byAffiliation.html#Microsoft Research  Cambridge" class="affiliation">Microsoft Research  Cambridge</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In spite of many advances in GUI workstations, the keyboard has remained limited to text entry and basic command invocation. In this work, we introduce the Touch-Display Keyboard (TDK), a novel keyboard that combines the physical-ergonomic qualities of the conventional keyboard with dynamic display and touch-sensing embedded in each key. The TDK effectively transforms the keyboard into an interactive surface that is seamlessly integrated with the interaction space of GUIs, extending graphical output, mouse interaction and three-state input to the keyboard. This gives rise to an entirely new design space of interaction across keyboard, mouse and screen, for which we provide a first systematic analysis in this paper. We illustrate the emerging design opportunities with a host of novel interaction concepts and techniques, and show how these contribute to expressiveness of GUIs, exploration and learning of keyboard interfaces, and interface customization across graphics display and physical keyboard.</span></div></div><div class="paper"><span class="title">iCon: Utilizing Everyday Objects as Additional, Auxiliary and Instant Tabletop Controllers</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kai-Yin Cheng" class="author">Kai-Yin Cheng</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a>,<br /><a href="byAuthors.html#Rong-Hao Liang" class="author">Rong-Hao Liang</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a>,<br /><a href="byAuthors.html#Bing-Yu Chen" class="author">Bing-Yu Chen</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a>,<br /><a href="byAuthors.html#Rung-Huei Liang" class="author">Rung-Huei Liang</a> <a href="byAffiliation.html#National Taiwan University of Science and Technology" class="affiliation">National Taiwan University of Science and Technology</a>,<br /><a href="byAuthors.html#Sy-Yen Kuo" class="author">Sy-Yen Kuo</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This work describes a novel approach to utilizing everyday objects of users as additional, auxiliary, and instant tabletop controllers. Based on this approach, a prototype platform, called iCon, is developed to explore the possible design. Field studies and user studies reveal that utilizing everyday objects such as auxiliary input devices might be appropriate under a multi-task scenario. User studies further demonstrate that daily objects can generally be applied in low precision circumstances, low engagement with selected objects, and medium-to-high frequency of use. The proposed approach allows users to interact with computers while not altering their original work environments.</span></div></div><div class="paper"><span class="title">Lumino: tangible blocks for tabletop computers based on glass fiber bundles</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Patrick Baudisch" class="author">Patrick Baudisch</a> <a href="byAffiliation.html#Hasso Plattner Institute" class="affiliation">Hasso Plattner Institute</a>,<br /><a href="byAuthors.html#Torsten Becker" class="author">Torsten Becker</a> <a href="byAffiliation.html#Hasso Plattner Institute" class="affiliation">Hasso Plattner Institute</a>,<br /><a href="byAuthors.html#Frederik Rudeck" class="author">Frederik Rudeck</a> <a href="byAffiliation.html#Hasso Plattner Institute" class="affiliation">Hasso Plattner Institute</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Tabletop computers based on diffuse illumination can track fiducial markers placed on the table's surface. In this paper, we demonstrate how to do the same with objects arranged in a three-dimensional structure without modifying the table. We present lumino, a system of building blocks. In addition to a marker, each block contains a glass fiber bundle. The bundle optically guides the light reflected off markers in the higher levels down to the table surface, where the table's built-in camera reads it. While guiding marker images down, the bundle optically scales and rearranges them. It thereby fits the images of an entire vertical arrangement of markers into the horizontal space usually occupied by a single 2D marker. We present three classes of blocks and matching marker designs, each of which is optimized for different requirements. We show three demo applications. One of them is a construction kit that logs and critiques constructions. The presented blocks are unpowered and maintenance-free, keeping larger numbers of blocks manageable.</span></div></div></td>

<td colspan="10" class="session_details" id="S73_details"><div class="paper"><span class="title">MOSES: Exploring New Ground in Media and Post-Conflict Reconciliation</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Thomas N. Smyth" class="author">Thomas N. Smyth</a> <a href="byAffiliation.html#School of Interactive Computing, Georgia Institute of Technology" class="affiliation">School of Interactive Computing, Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#John Etherton" class="author">John Etherton</a> <a href="byAffiliation.html#Sam Nunn School of International Affairs, Georgia Institute of Technology" class="affiliation">Sam Nunn School of International Affairs, Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Michael L. Best" class="author">Michael L. Best</a> <a href="byAffiliation.html#Sam Nunn School of International Affairs and School of Interactive Computing, Georgia Institute of Technology" class="affiliation">Sam Nunn School of International Affairs and School of Interactive Computing, Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">While the history of traditional media in post-conflict peace building efforts is rich and well studied, the potential for interactive new media technologies in this area has gone unexplored. In cooperation with the Truth and Reconciliation Commission of Liberia, we have constructed a novel interactive kiosk system, called MOSES, for use in that country's post-conflict reconciliation effort. The system allows the sharing of video messages between Liberians throughout the country, despite the presence of little or no communications infrastructure. In this paper, we describe the MOSES system, including several innovative design elements. We also present a novel design methodology we employed to manage the various distances between our design team and the intended user group in Liberia. Finally, we report on a qualitative study of the system with 27 participants from throughout Liberia. The study found that participants saw MOSES as giving them a voice and connecting them to other Liberians throughout the country; that the system was broadly usable by low-literate, novice users without human assistance; that the embodied conversational agent used in our design shows considerable promise; that users generally ascribed foreign involvement to the system; and that the system encouraged heavily group-oriented usage.</span></div></div><div class="paper"><span class="title">Blogging in a Region of Violent Conflict: Supporting Transition to Recovery</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Ban Al-Ani" class="author">Ban Al-Ani</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Gloria Mark" class="author">Gloria Mark</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Bryan Semaan" class="author">Bryan Semaan</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The blogosphere is changing how people experience war and conflict. We conducted an analysis of 125 blogs written by Iraqi citizens experiencing extreme disruption in their country. We used Hoffman's [ý8] stages of recovery model to understand how blogs support people in a region where conflict is occurring. We found that blogs create a safe virtual environment where people could interact, free of the violence in the physical environment and of the strict social norms of their changing society in wartime. Second, blogs enable a large network of global support through their interactive and personal nature. Third, blogs enable people experiencing a conflict to engage in dialogue with people outside their borders to discuss their situation. We discuss how blogs enable people to collaboratively interpret conflict through communities of interest and discussion with those who comment. We discuss how technology can better support blog use in a global environment.</span></div></div><div class="paper"><span class="title">Microblogging During Two Natural Hazards Events: What Twitter May Contribute to Situational Awareness</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sarah Vieweg" class="author">Sarah Vieweg</a> <a href="byAffiliation.html#University of Colorado" class="affiliation">University of Colorado</a>,<br /><a href="byAuthors.html#Amanda L. Hughes" class="author">Amanda L. Hughes</a> <a href="byAffiliation.html#University of Colorado" class="affiliation">University of Colorado</a>,<br /><a href="byAuthors.html#Kate Starbird" class="author">Kate Starbird</a> <a href="byAffiliation.html#University of Colorado" class="affiliation">University of Colorado</a>,<br /><a href="byAuthors.html#Leysia Palen" class="author">Leysia Palen</a> <a href="byAffiliation.html#University of Colorado" class="affiliation">University of Colorado</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We analyze microblog posts generated during two recent, concurrent emergency events in North America via Twitter, a popular microblogging service. We focus on communications broadcast by people who were on the ground during the Oklahoma Grassfires of April 2009 and the Red River Floods that occurred in March and April 2009, and identify information that may contribute to enhancing situational awareness (SA). This work aims to inform next steps for extracting useful, relevant information during emergencies using information extraction (IE) techniques. </span></div></div></td>

<td colspan="10" class="session_details" id="S11_details"><div class="paper"><span class="title">CHI 2010 Engineering Community SIG: the role of engineering work in CHI</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Keith Butler" class="author">Keith Butler</a> <a href="byAffiliation.html#CHI 2010 Engineering Community Chair,   University of Washington" class="affiliation">CHI 2010 Engineering Community Chair,   University of Washington</a></div></div></td>

<td colspan="10" class="session_details" id="S2_details"><div class="paper"><span class="title">Hard-To-Use Interfaces Considered Beneficial (Some of the Time)</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Yann Riche" class="author">Yann Riche</a> <a href="byAffiliation.html#Riche Design" class="affiliation">Riche Design</a>,<br /><a href="byAuthors.html#Nathalie Henry Riche" class="author">Nathalie Henry Riche</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Petra Isenberg" class="author">Petra Isenberg</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a>,<br /><a href="byAuthors.html#Anastasia Bezerianos" class="author">Anastasia Bezerianos</a> <a href="byAffiliation.html#MAS Laboratory  Ecole Centrale" class="affiliation">MAS Laboratory  Ecole Centrale</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Researchers in HCI share a common understanding that easy-to-use, easy-to-learn and intuitive interfaces are beneficial to users. Designing such interfaces raises challenges and often requires multiple iterations.  While we are generally prompt to discard more hard-to-use interfaces and smooth out usability issues, we want to raise here the issue of their potential benefits. We de-scribe two cases in which we observed potential bene-fits from introducing barriers for collaborating and communicating with others. We attempt to shed a new light on interfaces with usability problems and how these problems may benefit system efficiency and user experience.  We end with a discussion of the pros and cons of making systems harder for people to use, and how to integrate this perspective in the design process.</span></div></div><div class="paper"><span class="title">Communicating Software Agreement Content Using Narrative Pictograms</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Matthew Kay" class="author">Matthew Kay</a> <a href="byAffiliation.html#Human-Computer Interaction Lab  University of Waterloo  200 University Avenue West" class="affiliation">Human-Computer Interaction Lab  University of Waterloo  200 University Avenue West</a>,<br /><a href="byAuthors.html#Michael Terry" class="author">Michael Terry</a> <a href="byAffiliation.html#Human-Computer Interaction Lab  University of Waterloo  200 University Avenue West" class="affiliation">Human-Computer Interaction Lab  University of Waterloo  200 University Avenue West</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present narrative pictograms, illustrative diagrams designed to convey the abstract concepts of software agreements. Narrative pictograms arose out of a need to create software agreements that are comprehensible without written language. We first present example diagrams designed to describe the data collection policies of research software, and the composition rules used to create them. We then present our design process and lessons learned during design. Finally, we present results from an evaluation based on the ISO 9186-1 test for graphical symbols.</span></div></div><div class="paper"><span class="title">Theres Methodology in the Madness: Toward Critical HCI Ethnography</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Amanda Williams" class="author">Amanda Williams</a> <a href="byAffiliation.html#Concordia University  University of California, Irvine" class="affiliation">Concordia University  University of California, Irvine</a>,<br /><a href="byAuthors.html#Lilly Irani" class="author">Lilly Irani</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We examine the expansion of topic areas for qualitative research in HCI publications, focusing on representations of users and field sites. We examine further developments in anthropological methodologies during a critical period of the late 1980s and 90s. We identify concerns shared by both research communities, in particular, the relationships between researcher and informant, and the construction of bounded settings for field work. We then argue that ethnographic approaches and theoretical commitments which came to the fore after Anthropologys critical turn can be usefully applied, in ways that can inspire design, to investigations of social practice and technology appropriation.</span></div></div><div class="paper"><span class="title">Interaction Design in the University: Designing Disciplinary Interactions</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Gale Moore" class="author">Gale Moore</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a>,<br /><a href="byAuthors.html#Danielle Lottridge" class="author">Danielle Lottridge</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Interaction design (ID) as a field emerged in the late 90s with roots in both the HCI and design communities. We ask whether the interdisciplinary agenda of the 3rd paradigm of HCI can be accommodated in the traditional disciplined university. An alternate model of interdisciplinarity offers one way forward, but calls for clarity on the question of what interaction design aspires to be. We offer the notion of 'disciplined transdisciplinarity' as an exciting and perhaps necessary way of solving the complex problems that ID researchers face, and illustrate this with examples drawn from the area of emotional design and assessment. Our bridge between 3rd paradigm, knowledge production and what we are calling 'disciplined transdisciplinary' yields insights into the path toward institutionalizing and legitimating research on ID and academic careers in this field in the university.</span></div></div><div class="paper"><span class="title">Design Situations and Methodological Innovation in Interaction Design</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Gilbert Cockton" class="author">Gilbert Cockton</a> <a href="byAffiliation.html#Northumbria University" class="affiliation">Northumbria University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This juried alt.chi paper argues that philosophy can seed HCI innovations. Recent developments in ontology open up novel methodological opportunities. Alain Badious situational ontology breaks an apparent impasse between essentialism and relationalism. For Badiou, the essence of any entity is a multiplicity formed from what is counted-as-one, but its parts bring potentials for change. These can exploited through the concept of design situations that contain infinite opportunities for designing as connecting. Far from being a barren abstraction, this opens up new spaces for demonstrable practical methodological innovation in Interaction Design.</span></div></div><div class="paper"><span class="title">Experience in Social Affective Applications: Methodologies and Case Study</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Paul André" class="author">Paul André</a> <a href="byAffiliation.html#University of Southampton" class="affiliation">University of Southampton</a>,<br /><a href="byAuthors.html#M.c. Schraefel" class="author">M.c. Schraefel</a> <a href="byAffiliation.html#University of Southampton" class="affiliation">University of Southampton</a>,<br /><a href="byAuthors.html#Alan Dix" class="author">Alan Dix</a> <a href="byAffiliation.html#University of Lancaster" class="affiliation">University of Lancaster</a>,<br /><a href="byAuthors.html#Ryen W. White" class="author">Ryen W. White</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">New forms of social affective applications are emerging, bringing with them challenges in design and evaluation. We report on one such application, conveying well-being for both personal and group benefit, and consider why existing methodologies may not be suitable, before explaining and analyzing our proposed approach. We discuss our experience of using and writing about the methodology, in order to invite discussion about its suitability in particular, as well as the more general need for methodologies to examine experience and affect in social, connected situations. As these fields continue to interact, we hope that these discussions serve to aid in studying and learning from these types of application.</span></div></div></td>

<td colspan="10" class="session_details" id="S72_details"><div class="paper"><span class="title">Where Are You Pointing? The Accuracy of Deictic Pointing in CVEs</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Nelson Wong" class="author">Nelson Wong</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a>,<br /><a href="byAuthors.html#Carl Gutwin" class="author">Carl Gutwin</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Deictic reference - pointing at things during conversation - is ubiquitous in human communication, and should also be an important tool in distributed collaborative virtual environments (CVEs). Pointing gestures can be complex and subtle, however, and pointing is much more difficult in the virtual world. In order to improve the richness of interaction in CVEs, it is important to provide better support for pointing and deictic reference, and a first step in this support is to determine how well people can interpret the direction that another person is pointing. To investigate this question, we carried out two studies. The first identified several ways that people point towards distant targets, and established that not all pointing requires high accuracy. This suggested that natural CVE pointing could potentially be successful; but no knowledge is available about whether even moderate accuracy is possible in CVEs. Therefore, our second study looked more closely at how accurately people can produce and interpret the direction of pointing gestures in CVEs. We found that although people are more accurate in the real world, the differences are smaller than expected; our results show that deixis can be successful in CVEs for many pointing situations, and provide a foundation for more comprehensive support of deictic pointing.</span></div></div><div class="paper"><span class="title">Lie Tracking: Social Presence, Truth and Deception in Avatar-Mediated Telecommunication</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#William Steptoe" class="author">William Steptoe</a> <a href="byAffiliation.html#Department of Computer Science, University College London" class="affiliation">Department of Computer Science, University College London</a>,<br /><a href="byAuthors.html#Anthony Steed" class="author">Anthony Steed</a> <a href="byAffiliation.html#Department of Computer Science, University College London" class="affiliation">Department of Computer Science, University College London</a>,<br /><a href="byAuthors.html#Aitor Rovira" class="author">Aitor Rovira</a> <a href="byAffiliation.html#Department of Computer Science, University College London" class="affiliation">Department of Computer Science, University College London</a>,<br /><a href="byAuthors.html#John Rae" class="author">John Rae</a> <a href="byAffiliation.html#School of Human and Life Sciences, Roehampton University" class="affiliation">School of Human and Life Sciences, Roehampton University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The success of visual telecommunication systems depends on their ability to transmit and display users' natural nonverbal behavior. While video-mediated communication (VMC) is the most widely used form of interpersonal remote interaction, avatar-mediated communication (AMC) in shared virtual environments is increasingly common. This paper presents two experiments investigating eye tracking in AMC. The first experiment compares the degree of social presence experienced in AMC and VMC during truthful and deceptive discourse. Eye tracking data (gaze, blinking, and pupil size) demonstrates that oculesic behavior is similar in both mediation types, and uncovers systematic differences between truth telling and lying. Subjective measures show users' psychological arousal to be greater in VMC than AMC. The second experiment demonstrates that observers of AMC can more accurately detect truth and deception when viewing avatars with added oculesic behavior driven by eye tracking. We discuss implications for the design of future visual telecommunication media interfaces.</span></div></div><div class="paper"><span class="title">Embodied Social Proxy: Mediating Interpersonal Connection in Hub-and-Satellite Teams</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Gina Venolia" class="author">Gina Venolia</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#John Tang" class="author">John Tang</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Ruy Cervantes Fregoso" class="author">Ruy Cervantes Fregoso</a> <a href="byAffiliation.html#UC Irvine" class="affiliation">UC Irvine</a>,<br /><a href="byAuthors.html#Sara Bly" class="author">Sara Bly</a> <a href="byAffiliation.html#Sara Bly Consulting" class="affiliation">Sara Bly Consulting</a>,<br /><a href="byAuthors.html#George Robertson" class="author">George Robertson</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Bongshin Lee" class="author">Bongshin Lee</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Kori Inkpen" class="author">Kori Inkpen</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Current business conditions have given rise to distributed teams that are mostly collocated except for one remote member. These hub-and-satellite teams face the challenge of the satellite colleague being out-of-sight and out-of-mind. We developed a telepresence device, called an Embodied Social Proxy (ESP), which represents the satellite coworker 24x7. Beyond using ESPs in our own group, we deployed an ESP in four product teams within our company for six weeks. We studied how ESP was used through ethnographic observations, surveys, and usage log data. ESP not only increased the satellite worker's ability to fully participate in meetings, it also increased the hub's attention and affinity towards the satellite. The continuous physical presence of ESP in each team improved the interpersonal social connections between hub and satellite colleagues. </span></div></div></td>

<td colspan="10" class="session_details" id="S75_details"><div class="paper"><span class="title">PointAssist for Older Adults: Analyzing Sub-Movement Characteristics to Aid in Pointing Tasks</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Juan Pablo Hourcade" class="author">Juan Pablo Hourcade</a> <a href="byAffiliation.html#University of Iowa" class="affiliation">University of Iowa</a>,<br /><a href="byAuthors.html#Christopher M. Nguyen" class="author">Christopher M. Nguyen</a> <a href="byAffiliation.html#University of Iowa" class="affiliation">University of Iowa</a>,<br /><a href="byAuthors.html#Keith B. Perry" class="author">Keith B. Perry</a> <a href="byAffiliation.html#University of Iowa" class="affiliation">University of Iowa</a>,<br /><a href="byAuthors.html#Natalie L. Denburg" class="author">Natalie L. Denburg</a> <a href="byAffiliation.html#University of Iowa" class="affiliation">University of Iowa</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Perceptual, cognitive and motor deficits cause many older adults to have difficulty conducting pointing tasks on computers. Many strategies have been discussed in the HCI community to aid older adults and others in pointing tasks. We present a different approach in PointAssist, software that aids in pointing tasks by analyzing the characteristics of sub-movements, detecting when users have difficulty pointing, and triggering a precision mode that slows the speed of the cursor in those cases. PointAssist is designed to help maintain pointing skills, runs as a background process working with existing software, is not vulnerable to clusters of targets or targets in the way, and does not modify the visual appearance or the feel of user interfaces. There is evidence from a prior study that PointAssist helps young children conduct pointing tasks.  In this paper, we present a study evaluating PointAssist with twenty older adults (ages 66-88).  The study participants benefited from greater accuracy when using PointAssist, when compared to using the enhance pointer precision option in Windows XP. In addition, we provide evidence of correlations between neuropsychological measures, pointing performance, and PointAssist detecting pointing difficulty.</span></div></div><div class="paper"><span class="title">Steadied-Bubbles: Combining Techniques to Address Pen-Based Pointing Errors for Younger and Older Adults</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Karyn Moffatt" class="author">Karyn Moffatt</a> <a href="byAffiliation.html#University of British Columbia" class="affiliation">University of British Columbia</a>,<br /><a href="byAuthors.html#Joanna McGrenere" class="author">Joanna McGrenere</a> <a href="byAffiliation.html#University of British Columbia" class="affiliation">University of British Columbia</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Tablet PCs are gaining popularity but many older adults still struggle with pointing, particularly with two error types: missing, landing and lifting outside the target bounds; and slipping, landing on the target, but slipping off before lifting. To solve these problems, we examined the feasibility of extending and combining existing techniques designed for younger users and the mouse, focusing our investigation on the Bubble cursor and Steady Clicks techniques. Through a laboratory experiment with younger and older adults, we showed that both techniques can be adapted for use in a pen interface, and that combining the two techniques provides greater support than either technique on its own. Though our results were especially pertinent to the older group, both ages benefited from the designs. We also found that technique performance depended on task context. From these findings we established guidelines for technique selection.</span></div></div><div class="paper"><span class="title">Learning to text: An interaction analytic study of how seniors learn to enter text on mobile phones</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Alexandra Weilenmann" class="author">Alexandra Weilenmann</a> <a href="byAffiliation.html#Gothenburg University" class="affiliation">Gothenburg University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper is based on an interaction analysis of video  recordings of seniors being instructed in the use of texting.  Learning to text is a complex ordeal for the elderly, which  not only involves grasping such complex phenomena as  hierarchically organized menus and text prediction  technology, but also more mundane and seemingly simple  skills as pressing the keys. The latter is the primary focus of  the analysis, as this is a common and taken for granted skill  upon which many HCI systems rely. We show how the  seniors struggle with learning to press in a sequence,  embodying the timing and rhythm of key pressing, and  orchestrating their vision and pressing. The study  contributes to the general field of mobile phone design for  the elderly, to our knowledge on how people appropriate  and learn to use new technologies, as well as adds to  models explaining novice users' mastering of text input.</span></div></div></td>

<td colspan="10" class="session_details" id="S77_details"><div class="paper"><span class="title">Opinion Space:  A Scalable Tool for Browsing Online Comments</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Siamak Faridani" class="author">Siamak Faridani</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#Ephrat Bitton" class="author">Ephrat Bitton</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#Kimiko Ryokai" class="author">Kimiko Ryokai</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#Ken Goldberg" class="author">Ken Goldberg</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Internet users are increasingly inclined to contribute comments to online news articles, videos, product reviews, and blogs. The most common interface for comments is a list, sorted by time of entry or by binary ratings. It is widely recognized that such lists do not scale well and can lead to cyberpolarization, which serves to reinforce extreme opinions. We present Opinion Space: a new online interface incorporating ideas from deliberative polling, dimensionality reduction, and collaborative filtering that allows participants to visualize and navigate through a diversity of comments. This self-organizing system automatically highlights the comments found most insightful by users from a range of perspectives. We report results of a controlled user study. When Opinion Space was compared with a chronological List interface, participants read a similar diversity of comments. However, they were significantly more engaged with the system, and they had significantly higher agreement with and respect for the comments they read.</span></div></div><div class="paper"><span class="title">Short and Tweet: Experiments on Recommending Content from Information Streams</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jilin Chen" class="author">Jilin Chen</a> <a href="byAffiliation.html#University of Minnesota" class="affiliation">University of Minnesota</a>,<br /><a href="byAuthors.html#Rowan Nairn" class="author">Rowan Nairn</a> <a href="byAffiliation.html#Palo Alto Research Center" class="affiliation">Palo Alto Research Center</a>,<br /><a href="byAuthors.html#Les Nelson" class="author">Les Nelson</a> <a href="byAffiliation.html#Palo Alto Research Center" class="affiliation">Palo Alto Research Center</a>,<br /><a href="byAuthors.html#Michael Bernstein" class="author">Michael Bernstein</a> <a href="byAffiliation.html#Massachusetts Institute of Technology" class="affiliation">Massachusetts Institute of Technology</a>,<br /><a href="byAuthors.html#Ed Chi" class="author">Ed Chi</a> <a href="byAffiliation.html#Palo Alto Research Center" class="affiliation">Palo Alto Research Center</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">More and more web users keep up with newest information through information streams such as the popular micro-blogging website Twitter. In this paper we studied content recommendation on Twitter to better direct user attention. In a modular approach, we explored three separate dimensions in designing such a recommender: content sources, topic interest models for users, and social voting. We implemented 12 recommendation engines in the design space we formulated, and deployed them to a recommender service on the web to gather feedback from real Twitter users. The best performing algorithm improved the percentage of interesting content to 72% from a baseline of 33%. We conclude this work by discussing the implications of our recommender design and how our design can generalize to other information streams.</span></div></div><div class="paper"><span class="title">Characterizing Debate Performance via  Aggregated Twitter Sentiment</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Nicholas Diakopoulos" class="author">Nicholas Diakopoulos</a> <a href="byAffiliation.html#Rutgers University" class="affiliation">Rutgers University</a>,<br /><a href="byAuthors.html#David A. Shamma" class="author">David A. Shamma</a> <a href="byAffiliation.html#Yahoo! Research" class="affiliation">Yahoo! Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Television broadcasters are beginning to combine social micro-blogging systems such as Twitter with television to create social video experiences around events. We looked at one such event, the first U.S. presidential debate in 2008, in conjunction with aggregated ratings of message sentiment from Twitter. We begin to develop an analytical methodology and visual representations that could help a journalist or public affairs person better understand the temporal dynamics of sentiment in reaction to the debate video. We demonstrate visuals and metrics that can be used to detect sentiment pulse, anomalies in that pulse, and indications of controversial topics that can be used to inform the design of visual analytic systems for social media events. </span></div></div><div class="paper"><span class="title">Dandelion: Supporting Coordinated Collaborative Authoring in Wikis</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Changyan Chi" class="author">Changyan Chi</a> <a href="byAffiliation.html#IBM Research - China" class="affiliation">IBM Research - China</a>,<br /><a href="byAuthors.html#Michelle X. Zhou" class="author">Michelle X. Zhou</a> <a href="byAffiliation.html#IBM Research - China" class="affiliation">IBM Research - China</a>,<br /><a href="byAuthors.html#Min Yang" class="author">Min Yang</a> <a href="byAffiliation.html#IBM Research - China" class="affiliation">IBM Research - China</a>,<br /><a href="byAuthors.html#Wenpeng Xiao" class="author">Wenpeng Xiao</a> <a href="byAffiliation.html#IBM Research - China" class="affiliation">IBM Research - China</a>,<br /><a href="byAuthors.html#Yiqin Yu" class="author">Yiqin Yu</a> <a href="byAffiliation.html#IBM Research - China" class="affiliation">IBM Research - China</a>,<br /><a href="byAuthors.html#Xiaohua Sun" class="author">Xiaohua Sun</a> <a href="byAffiliation.html#IBM Research - China" class="affiliation">IBM Research - China</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Dandelion is a tool that extends wikis to support coordinated, collaborative authoring using a tag-based approach. Specifically, users can insert tags in a wiki page to specify various co-authoring tasks. These tags can then be executed to help drive and manage the collaboration workflow, and provide content-centric collaboration awareness for all the co-authors. Four successful pilot deployments and positive user feedback show the practical value of Dandelion, especially its value in supporting a structured, collaborative authoring process often seen in business settings.</span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">4:30&nbsp;PM<br/><em>to</em><br/>6:00&nbsp;PM</td>
<td class="session" id="S30">
<span class="type">ToCHI</span>
<span class="title">Input and Direct Manipulation</span>
<span class="location"></span>
</td>
<td class="session" id="S23">
<span class="type">Panel</span>
<span class="title">E-Government: Services for Everyone, Everywhere, Eventually</span>
<span class="location">Centennial 2</span>
</td>
<td class="session" id="S82">
<span class="type">Papers/Notes</span>
<span class="title">HCI For All</span>
<span class="location">Centennial 3</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S84">
<span class="type">Papers/Notes</span>
<span class="title">Machine Learning and Web Interactions</span>
<span class="location">Centennial 4</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S85">
<span class="type">Papers/Notes</span>
<span class="title">Pointing and Selecting</span>
<span class="location">Chicago ABC</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S12">
<span class="type">SIG</span>
<span class="title">Automotive User Interfaces: Human Computer Interaction in the Car</span>
<span class="location">Chicago DEF</span>
</td>
<td class="session" id="S81">
<span class="type">Papers/Notes</span>
<span class="title">Driving, Interrupted</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S79">
<span class="type">Papers/Notes</span>
<span class="title">Caring for Ourselves</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S80">
<span class="type">Papers/Notes</span>
<span class="title">Communicating</span>
<span class="location">Regency 6</span>
</td>
<td class="session" id="S83">
<span class="type">Papers/Notes</span>
<span class="title">Interaction Techniques</span>
<span class="location">Regency 7</span>
</td>
</tr>
<tr class="details_row">

<td colspan="10" class="session_details" id="S30_details"><div class="paper"><span class="title">Using Direct and Indirect Input Devices: Attention Demands and Age-Related Differences</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Anne McLaughlin" class="author">Anne McLaughlin</a> <a href="byAffiliation.html#North Carolina State University" class="affiliation">North Carolina State University</a>,<br /><a href="byAuthors.html#Wendy A. Rogers" class="author">Wendy A. Rogers</a> <a href="byAffiliation.html#School of Psychology, Georgia Tech" class="affiliation">School of Psychology, Georgia Tech</a>,<br /><a href="byAuthors.html#Arthur D. Fisk" class="author">Arthur D. Fisk</a> <a href="byAffiliation.html#School of Psychology, Georgia Tech" class="affiliation">School of Psychology, Georgia Tech</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Researchers have suggested that attention is a key moderating variable predicting performance with an input device [Greenstein &amp; Arnaut, 1988],  though the attention demands of devices have not been directly investigated. We hypothesized that the attentional demands of input devices are intricately linked to whether the device matches the input requirements of the on-screen task. Further, matching task and device should be more important for attentionally reduced groups, such as older adults. Younger and older adults used either a direct (touch screen) or indirect (rotary encoder) input device to perform matched or mismatched input tasks under a spectrum of attention allocation conditions. Input devices required attention  more so for older adults, especially in a mismatch situation. In addition, task performance was influenced by the mach between task demands and input device characteristics. Though both groups benefited from a match between input device and task input requirements, older adults benefited more and this benefit increased as less attention was available. We offer an a priori method to choose an input device for a task by considering the overlap between device attributes and input requirements. These data should affect design decisions concerning input device  selection across age groups and task contexts.</span></div></div><div class="paper"><span class="title">Shifting the Focus from Accuracy to Recallability: A Study of Informal Note Taking on Mobile IT</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Liwei Dai" class="author">Liwei Dai</a> <a href="byAffiliation.html#Xerox Corp." class="affiliation">Xerox Corp.</a>,<br /><a href="byAuthors.html#Andrew Sears" class="author">Andrew Sears</a> <a href="byAffiliation.html#UMBC" class="affiliation">UMBC</a>,<br /><a href="byAuthors.html#Rich Goldman" class="author">Rich Goldman</a> <a href="byAffiliation.html#UMBC" class="affiliation">UMBC</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Mobile information technologies are theoretically well suited to accommodate informal note taking activities, but adoption has been hindered by slow text entry techniques. Building on people's ability to recognize erroneous text, we explore the efficacy of disabling text correction and visual feedback. The modifications improved text entry speed, but decreased recognizability. A follow-up study confirmed the efficacy of discouraging user-initiated error correction, enhancing the resulting erroneous notes, and facilitating recall with enhanced alternative lists. Note taking speed increased by 47% without negatively impacting the participants' ability to recall details about the scenarios which motivated the note taking activities.</span></div></div><div class="paper"><span class="title">ModelCraft: Capturing Freehand Annotations and Edits on 3D Models using a Digital Pen</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Hyunyoung Song" class="author">Hyunyoung Song</a> <a href="byAffiliation.html#University of Maryland, College Park" class="affiliation">University of Maryland, College Park</a>,<br /><a href="byAuthors.html#Francois Guimbretière" class="author">Francois Guimbretière</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Hod Lipson" class="author">Hod Lipson</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Physical models in earlier stages of design can easily be annotated to capture comments, edits and user feedbacks, but these annotations remain in the physical world and cannot easily be transferred back to the digital world. ModelCraft addresses this problem by augmenting the surface of a model with a traceable pattern. Using a digital pen, any sketch drawn on the surface of the model is recovered as part of digital representation. Sketches can also be interpreted as operations on the original CAD model. ModelCraft system was proved useful from several interviews and a formal study of the potential users.</span></div></div><div class="paper"><span class="title">Can Direct Manipulation Lower the Barriers to Computer Programming and Promote Transfer of Training?</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Christopher Hundhausen" class="author">Christopher Hundhausen</a> <a href="byAffiliation.html#Washington State University" class="affiliation">Washington State University</a>,<br /><a href="byAuthors.html#Sean F. Farley" class="author">Sean F. Farley</a> <a href="byAffiliation.html#Washington State University" class="affiliation">Washington State University</a>,<br /><a href="byAuthors.html#Jonathan L. Brown" class="author">Jonathan L. Brown</a> <a href="byAffiliation.html#Washington State University" class="affiliation">Washington State University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">By constraining syntax and providing concrete visual representations on which to operate, direct manipulation programming environments can potentially ease computer programming tasks. Can direct manipulation programming environments also facilitate positive transfer to textual programming? To address this question, we designed a new direct manipulation programming interface and conducted an experimental study. Our direct manipulation interface promoted significantly better initial programming outcomes, positive transfer to the textual interface, and significant differences in programming processes, suggesting that direct manipulation interfaces can provide novices with a &quot;way in&quot; to textual programming.</span></div></div></td>

<td colspan="10" class="session_details" id="S23_details"><div class="paper"><span class="title">E-Government: Services for Everyone, Everywhere, Eventually</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jeff Johnson" class="author">Jeff Johnson</a> <a href="byAffiliation.html#UI Wizards, Inc. &amp; SIGCHI U.S. Public Policy Committee" class="affiliation">UI Wizards, Inc. &amp; SIGCHI U.S. Public Policy Committee</a>,<br /><a href="byAuthors.html#Jonathan Lazar" class="author">Jonathan Lazar</a> <a href="byAffiliation.html#Towson University &amp; SIGCHI U.S. Public Policy Committee" class="affiliation">Towson University &amp; SIGCHI U.S. Public Policy Committee</a></div></div></td>

<td colspan="10" class="session_details" id="S82_details"><div class="paper"><span class="title">Homeless Young People's Experiences with Information Systems: Life and Work in a Community Technology Center</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jill Palzkill Woelfer" class="author">Jill Palzkill Woelfer</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#David G. Hendry" class="author">David G. Hendry</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper explores how homeless young people, aged 13-25, make use of information systems in daily life. Observed in a community technology center, four different examples of uses are described: i) Using digital tools to find employment, ii) Telling stories with representations of the built world, iii) Portraying life on the street with video, and iv) Constructing online identities. From these examples and a discussion of this community, a framework of ecological considerations is proposed. This framework distinguishes between elements of life on the street (Self-Reliance, Vulnerability, and Basic Needs) and work in the community technology center (Conformity, Youth-Adult Relationships, and Goals). Any information system for homeless young people must engage the tensions and opportunities that arise from these two different perspectives of homelessness. </span></div></div><div class="paper"><span class="title">Feminist HCI:  Taking Stock and Outlining an Agenda for Design</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Shaowen Bardzell" class="author">Shaowen Bardzell</a> <a href="byAffiliation.html#Indiana University" class="affiliation">Indiana University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Feminism is a natural ally to interaction design, due to its central commitments to issues such as agency, fulfillment, identity, equity, empowerment, and social justice. In this paper, I summarize the state of the art of feminism in HCI and propose ways to build on existing successes to more robustly integrate feminism into interaction design research and practice. I explore the productive role of feminism in analogous fields, such as industrial design, architecture, and game design. I introduce examples of feminist interaction design already in the field. Finally, I propose a set of femi-nist interaction design qualities intended to support design and evaluation processes directly as they unfold.</span></div></div><div class="paper"><span class="title">Postcolonial Computing: A Lens on Design and Development</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Lilly Irani" class="author">Lilly Irani</a> <a href="byAffiliation.html#UC Irvine" class="affiliation">UC Irvine</a>,<br /><a href="byAuthors.html#Janet Vertesi" class="author">Janet Vertesi</a> <a href="byAffiliation.html#UC Irvine" class="affiliation">UC Irvine</a>,<br /><a href="byAuthors.html#Paul Dourish" class="author">Paul Dourish</a> <a href="byAffiliation.html#UC Irvine" class="affiliation">UC Irvine</a>,<br /><a href="byAuthors.html#Kavita Philip" class="author">Kavita Philip</a> <a href="byAffiliation.html#UC Irvine" class="affiliation">UC Irvine</a>,<br /><a href="byAuthors.html#Rebecca E. Grinter" class="author">Rebecca E. Grinter</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">As our technologies travel to new cultural contexts and our designs and methods engage new constituencies, both our design and analytical practices face significant challenges. We offer postcolonial computing as an analytical orientation to better understand these challenges. This analytic orientation inspires four key shifts in our approach to HCI4D efforts: generative models of culture, development as a historical program, uneven economic relations, and cultural epistemologies. Then, through reconsideration of the practices of engagement, articulation and translation in other contexts, we offer designers and researchers ways of understanding use and design practice to respond to global connectivity and movement.</span></div></div></td>

<td colspan="10" class="session_details" id="S84_details"><div class="paper"><span class="title">Interactive Optimization for Steering Machine Classification</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ashish Kapoor" class="author">Ashish Kapoor</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Bongshin Lee" class="author">Bongshin Lee</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Desney Tan" class="author">Desney Tan</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Eric Horvitz" class="author">Eric Horvitz</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Interest has been growing within HCI on the use of machine learning and reasoning in applications to classify such hidden states as user intentions, based on observations. HCI researchers with these interests typically have little expertise in machine learning and often employ toolkits as relatively fixed &quot;black boxes&quot; for generating statistical classifiers. However, attempts to tailor the performance of classifiers to specific application requirements may require a more sophisticated understanding and custom-tailoring of methods. We present ManiMatrix, a system that provides controls and visualizations that enable system builders to refine the behavior of classification systems in an intuitive manner. With ManiMatrix, users directly refine parameters of a confusion matrix via an interactive cycle of re-classification and visualization. We present the core methods and evaluate the effectiveness of the approach in a user study. Results show that users are able to quickly and effectively modify decision boundaries of classifiers to tailor the behavior of classifiers to problems at hand.</span></div></div><div class="paper"><span class="title">A Longitudinal Study of How Highlighting Web Content Change Affects People's Web Interactions</span> - <span class="type">Note</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Jaime Teevan" class="author">Jaime Teevan</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Susan T. Dumais" class="author">Susan T. Dumais</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Daniel J. Liebling" class="author">Daniel J. Liebling</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The Web is constantly changing, but most tools used to access Web content deal only with what can be captured at a single instance in time.  As a result, Web users may not have a good understanding of the changes that occur.  In this paper we show that making Web content change explicitly visible allows people to interact with the Web in new ways.  We present a longitudinal study in which 30 people used a Web browser plug-in that caches visited pages and highlights text changes to those pages when revisited.  We used a survey to capture their understanding of Web page change and their own revisitation patterns at the beginning of use and after one month. For a majority of the participants, we also logged their Web page visits and associated content change.  Exposing change is more valuable to our participants than initially expected, making them aware of how dynamic content they visit is and changing their interactions with it.</span></div></div><div class="paper"><span class="title">Examining Multiple Potential Models in End-User Interactive Concept Learning</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Saleema Amershi" class="author">Saleema Amershi</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#James Fogarty" class="author">James Fogarty</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Ashish Kapoor" class="author">Ashish Kapoor</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Desney Tan" class="author">Desney Tan</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">End-user interactive concept learning is a technique for interacting with large unstructured datasets, requiring insights from both human-computer interaction and machine learning. This note re-examines an assumption implicit in prior interactive machine learning research, that interaction should focus on the question what class is this object?. We broaden interaction to include examination of multiple potential models while training a machine learning system. We evaluate this approach and find that people naturally adopt revision in the interactive machine learning process and that this improves the quality of their resulting models for difficult concepts.</span></div></div><div class="paper"><span class="title">Signed networks in social media</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jure Leskovec" class="author">Jure Leskovec</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Daniel Huttenlocher" class="author">Daniel Huttenlocher</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Jon Kleinberg" class="author">Jon Kleinberg</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Relations between users on social media sites often reflect a mixture of  positive (friendly) and negative (antagonistic) interactions. In contrast to  the bulk of research on social networks that has focused almost exclusively on  positive interpretations of links between people, we study how the interplay  between positive and negative relationships affects the structure of on-line  social networks. We connect our analyses to theories of signed networks from  social psychology. We find that the classical theory of structural balance  tends to capture certain common patterns of interaction, but that it is also at  odds with some of the fundamental phenomena we observe --- particularly related  to the evolving, directed nature of these on-line networks.    We then develop an alternate theory of status that better  explains the observed edge signs and provides insights into the  underlying social mechanisms. Our work provides one of the first  large-scale evaluations of theories of signed networks using on-line  datasets, as well as providing a perspective for reasoning about  social media sites.  </span></div></div></td>

<td colspan="10" class="session_details" id="S85_details"><div class="paper"><span class="title">Why it's Quick to be Square: Modelling New and Existing Hierarchical Menu Designs</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#David Ahlström" class="author">David Ahlström</a> <a href="byAffiliation.html#Klagenfurt University" class="affiliation">Klagenfurt University</a>,<br /><a href="byAuthors.html#Andy Cockburn" class="author">Andy Cockburn</a> <a href="byAffiliation.html#University of Canterbury" class="affiliation">University of Canterbury</a>,<br /><a href="byAuthors.html#Carl Gutwin" class="author">Carl Gutwin</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a>,<br /><a href="byAuthors.html#Pourang Irani" class="author">Pourang Irani</a> <a href="byAffiliation.html#University of Manitoba" class="affiliation">University of Manitoba</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We consider different hierarchical menu and toolbar-like interface designs from a theoretical perspective and show how a model based on visual search time, pointing time, decision time and expertise development can assist in understanding and predicting interaction performance. Three hierarchical menus designs are modelled - a traditional pull-down menu, a pie menu and a novel Square Menu with its items arranged in a grid - and the predictions are validated in an empirical study. The model correctly predicts the relative performance of the designs - both the eventual dominance of Square Menus compared to traditional and pie designs and a performance crossover as users gain experience. Our work shows the value of modelling in HCI design, provides new insights about performance with different hierarchical menu designs, and demonstrates a new high-performance menu type.</span></div></div><div class="paper"><span class="title">pCubee: A Perspective-Corrected Handheld Cubic Display</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ian Stavness" class="author">Ian Stavness</a> <a href="byAffiliation.html#University of British Columbia" class="affiliation">University of British Columbia</a>,<br /><a href="byAuthors.html#Billy Lam" class="author">Billy Lam</a> <a href="byAffiliation.html#University of British Columbia" class="affiliation">University of British Columbia</a>,<br /><a href="byAuthors.html#Sidney Fels" class="author">Sidney Fels</a> <a href="byAffiliation.html#University of British Columbia" class="affiliation">University of British Columbia</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper, we describe the design of a personal cubic display that offers novel interaction techniques for static and dynamic 3D content. We extended one-screen Fish Tank VR by arranging five small LCD panels into a box shape that is light and compact enough to be handheld. The display uses head-coupled perspective rendering and a real-time physics simulation engine to establish an interaction metaphor of having real objects inside a physical box that a user can hold and manipulate. We evaluated our prototype as a visualization tool and as an input device by comparing it with a conventional LCD display and mouse for a 3D tree-tracing task. We found that bimanual interaction with pCubee and a mouse offered the best performance and was most preferred by users. pCubee has potential in 3D visualization and interactive applications such as games, storytelling and education, as well as viewing 3D maps, medical and architectural data.</span></div></div><div class="paper"><span class="title">Bias towards Regular Con&amp;#64257;guration in 2D Pointing</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Huahai Yang" class="author">Huahai Yang</a> <a href="byAffiliation.html#IBM Research - Almaden" class="affiliation">IBM Research - Almaden</a>,<br /><a href="byAuthors.html#Xianggang Xu" class="author">Xianggang Xu</a> <a href="byAffiliation.html#Civil Aviation Medical Center" class="affiliation">Civil Aviation Medical Center</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Extending Fitts' law to more than one dimension has been recognized as having important implications for HCI. In spite of the progress made over the years, however, it is still far from a resolved issue. Our work approaches this problem from the viewpoint of a configuration space, which has served as a useful conceptual framework for understanding human preference in perception. Notably, human are found to be biased towards regular configurations. In this work, we extended the configuration space framework to the domain of motor behavior, analyzed 2D pointing, and developed five models to account for the performance. An extensive experiment was conducted to measure the fit of the derived models and that of three previous models. Consistent with our hypothesis, the model reflecting a bias towards regular configuration was found to have the most satisfactory fit with the data. The paper concludes with discussions on improving understanding of Fitts' law and the implications for HCI.  </span></div></div></td>

<td colspan="10" class="session_details" id="S12_details"><div class="paper"><span class="title">Automotive User Interfaces: Human Computer Interaction in the Car</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Albrecht Schmidt" class="author">Albrecht Schmidt</a> <a href="byAffiliation.html#University of Duisburg-Essen" class="affiliation">University of Duisburg-Essen</a>,<br /><a href="byAuthors.html#Anind Dey" class="author">Anind Dey</a> <a href="byAffiliation.html#CMU" class="affiliation">CMU</a>,<br /><a href="byAuthors.html#Andrew Kun" class="author">Andrew Kun</a> <a href="byAffiliation.html#University of New Hampshire " class="affiliation">University of New Hampshire </a>,<br /><a href="byAuthors.html#Wolgang Spießl" class="author">Wolgang Spießl</a> <a href="byAffiliation.html#BMW Group Research and Technology" class="affiliation">BMW Group Research and Technology</a></div></div></td>

<td colspan="10" class="session_details" id="S81_details"><div class="paper"><span class="title">Where Should I Turn? Moving from Individual to Collaborative Navigation Strategies to Inform the Interaction Design of Future Navigation Systems</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jodi Forlizzi" class="author">Jodi Forlizzi</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Will Barley" class="author">Will Barley</a> <a href="byAffiliation.html#Northwestern University" class="affiliation">Northwestern University</a>,<br /><a href="byAuthors.html#Thomas Seder" class="author">Thomas Seder</a> <a href="byAffiliation.html#General Motors" class="affiliation">General Motors</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The design of in-vehicle navigation systems fails to take into account the social nature of driving and automobile navigation. In this paper, we consider navigation as a social activity among drivers and navigators to improve design of such systems. We explore the implications of moving from a map-centered, individually-focused design paradigm to one based upon collaborative human interaction during the navigation task. We conducted a qualitative interaction design study of navigation among three types of teams: parents and their teenage children, couples, and unacquainted individuals. We found that collaboration varied among these different teams, and was influenced by social role, as well as the task role of driver or navigator. We also found that patterns of prompts, maneuvers, and confirmations varied among the three teams. We identify overarching practices that differ greatly from the literature on individual navigation. From these discoveries, we present design implications that can be used to inform future navigation systems.</span></div></div><div class="paper"><span class="title">Studying Driver Attention and Behaviour for Three Configurations of GPS Navigation in Real Traffic Driving</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Brit Susan Jensen" class="author">Brit Susan Jensen</a> <a href="byAffiliation.html#Aalborg University" class="affiliation">Aalborg University</a>,<br /><a href="byAuthors.html#Mikael B. Skov" class="author">Mikael B. Skov</a> <a href="byAffiliation.html#Aalborg University" class="affiliation">Aalborg University</a>,<br /><a href="byAuthors.html#Nissanthen Thiruravichandran" class="author">Nissanthen Thiruravichandran</a> <a href="byAffiliation.html#Aalborg University" class="affiliation">Aalborg University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Global Positioning System (GPS) navigation systems were amongst the top selling consumer technologies in 2008 and research has indicated that such technologies could affect driving behaviour. In this paper, we study how different output configurations (audio, visual and audio-visual) of a GPS system affect driving behaviour and performance. We conducted field experiments in real traffic with 30 subjects. Our results illustrated that visual output not only causes a substantial amount of eye glances, but also led to a decrease in driving performance. Adding audio output decreased the number of eye glances, but we found no significant effects on driving performance. Although the audio configuration implied much fewer eye glances and improved driving performance, several participants expressed preference for the audio/visual output.</span></div></div><div class="paper"><span class="title">Cars, Calls and Cognition: Investigating Driving and Divided Attention</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Shamsi Iqbal" class="author">Shamsi Iqbal</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Yun-Cheng Ju" class="author">Yun-Cheng Ju</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Eric Horvitz" class="author">Eric Horvitz</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Conversing on cell phones while driving an automobile is a common practice. We examine the interference of the cognitive load of conversational dialog with driving tasks, with the goal of identifying better and worse times for conversations during driving. We present results from a controlled study involving 18 users using a driving simulator. The driving complexity and conversation type were manipulated in the study, and performance was measured for factors related to both the primary driving task and secondary conversation task. Results showed significant interactions between the primary and secondary tasks, where certain combinations of complexity and conversations were found especially detrimental to driving. We present the studies and analyses and relate the findings to prior work on multiple resource models of cognition. We discuss how the results can frame thinking about policies and technologies aimed at enhancing driving safety.  </span></div></div></td>

<td colspan="10" class="session_details" id="S79_details"><div class="paper"><span class="title">Constructing Identities through Storytelling in Diabetes Management</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Lena Mamykina" class="author">Lena Mamykina</a> <a href="byAffiliation.html#Columbia University" class="affiliation">Columbia University</a>,<br /><a href="byAuthors.html#Andrew Miller" class="author">Andrew Miller</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Elizabeth Mynatt" class="author">Elizabeth Mynatt</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Daniel Greenblatt" class="author">Daniel Greenblatt</a> <a href="byAffiliation.html#Smart Technologies" class="affiliation">Smart Technologies</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The continuing epidemics of diabetes and obesity create much need for information technologies that can help individuals engage in proactive health management. Yet many of these technologies focus on such pragmatic issues as collecting and presenting health information and modifying individuals' behavior. At the same time, researchers in clinical community argue that individuals' perception of their identity has dramatic consequences for their health behaviors. In this paper we discuss results of a deployment study of a mobile health monitoring application. We show how individuals with considerable diabetes experience found a unique way to adopt this health-monitoring application to construct and negotiate their identities as persons with a chronic disease.  We argue that viewing health management from identity construction perspective opens new opportunities for research and design in technologies for health.  </span></div></div><div class="paper"><span class="title">Self-Monitoring, Self-Awareness, and Self-Determination in Cardiac Rehabilitation</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Julie Maitland" class="author">Julie Maitland</a> <a href="byAffiliation.html#National Research Council Canada Institute for Information Technology" class="affiliation">National Research Council Canada Institute for Information Technology</a>,<br /><a href="byAuthors.html#Matthew Chalmers" class="author">Matthew Chalmers</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The application of self-monitoring technologies to the problem of promoting health-related behavioural change has been an active area of research for many years. This paper reports on our investigations into health-related behavioural change within the context of a cardiac rehabilitation programme, and considers the role that self-monitoring currently plays and may play in the future. We carried out semi-structured interviews with nineteen cardiac rehabilitation participants. Our main findings relate to distinctions between implicit and conscious change, tensions between cardiac rehabilitation and everyday life, the importance of self-awareness and self-determination, and an overall reluctance towards unnecessary self-monitoring. In view of these findings, we then offer suggestions as to how self-monitoring technologies can be designed to suit this particular context of use.</span></div></div><div class="paper"><span class="title">Negotiating Boundaries: Managing Disease at Home</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Rikke Aarhus" class="author">Rikke Aarhus</a> <a href="byAffiliation.html#Centre for Pervasive Healthcare  Department of Computer Science   Aarhus University" class="affiliation">Centre for Pervasive Healthcare  Department of Computer Science   Aarhus University</a>,<br /><a href="byAuthors.html#Stinne Aaløkke Ballegaard" class="author">Stinne Aaløkke Ballegaard</a> <a href="byAffiliation.html#Centre for Pervasive Healthcare  Department of Information and Media Studies   Aarhus University" class="affiliation">Centre for Pervasive Healthcare  Department of Information and Media Studies   Aarhus University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">To move treatment successfully from the hospital to that of technology assisted self-care at home, it is vital in the design of such technologies to understand the setting in which the health IT should be used. Based on qualitative studies we find that people engage in elaborate boundary work to maintain the order of the home when managing disease and adopting new healthcare technology. In our analysis we relate this boundary work to two continuums of visibility-invisibility and integration-segmentation in disease management. We explore five factors that affect the boundary work: objects, activities, places, character of disease, and collaboration. Furthermore, the processes are explored of how boundary objects move between social worlds pushing and shaping boundaries. From this we discuss design implications for future healthcare technologies for the home.</span></div></div></td>

<td colspan="10" class="session_details" id="S80_details"><div class="paper"><span class="title">Momentum: Getting and Staying on Topic Before the Brainstorm</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Patti Bao" class="author">Patti Bao</a> <a href="byAffiliation.html#Northwestern University" class="affiliation">Northwestern University</a>,<br /><a href="byAuthors.html#Elizabeth Gerber" class="author">Elizabeth Gerber</a> <a href="byAffiliation.html#Northwestern University" class="affiliation">Northwestern University</a>,<br /><a href="byAuthors.html#Darren Gergle" class="author">Darren Gergle</a> <a href="byAffiliation.html#Northwestern University" class="affiliation">Northwestern University</a>,<br /><a href="byAuthors.html#David Hoffman" class="author">David Hoffman</a> <a href="byAffiliation.html#Northwestern University" class="affiliation">Northwestern University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Despite the prevalent use of group brainstorming for problem solving and decision-making within organizations, brainstorming sessions often lack focus and fail to produce quality ideas. We describe Momentum, a tool that elicits topic-oriented responses prior to a group brainstorm. In an exploratory study of established groups, we found qualitative differences in task focus, quality and rate of ideation, and efficiency of storytelling between those who did and those who did not use the tool. </span></div></div><div class="paper"><span class="title">Layered Elaboration:  A New Technique for Co-Design with Children</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Gregory Walsh" class="author">Gregory Walsh</a> <a href="byAffiliation.html#Human-Computer Interaction Lab, University of Maryland" class="affiliation">Human-Computer Interaction Lab, University of Maryland</a>,<br /><a href="byAuthors.html#Allison Druin" class="author">Allison Druin</a> <a href="byAffiliation.html#Human-Computer Interaction Lab, University of Maryland" class="affiliation">Human-Computer Interaction Lab, University of Maryland</a>,<br /><a href="byAuthors.html#Mona Leigh Guha" class="author">Mona Leigh Guha</a> <a href="byAffiliation.html#Human-Computer Interaction Lab, University of Maryland" class="affiliation">Human-Computer Interaction Lab, University of Maryland</a>,<br /><a href="byAuthors.html#Beth Foss" class="author">Beth Foss</a> <a href="byAffiliation.html#Human-Computer Interaction Lab, University of Maryland" class="affiliation">Human-Computer Interaction Lab, University of Maryland</a>,<br /><a href="byAuthors.html#Evan Golub" class="author">Evan Golub</a> <a href="byAffiliation.html#Human-Computer Interaction Lab, University of Maryland" class="affiliation">Human-Computer Interaction Lab, University of Maryland</a>,<br /><a href="byAuthors.html#Leshell Hatley" class="author">Leshell Hatley</a> <a href="byAffiliation.html#Human-Computer Interaction Lab, University of Maryland" class="affiliation">Human-Computer Interaction Lab, University of Maryland</a>,<br /><a href="byAuthors.html#Beth Bonsignore" class="author">Beth Bonsignore</a> <a href="byAffiliation.html#Human-Computer Interaction Lab, University of Maryland" class="affiliation">Human-Computer Interaction Lab, University of Maryland</a>,<br /><a href="byAuthors.html#Sonia Franckel" class="author">Sonia Franckel</a> <a href="byAffiliation.html#Human-Computer Interaction Lab, University of Maryland" class="affiliation">Human-Computer Interaction Lab, University of Maryland</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">As technology for children becomes more mobile, social, and distributed, our design methods and techniques must evolve to better explore these new directions. This paper reports on Layered Elaboration, a co-design technique created to support these evolving needs. .Layered Elaboration allows design teams to generate ideas through an iterative process in which each version leaves prior ideas intact while extending concepts. Layered Elaboration is a useful technique as it enables co-design to take place asynchronously and does not require much space or many resources. Our intergenerational team, including adults and children ages 7 - 11 years old, used the technique to design both a game about history and a prototype of an instructional game about energy conservation.</span></div></div><div class="paper"><span class="title">Don't Just Stare at Me!</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ning Wang" class="author">Ning Wang</a> <a href="byAffiliation.html#University of Southern California" class="affiliation">University of Southern California</a>,<br /><a href="byAuthors.html#Jonathan Gratch" class="author">Jonathan Gratch</a> <a href="byAffiliation.html#University of Southern California" class="affiliation">University of Southern California</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Communication is more effective and persuasive when participants establish rapport. Tickle-Degnen and Rosenthal [57] argue rapport arises when participants exhibit mutual attentiveness, positivity and coordination. In this paper, we investigate how these factors relate to perceptions of rapport when users interact via avatars in virtual worlds.  In this study, participants told a story to what they believed was the avatar of another participant. In fact, the avatar was a computer program that systematically manipulated levels of attentiveness, positivity and coordination. In contrast to Tickel-Degnen and Rosenthal's findings, high-levels of mutual attentiveness alone can dramatically lower perceptions of rapport in avatar communication. Indeed, an agent that attempted to maximize mutual attention performed as poorly as an agent that was designed to convey boredom.  Adding positivity and coordination to mutual attentiveness, on the other hand, greatly improved rapport. This work unveils the dependencies between components of rapport and informs the design of agents and avatars in computer mediated communication.</span></div></div><div class="paper"><span class="title">Video Playdate: Toward Free Play across Distance</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Svetlana Yarosh" class="author">Svetlana Yarosh</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Kori Inkpen" class="author">Kori Inkpen</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#A.J. Brush" class="author">A.J. Brush</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present an empirical investigation of video-mediated free play between 13 pairs of friends (ages 7 and 8). The pairs spent 10 minutes playing with each of four different prototypes we developed to support free play over videoconferencing. We coded each interaction for the types of play and the amount of social play observed. The children in our study were largely successful in playing together across videoconferencing, though challenges in managing visibility, attention, and intersubjectivity made it more difficult than face-to-face play. We also found that our prototypes supported some types of play to varying degrees. Our contribution lies in identifying these design tradeoffs and providing directions for future design of video-mediated communication systems for children.</span></div></div></td>

<td colspan="10" class="session_details" id="S83_details"><div class="paper"><span class="title">Integrating Text with Video and 3D Graphics: The Effects of Text Drawing Styles on Text Readability</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jacek Jankowski" class="author">Jacek Jankowski</a> <a href="byAffiliation.html#Digital Enterprise Research Institute, National University of Ireland" class="affiliation">Digital Enterprise Research Institute, National University of Ireland</a>,<br /><a href="byAuthors.html#Krystian Samp" class="author">Krystian Samp</a> <a href="byAffiliation.html#Digital Enterprise Research Institute, National University of Ireland" class="affiliation">Digital Enterprise Research Institute, National University of Ireland</a>,<br /><a href="byAuthors.html#Izabela Irzynska" class="author">Izabela Irzynska</a> <a href="byAffiliation.html#Digital Enterprise Research Institute, National University of Ireland" class="affiliation">Digital Enterprise Research Institute, National University of Ireland</a>,<br /><a href="byAuthors.html#Marek Jozwowicz" class="author">Marek Jozwowicz</a> <a href="byAffiliation.html#Digital Enterprise Research Institute, National University of Ireland" class="affiliation">Digital Enterprise Research Institute, National University of Ireland</a>,<br /><a href="byAuthors.html#Stefan Decker" class="author">Stefan Decker</a> <a href="byAffiliation.html#Digital Enterprise Research Institute, National University of Ireland" class="affiliation">Digital Enterprise Research Institute, National University of Ireland</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">There have been many studies of computer based text reading. However, only a few have considered text integrated with video and 3D graphics. This paper presents an investigation into the effects of varying (a) text drawing style (plain, billboard, Anti-Interference, shadow), (b) image polarity (positive and negative), and (c) background style (video and 3D) on text readability. Reading speed and accuracy were measured and subjective views of participants recorded.   Results showed that: (a) there was little difference in reading performance for the video and 3D backgrounds; (b) the negative presentation outperformed the positive presentation; (c) the billboard drawing styles supported the best performance; subjective comments showed a preference for the billboard style. We therefore suggest, for reading tasks, that designers of interfaces for games, video, and augmented reality provide billboard style to maximize readability for the widest range of applications.</span></div></div><div class="paper"><span class="title">Apatite: A New Interface for Exploring APIs</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Daniel S. Eisenberg" class="author">Daniel S. Eisenberg</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Jeffrey Stylos" class="author">Jeffrey Stylos</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Brad A. Myers" class="author">Brad A. Myers</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present Apatite, a new tool that aids users in learning and understanding a complex API by visualizing the common associations between its various components. Current object-oriented API documentation is usually navigated in a fixed tree structure, starting with a package and then filtering by a specific class. For large APIs, this scheme is overly restrictive, because it prevents users from locating a particular action without first knowing which class it belongs to. Apatite's design instead enables users to search across any level of an API's hierarchy. This is made possible by the introduction of a novel interaction technique that presents popular items from multiple categories simultaneously, determining their relevance by approximating the strength of their association using search engine data. The design of Apatite was refined through iterative usability testing, and it has been released publicly as a web application.</span></div></div><div class="paper"><span class="title">Push-and-Pull Switching: Window Switching based on Window Overlapping</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Quan Xu" class="author">Quan Xu</a> <a href="byAffiliation.html#LIFL &amp; INRIA Lille  University of Lille, France" class="affiliation">LIFL &amp; INRIA Lille  University of Lille, France</a>,<br /><a href="byAuthors.html#Géry Casiez" class="author">Géry Casiez</a> <a href="byAffiliation.html#LIFL &amp; INRIA Lille  University of Lille, France" class="affiliation">LIFL &amp; INRIA Lille  University of Lille, France</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We propose Push-and-Pull Switching, a window switching technique using window overlapping to implicitly define groups. Push-and-Pull Switching enables switching between groups and restacking the focused window to any position to change its group membership. The technique was evaluated in an experiment which found that Push-and-Pull Switching improves switching performance by more than 50% compared to other switching techniques in different scenarios. A longitudinal user study indicates that participants invoked this switching technique 15% of the time on single monitor displays and that they found it easy to understand and use.</span></div></div><div class="paper"><span class="title">Animated UI Transitions and Perception of Time - a User Study on Animated Effects on a Mobile Screen</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Jussi Huhtala" class="author">Jussi Huhtala</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Ari-Heikki Sarjanoja" class="author">Ari-Heikki Sarjanoja</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Jani Mäntyjärvi" class="author">Jani Mäntyjärvi</a> <a href="byAffiliation.html#Technical Research Centre of Finland" class="affiliation">Technical Research Centre of Finland</a>,<br /><a href="byAuthors.html#Minna Isomursu" class="author">Minna Isomursu</a> <a href="byAffiliation.html#Technical Research Centre of Finland" class="affiliation">Technical Research Centre of Finland</a>,<br /><a href="byAuthors.html#Jonna Häkkilä" class="author">Jonna Häkkilä</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The capability to present advanced graphics in the present mobile devices can be utilized to improve their usability and overall user experience. Mobile devices have limitations compared to PCs due to their inferior computing power and small screens, but a successful design of animated transitions can hide processing delays and make the user experience smoother. In this paper, we describe the design of animated transitions and present a user study on how they are perceived. The results show that in the transition between two images, bringing up the next image earlier dominates the perception of a fast transition over other variables examined in the study.</span></div></div></td>

</tr>
</table>
</div>
<div class="day" id="04/14/10">
<h1>Wednesday, April 14</h1>
<table cellspacing="0" class="program">
<tr class="timeslot">
<td class="time">9:00&nbsp;AM<br/><em>to</em><br/>10:30&nbsp;AM</td>
<td class="session" id="S24">
<span class="type">Panel</span>
<span class="title">Managing User Experience...Managing Change</span>
<span class="location">Centennial 2</span>
</td>
<td class="session" id="S89">
<span class="type">Papers/Notes</span>
<span class="title">Looking with Video</span>
<span class="location">Centennial 3</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S91">
<span class="type">Papers/Notes</span>
<span class="title">Privacy</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S13">
<span class="type">SIG</span>
<span class="title">How to bring HCI Research and Practice Closer Together</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S92">
<span class="type">Papers/Notes</span>
<span class="title">Storytelling</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S88">
<span class="type">Papers/Notes</span>
<span class="title">Humans and Sociability</span>
<span class="location">Hanover FG</span>
</td>
<td class="session" id="S87">
<span class="type">Papers/Notes</span>
<span class="title">Expressing and Understanding Opinions in Social Media</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S90">
<span class="type">Papers/Notes</span>
<span class="title">Pixels and Perception</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S86">
<span class="type">Papers/Notes</span>
<span class="title">Bang a Table</span>
<span class="location">Regency 7</span>
</td>
</tr>
<tr class="details_row">

<td colspan="9" class="session_details" id="S24_details"><div class="paper"><span class="title">Managing User Experience... Managing Change</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Carola Thompson" class="author">Carola Thompson</a> <a href="byAffiliation.html#SAP Labs, LLC" class="affiliation">SAP Labs, LLC</a>,<br /><a href="byAuthors.html#Richard Anderson" class="author">Richard Anderson</a> <a href="byAffiliation.html#Independent" class="affiliation">Independent</a>,<br /><a href="byAuthors.html#Irene Au" class="author">Irene Au</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a>,<br /><a href="byAuthors.html#Cordell Ratzlaff" class="author">Cordell Ratzlaff</a> <a href="byAffiliation.html#Cisco" class="affiliation">Cisco</a></div></div></td>

<td colspan="9" class="session_details" id="S89_details"><div class="paper"><span class="title">Temporal hybridity: Mixing live video footage  with instant replay in real time</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Arvid Engstrom" class="author">Arvid Engstrom</a> <a href="byAffiliation.html#Mobility Studio, Interactive Institute" class="affiliation">Mobility Studio, Interactive Institute</a>,<br /><a href="byAuthors.html#Oskar Juhlin" class="author">Oskar Juhlin</a> <a href="byAffiliation.html#Mobility Studio, Interactive Institute" class="affiliation">Mobility Studio, Interactive Institute</a>,<br /><a href="byAuthors.html#Mark Perry" class="author">Mark Perry</a> <a href="byAffiliation.html#Brunel University" class="affiliation">Brunel University</a>,<br /><a href="byAuthors.html#Mathias Broth" class="author">Mathias Broth</a> <a href="byAffiliation.html#Linköping University" class="affiliation">Linköping University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we explore the production of streaming media that involves live and recorded content. To examine this, we report on how the production practices and process are conducted through an empirical study of the production of live television, involving the use of live and non-live media under highly time critical conditions. In explaining how this process is managed both as an individual and collective activity, we develop the concept of temporal hybridity to explain the properties of these kinds of production system and show how temporally separated media are used, understood and coordinated. Our analysis is examined in the light of recent developments in computing technology and we present some design implications to support amateur video production.</span></div></div><div class="paper"><span class="title">Experience, Adjustment, and Engagement:  The Role of Video in Law Enforcement</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Joe Tullio" class="author">Joe Tullio</a> <a href="byAffiliation.html#Motorola, Inc." class="affiliation">Motorola, Inc.</a>,<br /><a href="byAuthors.html#Elaine Huang" class="author">Elaine Huang</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a>,<br /><a href="byAuthors.html#David Wheatley" class="author">David Wheatley</a> <a href="byAffiliation.html#Motorola, Inc." class="affiliation">Motorola, Inc.</a>,<br /><a href="byAuthors.html#Harry Zhang" class="author">Harry Zhang</a> <a href="byAffiliation.html#Motorola, Inc." class="affiliation">Motorola, Inc.</a>,<br /><a href="byAuthors.html#Claudia Guerrero" class="author">Claudia Guerrero</a> <a href="byAffiliation.html#Motorola, Inc." class="affiliation">Motorola, Inc.</a>,<br /><a href="byAuthors.html#Amruta Tamdoo" class="author">Amruta Tamdoo</a> <a href="byAffiliation.html#University of Illinois, Chicago" class="affiliation">University of Illinois, Chicago</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Questions about the effectiveness of increasingly ubiquitous video technology in law enforcement have prompted an examination of the practices surrounding this technology. We present the results of a multi-site study aimed at understanding the use of video in several phases of law enforcement, from crime prevention and response to investigation and prosecution. Our findings show that while video has provided numerous benefits to law enforcement agencies, in many cases the technology either fails to support key facets of work or introduces new tasks that present an additional burden to workers. We discuss the need to incorporate human experience and tacit knowledge, operator engagement, and the greater ecosystem of work into video deployments.</span></div></div><div class="paper"><span class="title">ToolClips: An Investigation of Contextual Video Assistance for Functionality Understanding</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Tovi Grossman" class="author">Tovi Grossman</a> <a href="byAffiliation.html#Autodesk Research" class="affiliation">Autodesk Research</a>,<br /><a href="byAuthors.html#George Fitzmaurice" class="author">George Fitzmaurice</a> <a href="byAffiliation.html#Autodesk Research" class="affiliation">Autodesk Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We investigate the use of on-line contextual video assistance to improve the learnability of software functionality. After discussing motivations and design goals for such forms of assistance, we present our new technique, ToolClips. ToolClips augment traditional tooltips to provide users with quick and contextual access to both textual and video assistance. In an initial study we found that users successfully integrated ToolClip usage into the flow of their primary tasks to overcome learnability difficulties. In a second study, we found that with ToolClips, users successfully completed 7 times as many unfamiliar tasks, in comparison to using a commercial professionally developed on-line help system.  Users also retained the information obtained from ToolClips, performing tasks significantly faster one week later. </span></div></div></td>

<td colspan="9" class="session_details" id="S91_details"><div class="paper"><span class="title">Friends Only: Examining a Privacy-Enhancing Behavior in Facebook</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Fred Stutzman" class="author">Fred Stutzman</a> <a href="byAffiliation.html#UNC-Chapel Hill" class="affiliation">UNC-Chapel Hill</a>,<br /><a href="byAuthors.html#Jacob Kramer-Duffield" class="author">Jacob Kramer-Duffield</a> <a href="byAffiliation.html#UNC-Chapel Hill" class="affiliation">UNC-Chapel Hill</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Privacy practices in social network sites often appear paradoxical, as content-sharing behavior stands in conflict with the need to reduce disclosure-related harms.  In this study we explore privacy in social network sites as a contextual information practice, managed by a process of boundary regulation.  Drawing on a sample survey of undergraduate Facebook users, we examine a particular privacy-enhancing practice: having a friends-only Facebook profile.  Particularly, we look at the association between network composition, expectancy violations, interpersonal privacy practices and having a friends-only profile.  We find that expectancy violations by weak ties and increased levels of interpersonal privacy management are positively associated with having a friends-only profile.  We conclude with a discussion of how these findings may be integrated into the design of systems to facilitate interaction while enhancing individual privacy. </span></div></div><div class="paper"><span class="title">Moving Beyond Untagging: Photo Privacy in a Tagged World</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Andrew Besmer" class="author">Andrew Besmer</a> <a href="byAffiliation.html#University of North Carolina at Charlotte" class="affiliation">University of North Carolina at Charlotte</a>,<br /><a href="byAuthors.html#Heather Richter Lipford" class="author">Heather Richter Lipford</a> <a href="byAffiliation.html#University of North Carolina at Charlotte" class="affiliation">University of North Carolina at Charlotte</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Photo tagging is a popular feature of many social network sites that allows users to annotate uploaded images with those who are in them, explicitly linking the photo to each person's profile. In this paper, we examine privacy concerns and mechanisms surrounding these tagged images. Using a focus group, we explored the needs and concerns of users, resulting in a set of design considerations for tagged photo privacy. We then designed a privacy enhancing mechanism based on our findings, and validated it using a mixed methods approach. Our results identify the social tensions that tagging generates, and the needs of privacy tools to address the social implications of photo privacy management.</span></div></div><div class="paper"><span class="title">Standardizing Privacy Notices:  An Online Study of the Nutrition Label Approach</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Patrick Gage Kelley" class="author">Patrick Gage Kelley</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Lucian Cesca" class="author">Lucian Cesca</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Joanna Bresee" class="author">Joanna Bresee</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Lorrie Faith Cranor" class="author">Lorrie Faith Cranor</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Earlier work has shown that consumers cannot effectively find information in privacy policies and that they do not enjoy using them. In our previous research we developed a standardized-table format for privacy policies. We compared this standardized format, and two short variants (one tabular, one text) with the current status quo: full-text natural-language policies and layered policies. We conducted an online user study of 764 participants to test if these three more-intentionally designed, standardized privacy policy formats, assisted by consumer education, can benefit consumers. Our results show that standardized privacy policy presentations can have significant positive effects on accuracy and speed of information finding and on reader enjoyment of privacy policies.</span></div></div></td>

<td colspan="9" class="session_details" id="S13_details"><div class="paper"><span class="title">How to bring HCI Research and Practice Closer Together</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Keith Instone" class="author">Keith Instone</a> <a href="byAffiliation.html#IBM" class="affiliation">IBM</a>,<br /><a href="byAuthors.html#Elizabeth Buie" class="author">Elizabeth Buie</a> <a href="byAffiliation.html#Luminanze Consulting" class="affiliation">Luminanze Consulting</a>,<br /><a href="byAuthors.html#Susan Dray" class="author">Susan Dray</a> <a href="byAffiliation.html#Dray &amp; Associates" class="affiliation">Dray &amp; Associates</a>,<br /><a href="byAuthors.html#Jhilmil Jain" class="author">Jhilmil Jain</a> <a href="byAffiliation.html#HP" class="affiliation">HP</a>,<br /><a href="byAuthors.html#Gitte Lindgaard" class="author">Gitte Lindgaard</a> <a href="byAffiliation.html#Carleton University" class="affiliation">Carleton University</a>,<br /><a href="byAuthors.html#Arnie Lund" class="author">Arnie Lund</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a></div></div></td>

<td colspan="9" class="session_details" id="S92_details"><div class="paper"><span class="title">Family Story Play: Reading with Young Children (and Elmo) Over a Distance</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Hayes Raffle" class="author">Hayes Raffle</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Rafael &quot;Tico&quot; Ballagas" class="author">Rafael &quot;Tico&quot; Ballagas</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Glenda Revelle" class="author">Glenda Revelle</a> <a href="byAffiliation.html#Joan Ganz Cooney Center at Sesame Workshop" class="affiliation">Joan Ganz Cooney Center at Sesame Workshop</a>,<br /><a href="byAuthors.html#Hiroshi Horii" class="author">Hiroshi Horii</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Sean Follmer" class="author">Sean Follmer</a> <a href="byAffiliation.html#MIT Media Lab" class="affiliation">MIT Media Lab</a>,<br /><a href="byAuthors.html#Janet Go" class="author">Janet Go</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Emily Reardon" class="author">Emily Reardon</a> <a href="byAffiliation.html#Sesame Workshop" class="affiliation">Sesame Workshop</a>,<br /><a href="byAuthors.html#Koichi Mori" class="author">Koichi Mori</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Joseph &quot;Jofish&quot; Kaye" class="author">Joseph &quot;Jofish&quot; Kaye</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Mirjana Spasojevic" class="author">Mirjana Spasojevic</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We introduce Family Story Play, a system that supports grandparents to read books together with their grandchildren over the Internet. Family Story Play is designed to improve communication across generations and over a distance, and to support parents and grandparents in fostering the literacy development of young children. The interface encourages active child participation in the book reading experience by combining a paper book, a sensor-enhanced frame, video conferencing technology, and video content of a Sesame Street Muppet (Elmo). Results with users indicate that Family Story Play improves child engagement in long-distance communication and increases the quality of interaction between young children and distant grandparents. Additionally, Family Story Play encourages dialogic reading styles that are linked with literacy development. Ultimately, reading with Family Story Play becomes a creative shared activity that suggests a new kind of collaborative story telling.  </span></div></div><div class="paper"><span class="title">Designing with Mobile Digital Storytelling in Rural Africa</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Nicola J Bidwell" class="author">Nicola J Bidwell</a> <a href="byAffiliation.html#UCT Centre in ICT4D &amp; James Cook University" class="affiliation">UCT Centre in ICT4D &amp; James Cook University</a>,<br /><a href="byAuthors.html#Thomas Reitmaier" class="author">Thomas Reitmaier</a> <a href="byAffiliation.html#UCT Centre in ICT4D" class="affiliation">UCT Centre in ICT4D</a>,<br /><a href="byAuthors.html#Gary Marsden" class="author">Gary Marsden</a> <a href="byAffiliation.html#UCT Centre in ICT4D" class="affiliation">UCT Centre in ICT4D</a>,<br /><a href="byAuthors.html#Susan Hansen" class="author">Susan Hansen</a> <a href="byAffiliation.html#University of Technology Sydney &amp; CSIRO ICT Centre" class="affiliation">University of Technology Sydney &amp; CSIRO ICT Centre</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We reflect on activities to design a mobile application to enable rural people in South Africa's Eastern Cape to record and share their stories, which have implications for cross-cultural design,' and the wider use of stories in design. We based our initial concept for generating stories with audio and photos on cell-phones on a scenario informed by abstracting from digital storytelling projects globally and our personal experience. But insights from ethnography, and technology experiments involving storytelling, in a rural village led us to query our grounding assumptions and usability criteria. So, we implemented a method using cell-phones to localise storytelling, involve rural users and probe ways to incorporate visual and audio media. Products from this method helped us to generate design ideas for our current prototype which offers great flexibility. Thus we present a new way to depict stories digitally and a process for improving such software. </span></div></div><div class="paper"><span class="title">Let's Play Chinese Characters - Mobile Learning Approaches via Culturally Inspired Group Games</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Feng Tian" class="author">Feng Tian</a> <a href="byAffiliation.html#Institute of Software, Chinese Academy of Sciences" class="affiliation">Institute of Software, Chinese Academy of Sciences</a>,<br /><a href="byAuthors.html#Fei Lv" class="author">Fei Lv</a> <a href="byAffiliation.html#Institute of Software, Chinese Academy of Sciences" class="affiliation">Institute of Software, Chinese Academy of Sciences</a>,<br /><a href="byAuthors.html#Jingtao Wang" class="author">Jingtao Wang</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#Hongan Wang" class="author">Hongan Wang</a> <a href="byAffiliation.html#Institute of Software, Chinese Academy of Sciences" class="affiliation">Institute of Software, Chinese Academy of Sciences</a>,<br /><a href="byAuthors.html#Wencan Luo" class="author">Wencan Luo</a> <a href="byAffiliation.html#Institute of Software, Chinese Academy of Sciences" class="affiliation">Institute of Software, Chinese Academy of Sciences</a>,<br /><a href="byAuthors.html#Matthew Kam" class="author">Matthew Kam</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Vidya Setlur" class="author">Vidya Setlur</a> <a href="byAffiliation.html#Nokia Research Palo Alto" class="affiliation">Nokia Research Palo Alto</a>,<br /><a href="byAuthors.html#Guozhong Dai" class="author">Guozhong Dai</a> <a href="byAffiliation.html#Institute of Software, Chinese Academy of Sciences" class="affiliation">Institute of Software, Chinese Academy of Sciences</a>,<br /><a href="byAuthors.html#John Canny" class="author">John Canny</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In many developing countries such as India and China, low educational levels often hinder economic empowerment. In this paper, we argue that mobile learning games can play an important role in the Chinese literacy acquisition process. We report on the unique challenges in the learning Chinese language, especially its logographic writing system.  Based on an analysis of 25 traditional Chinese games currently played by children in China, we present the design and implementation of two culturally inspired mobile group learning games, Multimedia Word and Drumming Strokes. These two mobile games are designed to match Chinese children's understanding of everyday games. An informal evaluation reveals that these two games have the potential to enhance the intuitiveness and engagement of traditional games, and children may improve their knowledge of Chinese characters through group learning activities such as controversy, judgments and self-correction during the game play.</span></div></div></td>

<td colspan="9" class="session_details" id="S88_details"><div class="paper"><span class="title">Propitious Aggregation: Reducing Participant Burden in Ego-centric Network Data Collection</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Derek Lackaff" class="author">Derek Lackaff</a> <a href="byAffiliation.html#University of Texas at Austin" class="affiliation">University of Texas at Austin</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">One of the central challenges of ego-centric or personal social network research is minimizing the quantity of data that is requested from research participants while ensuring high data accuracy and validity. In general, collecting data about increasingly larger ego-centric networks places an increasing burden on respondents. The web-based Propitious Aggregation of Social Networks (PASN, http://pro.pitio.us) survey instrument reduces this burden by leveraging network data already available in the context of social network websites, and by providing an intuitive click-and-drag interface for survey responses. An experiment was conducted (N  = 85), and the PASN method was found to produce networks which were significantly larger and more diverse than those produced using standard survey methods, yet required significantly lower time investments from participants.</span></div></div><div class="paper"><span class="title">Trying Too Hard? Effects of Mobile Agents' (Inappropriate) Social Expressiveness on Trust, Affect and Compliance.</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Henriette Cramer" class="author">Henriette Cramer</a> <a href="byAffiliation.html#University of Amsterdam, Mobile Life Centre &amp; SICS" class="affiliation">University of Amsterdam, Mobile Life Centre &amp; SICS</a>,<br /><a href="byAuthors.html#Vanessa Evers" class="author">Vanessa Evers</a> <a href="byAffiliation.html#University of Amsterdam" class="affiliation">University of Amsterdam</a>,<br /><a href="byAuthors.html#Tim Van Slooten" class="author">Tim Van Slooten</a> <a href="byAffiliation.html#University of Amsterdam" class="affiliation">University of Amsterdam</a>,<br /><a href="byAuthors.html#Mattijs Ghijsen" class="author">Mattijs Ghijsen</a> <a href="byAffiliation.html#University of Amsterdam" class="affiliation">University of Amsterdam</a>,<br /><a href="byAuthors.html#Bob Wielinga" class="author">Bob Wielinga</a> <a href="byAffiliation.html#University of Amsterdam" class="affiliation">University of Amsterdam</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Mobile services can provide users with information relevant to their current circumstances. Distant services in turn can acquire local information from people in an area of interest. Socially expressive agent behaviour has been suggested as a way to build reciprocal relationships and to increase user response to such requests. This between-subject, Wizard-of-Oz experiment aimed to investigate the potential of such behaviours. 44 participants performed a search task in an urgent context while being interrupted by a mobile agent that both provided and requested information. The socially expressive behaviour shown in this study did not increase compliance to requests; it instead reduced trust in provided information and compliance to warnings. It also negatively impacted the affective experience of users scoring lower on empathy as a personality trait. Inappropriate social expressiveness can have serious consequences; we here elaborate on the reasons for our negative results. </span></div></div><div class="paper"><span class="title">A Simple Index for Multimodal Flexibility</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Antti Oulasvirta" class="author">Antti Oulasvirta</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology HIIT" class="affiliation">Helsinki Institute for Information Technology HIIT</a>,<br /><a href="byAuthors.html#Joanna Bergstrom-Lehtovirta" class="author">Joanna Bergstrom-Lehtovirta</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology HIIT" class="affiliation">Helsinki Institute for Information Technology HIIT</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Most interactive tasks engage more than one of the user's exteroceptive senses and are therefore multimodal. In real world situations with multitasking and distractions, the key aspect of multimodality is not which modalities can be allocated to the interactive task but which are free to be allocated to something else. We present the multimodal flexibility index (MFI), calculated from changes in users' performance induced by blocking of sensory modalities. A high score indicates that the highest level of performance is achievable regardless of the modalities available and, conversely, a low score that performance will be severely hampered unless all modalities are allocated to the task. Various derivatives describe unimodal and bimodal effects. Results from a case study (mobile text entry) illustrate how an interface that is superior to others in absolute terms is the worst from the multimodal flexibility perspective. We discuss the suitability of MFI for evaluation of interactive prototypes.</span></div></div><div class="paper"><span class="title">Social Gravity: A Virtual Elastic Tether for Casual, Privacy-Preserving Pedestrian Rendezvous</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#John Williamson" class="author">John Williamson</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Simon Robinson" class="author">Simon Robinson</a> <a href="byAffiliation.html#Swansea University" class="affiliation">Swansea University</a>,<br /><a href="byAuthors.html#Craig Stewart" class="author">Craig Stewart</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Rod Murray-Smith" class="author">Rod Murray-Smith</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Matt Jones" class="author">Matt Jones</a> <a href="byAffiliation.html#Swansea University" class="affiliation">Swansea University</a>,<br /><a href="byAuthors.html#Stephen Brewster" class="author">Stephen Brewster</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We describe a virtual tether for mobile devices that allows  groups to have quick, simple and privacy-preserving meetups.  Our design provides cues which allow dynamic coordination  of rendezvous without revealing user's positions.  Using accelerometers and magnetometers, combined with  GPS positioning and non-visual feedback, users can probe  and sense a dynamic virtual object representing the nearest  meeting point. The Social Gravity system makes social  bonds tangible in a virtual world which is geographically  grounded, using haptic feedback to help users rendezvous.  We show dynamic navigation using this physical  model-based system to be efficient and robust in significant  field trials, even in the presence of low-quality positioning.  The use of simulators to build models of mobile geolocated  systems for pre-validation purposes is discussed, and results  compared with those from our trials. Our results show interesting  behaviours in the social coordination task, which  lead to guidelines for geosocial interaction design. The Social  Gravity system proved to be very successful in allowing  groups to rendezvous efficiently and simply and can be implemented  using only commercially available hardware.</span></div></div></td>

<td colspan="9" class="session_details" id="S87_details"><div class="paper"><span class="title">'America Is Like Metamucil': Fostering Critical and Creative Thinking about Metaphor in Political Blogs</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Eric P. S. Baumer" class="author">Eric P. S. Baumer</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Jordan Sinclair" class="author">Jordan Sinclair</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Bill Tomlinson" class="author">Bill Tomlinson</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Blogs are becoming an increasingly important mediumsocially, academically, and politically. Much research has involved analyzing blogs, but less work has considered how such analytic techniques might be incorporated into tools for blog readers. A new tool, metaViz, analyzes political blogs for potential conceptual metaphors and presents them to blog readers. This paper presents a study exploring the types of critical and creative thinking fostered by metaViz as evidenced by user comments and discussion on the system. These results indicate the effectiveness of various system features at fostering critical thinking and creativity, specifically in terms of deep, structural reasoning about metaphors and creatively extending existing metaphors. Furthermore, the results carry broader implications beyond blogs and politics about exploring alternate configurations between computation and human thought.</span></div></div><div class="paper"><span class="title">Understanding Dispute Resolution Online: Using Text to Reflect Personal and Substantive Issues in Conflict</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Matt Billings" class="author">Matt Billings</a> <a href="byAffiliation.html#University of Bath" class="affiliation">University of Bath</a>,<br /><a href="byAuthors.html#Leon Watts" class="author">Leon Watts</a> <a href="byAffiliation.html#University of Bath" class="affiliation">University of Bath</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Conflict is a natural part of human communication with implications for the work and well-being of a community. It can cause projects to stall or fail. Alternatively new insights can be produced that are valuable to the community, and membership can be strengthened. We describe how Wikipedia mediators create and maintain a safe space'. They help conflicting parties to express, recognize and respond positively to their personal and substantive differences. We show how the mutability' of wiki text can be used productively by mediators: to legitimize and restructure the personal and substantive issues under dispute; to actively and visibly differentiate personal from substantive elements in the dispute, and to maintain asynchronous engagement by adjusting expectations of timeliness. We argue that online conflicts could be effectively conciliated in other text-based web communities, provided power differences can be controlled, by policies and technical measures for maintaining special safe' conflict resolution spaces. </span></div></div><div class="paper"><span class="title">Presenting Diverse Political Opinions: How and How Much</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sean Munson" class="author">Sean Munson</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Paul Resnick" class="author">Paul Resnick</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Is a polarized society inevitable, where people choose to be exposed to only political news and commentary that reinforces their existing viewpoints? We examine the relationship between the numbers of supporting and challenging items in a collection of political opinion items and readers' satisfaction, and then evaluate whether simple presentation techniques such as highlighting agreeable items or showing them first can increase satisfaction when fewer agreeable items are present. We find individual differences: some people are diversity-seeking while others are challenge-averse. For challenge-averse readers, highlighting appears to make satisfaction with sets of mostly agreeable items more extreme, but does not increase satisfaction overall, and sorting agreeable content first appears to decrease satisfaction rather than increasing it. These findings have important implications for builders of websites that aggregate content reflecting different positions.</span></div></div></td>

<td colspan="9" class="session_details" id="S90_details"><div class="paper"><span class="title">Prefab: Implementing Advanced Behaviors Using Pixel-Based Reverse Engineering of Interface Structure</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Morgan Dixon" class="author">Morgan Dixon</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#James Fogarty" class="author">James Fogarty</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Current chasms between applications implemented with different user interface toolkits make it difficult to implement and explore potentially important interaction techniques in new and existing applications, limiting the progress and impact of human-computer interaction research. This work examines an approach based in the single largest common characteristic of all user interface toolkits, that they ultimately paint pixels. We present Prefab, a system for implementing advanced behaviors through the reverse engineering of the pixels in an interface. Informed by how user interface toolkits paint interfaces, our architecture features a separation of the modeling of widget layout from the recognition of widget appearance. We validate Prefab in implementations of three applications: target-aware pointing techniques, Phosphor transitions, and Side Views parameter spectrums. Working only from pixels, we demonstrate a single implementation of these enhancements in complex existing applications created in different user interface toolkits running on different windowing systems.</span></div></div><div class="paper"><span class="title">GUI Testing Using Computer Vision</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Tsung-Hsiang Chang" class="author">Tsung-Hsiang Chang</a> <a href="byAffiliation.html#MIT CSAIL" class="affiliation">MIT CSAIL</a>,<br /><a href="byAuthors.html#Tom Yeh" class="author">Tom Yeh</a> <a href="byAffiliation.html#UMIACS &amp; HCIL, University of Maryland" class="affiliation">UMIACS &amp; HCIL, University of Maryland</a>,<br /><a href="byAuthors.html#Robert Miller" class="author">Robert Miller</a> <a href="byAffiliation.html#MIT CSAIL" class="affiliation">MIT CSAIL</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Testing a GUI's visual behavior typically requires human testers to interact with the GUI and to observe whether the expected results of interaction are presented. This paper presents a new approach to GUI testing using computer vision for testers to automate their tasks. Testers can write a visual test script that uses images to specify which GUI components to interact with and what visual feedback to be observed. Testers can also generate visual test scripts by demonstration. By recording both input events and screen images, it is possible to extract the images of components interacted with and the visual feedback seen by the demonstrator, and generate a visual test script automatically. We show that a variety of GUI behavior can be tested using this approach. Also, we show how this approach can facilitate good testing practices such as unit testing, regression testing, and test-driven development.</span></div></div><div class="paper"><span class="title">Faster Progress Bars: Manipulating Perceived Duration with Visual Augmentations</span> - <span class="type">Note</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Chris Harrison" class="author">Chris Harrison</a> <a href="byAffiliation.html#Human-Computer Interaction Institute, Carnegie Mellon University" class="affiliation">Human-Computer Interaction Institute, Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Zhiquan Yeo" class="author">Zhiquan Yeo</a> <a href="byAffiliation.html#Human-Computer Interaction Institute, Carnegie Mellon University" class="affiliation">Human-Computer Interaction Institute, Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Scott E. Hudson" class="author">Scott E. Hudson</a> <a href="byAffiliation.html#Human-Computer Interaction Institute, Carnegie Mellon University" class="affiliation">Human-Computer Interaction Institute, Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Human perception of time is fluid, and can be manipulated in purposeful and productive ways. In this note, we propose and evaluate variations on two visual designs for progress bars that alter users' perception of time passing, and appear faster when in fact they are not. As a baseline, we use standard, solid-color progress bars, prevalent in many user interfaces. In a series of direct comparison tests, we are able to rank how these augmentations compare to one another. We then show that these designs yield statistically significantly shorter perceived durations than progress bars seen in many modern interfaces, including Mac OSX. Progress bars with animated ribbing that move backwards in a decelerating manner proved to have the strongest effect. In a final experiment, we measured the effect of this particular progress bar design and showed that it reduces the perceived duration among our participants by 11%.   </span></div></div><div class="paper"><span class="title">Evaluation of Progressive Image Loading Schemes</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Chris Harrison" class="author">Chris Harrison</a> <a href="byAffiliation.html#Human-Computer Interaction Institute, Carnegie Mellon University" class="affiliation">Human-Computer Interaction Institute, Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Anind K. Dey" class="author">Anind K. Dey</a> <a href="byAffiliation.html#Human-Computer Interaction Institute, Carnegie Mellon University" class="affiliation">Human-Computer Interaction Institute, Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Scott E. Hudson" class="author">Scott E. Hudson</a> <a href="byAffiliation.html#Human-Computer Interaction Institute, Carnegie Mellon University" class="affiliation">Human-Computer Interaction Institute, Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Although network bandwidth has increased dramatically, high-resolution images often take several seconds to load, and considerably longer on mobile devices over wireless connections. Progressive image loading techniques allow for some visual content to be displayed prior to the whole file being downloaded. In this note, we present an empirical evaluation of popular progressive image loading methods, and derive one novel technique from our findings. Results suggest a spiral variation of bilinear interlacing can yield an improvement in content recognition time.</span></div></div></td>

<td colspan="9" class="session_details" id="S86_details"><div class="paper"><span class="title">Digital Drumming: A Study of Co-located, Highly  Coordinated, Dyadic Collaboration</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Bobby Beaton" class="author">Bobby Beaton</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a>,<br /><a href="byAuthors.html#Steve Harrison" class="author">Steve Harrison</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a>,<br /><a href="byAuthors.html#Deborah Tatar" class="author">Deborah Tatar</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Collaborative drumming is a creative human activity that requires a high degree of coordination among the participants.  In this study, inexperienced drummer and experienced drummer participants were paired with a computer or experienced human drummer counterpart and given the task of producing musical rhythms on the fly. We found differing patterns of music production across the computer and human conditions. Participants intentionally and unintentionally assumed leadership roles depending on the dyad dynamic. Also noted were differences in the needs of inexperienced and experienced participants for visual and verbal cues for coordination. In our study, participants did not treat computers as other humans, but seemed to engage a more complex evaluation of the situation.  This study contributes to the growing body of knowledge on how people respond to and interact with technology to accomplish complex, collaborative tasks.</span></div></div><div class="paper"><span class="title">G-nome Surfer: a Tabletop Interface for Collaborative Exploration of Genomic Data</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Orit Shaer" class="author">Orit Shaer</a> <a href="byAffiliation.html#Wellesley College" class="affiliation">Wellesley College</a>,<br /><a href="byAuthors.html#Guy Kol" class="author">Guy Kol</a> <a href="byAffiliation.html#Babson College" class="affiliation">Babson College</a>,<br /><a href="byAuthors.html#Megan Strait" class="author">Megan Strait</a> <a href="byAffiliation.html#Wellesley College" class="affiliation">Wellesley College</a>,<br /><a href="byAuthors.html#Chloe Fan" class="author">Chloe Fan</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Catherine Grevet" class="author">Catherine Grevet</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Sarah Elfenbein" class="author">Sarah Elfenbein</a> <a href="byAffiliation.html#Wellesley College" class="affiliation">Wellesley College</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Molecular and computational biologists develop new insights by gathering heterogeneous data from genomic databases and leveraging bioinformatics tools. Through a qualitative study with  17 participants, we found that molecular and computational biologists experience difficulties interpreting, comparing, annotating, sharing, and relating this vast amount of biological information. We further observed that such interactions are critical for forming new scientific hypotheses. These observations motivated the creation of  G-nome Surfer, a tabletop interface for collaborative exploration of genomic data that implements multi-touch and tangible interaction techniques. G-nome Surfer was developed in close collaboration with domain scientists and is aimed at lowering the threshold for using bioinformatics tools. A first-use study with 16 participants found that G-nome Surfer enables users to gain biological insights that are based on multiple forms of evidence with minimal overhead.</span></div></div><div class="paper"><span class="title">Using Metaphors to Create a Natural User Interface for Microsoft Surface</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kay Hofmeester" class="author">Kay Hofmeester</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a>,<br /><a href="byAuthors.html#Dennis Wixon" class="author">Dennis Wixon</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Creating a new model of human computer interaction is not straightforward.  Only a handful of such models have been commercially successful. Those that have, such as the graphical user interface (GUI), can provide valuable lessons. When we were challenged to develop a new natural user interface design for Microsoft Surface, we drew from these lessons and from modern user research techniques. A prominent starting point resulting from this was using metaphors to develop the new user interface. We used metaphors for two reasons: To create a user interface world that was understandable and predictable for our users, and to guide the design team in creating the detailed user interface design. We continued this practice in the user research: We focused on which metaphors worked best in the studies, and learned if users understood the metaphors we were using and which metaphor they preferred. This case study describes the process we followed, and the lessons we learned from this.</span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">11:30&nbsp;AM<br/><em>to</em><br/>1:00&nbsp;PM</td>
<td class="session" id="S96">
<span class="type">Papers/Notes</span>
<span class="title">Interactions in the World</span>
<span class="location">Centennial 1</span>
</td>
<td class="session" id="S25">
<span class="type">Panel</span>
<span class="title">Making Food, Producing Sustainability</span>
<span class="location">Centennial 2</span>
</td>
<td class="session" id="S98">
<span class="type">Papers/Notes</span>
<span class="title">Using Your Social Network</span>
<span class="location">Centennial 3</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S93">
<span class="type">Papers/Notes</span>
<span class="title">Classroom Technologies</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S14">
<span class="type">SIG</span>
<span class="title">Creating Prosocial Media for Children</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S3">
<span class="type">alt.chi</span>
<span class="title">I Need Your Input</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S94">
<span class="type">Papers/Notes</span>
<span class="title">Devising Input</span>
<span class="location">Hanover FG</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S99">
<span class="type">Papers/Notes</span>
<span class="title">Working with Medical Records</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S95">
<span class="type">Papers/Notes</span>
<span class="title">Expertise</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S97">
<span class="type">Papers/Notes</span>
<span class="title">Sound and Speech</span>
<span class="location">Regency 7</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
</tr>
<tr class="details_row">

<td colspan="10" class="session_details" id="S96_details"><div class="paper"><span class="title">An Empirical Task Analysis of Warehouse Order Picking Using Head-Mounted Displays</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kimberly A. Weaver" class="author">Kimberly A. Weaver</a> <a href="byAffiliation.html#GVU Center, School of  Interactive Computing,  Georgia Institute of Technology" class="affiliation">GVU Center, School of  Interactive Computing,  Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Hannes Baumann" class="author">Hannes Baumann</a> <a href="byAffiliation.html#TZI, Universität Bremen" class="affiliation">TZI, Universität Bremen</a>,<br /><a href="byAuthors.html#Thad Starner" class="author">Thad Starner</a> <a href="byAffiliation.html#GVU Center, School of  Interactive Computing,  Georgia Institute of Technology" class="affiliation">GVU Center, School of  Interactive Computing,  Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Hendrick Iben" class="author">Hendrick Iben</a> <a href="byAffiliation.html#TZI, Universität Bremen" class="affiliation">TZI, Universität Bremen</a>,<br /><a href="byAuthors.html#Michael Lawo" class="author">Michael Lawo</a> <a href="byAffiliation.html#TZI, Universität Bremen" class="affiliation">TZI, Universität Bremen</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Evaluations of task guidance systems often focus on evaluations of new technologies rather than comparing the nuances of interaction across the various systems. One common domain for task guidance systems is warehouse order picking. We present a method involving an easily reproducible ecologically motivated order picking environment for quantitative user studies designed to reveal differences in interactions. Using this environment, we perform a 12 participant within-subjects experiment demonstrating the advantages of a head-mounted display based picking chart over a traditional text-based pick list, a paper-based graphical pick chart, and a mobile pick-by-voice system. The test environment proved sufficiently sensitive, showing statistically significant results along several metrics with the head-mounted display system performing the best. We also provide a detailed analysis of the strategies adopted by our participants.</span></div></div><div class="paper"><span class="title">Where is my Team? Supporting Collaboration and Situation Awareness with Tactile Displays</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Martin Pielot" class="author">Martin Pielot</a> <a href="byAffiliation.html#OFFIS Institute for Information Technology" class="affiliation">OFFIS Institute for Information Technology</a>,<br /><a href="byAuthors.html#Oliver Krull" class="author">Oliver Krull</a> <a href="byAffiliation.html#University of Oldenburg" class="affiliation">University of Oldenburg</a>,<br /><a href="byAuthors.html#Susanne Boll" class="author">Susanne Boll</a> <a href="byAffiliation.html#University of Oldenburg" class="affiliation">University of Oldenburg</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">A group of friends visiting a crowded and noisy music festival is an example of a situation where knowing the location of other people is important, but where external factors, such as darkness or noise, can limit the ability to keep track of the others.  By combining theories about situation awareness and cognitive processing we inferred that communicating information via the sense of touch is a promising approach in such situations. We therefore investigated how to present the location of several people using a tactile torso display. In particular we focused on encoding spatial distances in the tactile signals. We experimentally compared encoding spatial distances in the rhythm, duration, and intensity of a tactile signal. Our findings show that all parameters are suited to encode distances. None of it was clearly outperformed. We then embedded our tactile location encoding into a fast-paced 3D multiplayer game. In this game, team play and the awareness of the team members' locations are crucial for the success in the game. The results provides evidence that the locations of the team members could be processed effectively despite the game's high cognitive demands. In addition, the team equipped with the tactile display showed a better team play and a higher situation awareness.</span></div></div><div class="paper"><span class="title">Case Study - Designing An Advanced Visualization System for Geological Core Drilling Expeditions</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Yu-Chung Chen" class="author">Yu-Chung Chen</a> <a href="byAffiliation.html#University of Illinois at Chicago" class="affiliation">University of Illinois at Chicago</a>,<br /><a href="byAuthors.html#Sangyoon Lee" class="author">Sangyoon Lee</a> <a href="byAffiliation.html#University of Illinois at Chicago" class="affiliation">University of Illinois at Chicago</a>,<br /><a href="byAuthors.html#HyeJung Hur" class="author">HyeJung Hur</a> <a href="byAffiliation.html#University of Illinois at Chicago" class="affiliation">University of Illinois at Chicago</a>,<br /><a href="byAuthors.html#Jason Leigh" class="author">Jason Leigh</a> <a href="byAffiliation.html#University of Illinois at Chicago" class="affiliation">University of Illinois at Chicago</a>,<br /><a href="byAuthors.html#Andrew Johnson" class="author">Andrew Johnson</a> <a href="byAffiliation.html#University of Illinois at Chicago" class="affiliation">University of Illinois at Chicago</a>,<br /><a href="byAuthors.html#Luc Renambot" class="author">Luc Renambot</a> <a href="byAffiliation.html#University of Illinois at Chicago" class="affiliation">University of Illinois at Chicago</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present the design and process of an interactive high-resolution visualization system for diverse and distributed real-world geological core drilling expeditions. The high domain knowledge barrier makes it difficult for a person who is outside this field to imagine the user experience, and the globally distributed core drilling community imposes more design constraints in space and time. In addition to activities proposed in prior literatures, we used the immersive empathic design approach of having a computer scientist trained as a junior core technician. Through in-situ observation and interview evaluations from on-going expeditions, we present the system and the lesson learned in the process. It makes the best use of precious co-located opportunities. It allows the developer to build up domain knowledge efficiently. It establishes a trust relationship between the developer and scientists. The system designed through this approach formed a sustainable foundation that was adapted in the following design iterations. This process allows the software developer to experience authentic user activities. The designed system is innovative and helps scientists solving real-world problems. This approach can be a useful example to HCI practitioners who work with potential users or communities that share similar properties.  </span></div></div></td>

<td colspan="10" class="session_details" id="S25_details"><div class="paper"><span class="title">Making Food, Producing Sustainability</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Tad Hirsch" class="author">Tad Hirsch</a> <a href="byAffiliation.html#intel labs" class="affiliation">intel labs</a>,<br /><a href="byAuthors.html#Phoebe Sengers" class="author">Phoebe Sengers</a> <a href="byAffiliation.html#cornell university" class="affiliation">cornell university</a>,<br /><a href="byAuthors.html#Eli Blevis" class="author">Eli Blevis</a> <a href="byAffiliation.html#Indiana UniversityBloomington" class="affiliation">Indiana UniversityBloomington</a>,<br /><a href="byAuthors.html#Richard Beckwith" class="author">Richard Beckwith</a> <a href="byAffiliation.html#intel labs" class="affiliation">intel labs</a>,<br /><a href="byAuthors.html#Tapan Parikh" class="author">Tapan Parikh</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Many contemporary approaches to environmental sustainability focus on the end-consumer. In this panel, we explore lessons from small food producers for future development of HCI as an agency of sustainable ways of being. We argue that attention to the relationship small producers have to the environment and their experiences of interrelations between environmental, economic, and social sustainability suggest new foundational issues for sustainable HCI research.      </span></div></div></td>

<td colspan="10" class="session_details" id="S98_details"><div class="paper"><span class="title">What Do People Ask Their Social Networks, and Why?  A Survey Study of Status Message Q&amp;A Behavior</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Meredith Ringel Morris" class="author">Meredith Ringel Morris</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Jaime Teevan" class="author">Jaime Teevan</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Katrina Panovich" class="author">Katrina Panovich</a> <a href="byAffiliation.html#Massachusetts Institute of Technology" class="affiliation">Massachusetts Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">People often turn to their friends, families, and colleagues when they have questions. The recent, rapid rise of online social networking tools has made doing this on a large scale easy and efficient. In this paper we explore the phenomenon of using social network status messages to ask questions. We conducted a survey of 624 people, asking them to share the questions they have asked and answered of their online social networks. We present detailed data on the frequency of this type of question asking, the types of questions asked, and respondents' motivations for asking their social networks rather than using more traditional search tools like Web search engines. We report on the perceived speed and quality of the answers received, as well as what motivates people to respond to questions seen in their friends' status messages. We then discuss the implications of our findings for the design of next-generation search tools.</span></div></div><div class="paper"><span class="title">Affirming the self through online profiles: Beneficial effects of social networking websites</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Catalina Toma" class="author">Catalina Toma</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Self-affirmation is the process of bringing to awareness important aspects of the self, such as values, goals, and treasured characteristics. When affirmed, individuals are more open-minded and less defensive. This study examines whether social networking tools, such as Facebook, have self-affirming value. Participants were asked to either spend time on their own Facebook profiles, or on a stranger's profile. Afterwards, they were given negative feedback on a task. Participants who spent time on their own profiles were more accepting of the feedback, and less likely to engage in ego-protective mechanisms, such as derogating the task or the evaluator. In fact, they behaved identically to participants who completed a classic self-affirmation manipulation. The theoretical contributions of this paper include (1) identifying intrapersonal effects of online self-presentation and (2) extending self-affirmation theory to include social media use. </span></div></div><div class="paper"><span class="title">Improving Social Game Engagement on Facebook through Enhanced Socio-Contextual Information</span> - <span class="type">Note</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Ben Kirman" class="author">Ben Kirman</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Shaun Lawson" class="author">Shaun Lawson</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Conor Linehan" class="author">Conor Linehan</a> <a href="byAffiliation.html#University of Lincoln" class="affiliation">University of Lincoln</a>,<br /><a href="byAuthors.html#Francesco Martino" class="author">Francesco Martino</a> <a href="byAffiliation.html#University of Padova" class="affiliation">University of Padova</a>,<br /><a href="byAuthors.html#Luciano Gamberini" class="author">Luciano Gamberini</a> <a href="byAffiliation.html#University of Padova" class="affiliation">University of Padova</a>,<br /><a href="byAuthors.html#Andrea Gaggioli" class="author">Andrea Gaggioli</a> <a href="byAffiliation.html#Istituto Auxologico Italiano" class="affiliation">Istituto Auxologico Italiano</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we describe the results of a controlled study of a social game, Magpies, which was built on the Facebook Online Social Network (OSN) and enhanced with contextual social information in the form of a variety of social network indices. Through comparison with a concurrent control trial using an identical game without the enhanced social information, it was shown that the additional contextual data increased the frequency of social activity between players engaged in the game. Despite this increase in activity, there was little increase in growth of the player-base when compared to the control condition. These findings corroborate previous work that showed how socio-contextual enhancement can increase performance on task-driven games, whilst also suggesting that it can increase activity and engagement when provided as context for non task-driven game environments. </span></div></div><div class="paper"><span class="title">The Role of Community and Groupware in Geocache Creation and Maintenance</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Carman Neustaedter" class="author">Carman Neustaedter</a> <a href="byAffiliation.html#Kodak Research Labs" class="affiliation">Kodak Research Labs</a>,<br /><a href="byAuthors.html#Anthony Tang" class="author">Anthony Tang</a> <a href="byAffiliation.html#University of British Columbia" class="affiliation">University of British Columbia</a>,<br /><a href="byAuthors.html#Tejinder K. Judge" class="author">Tejinder K. Judge</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Applications that provide location-based experiences are an increasingly viable design space given the proliferation of GPS-enabled mobile devices. However, these applications are in their infancy, and we do not yet know what design factors will contribute to their success. For this reason, we have studied the well-established location-based experience of geocaching. We report on the results of a survey of geocachers along with observations from our own in-depth geocaching activities. Our findings illustrate that geocaching permits users to create a range of experiences for others within a permeable yet restricted culture of norms. Once created, geocaches are maintained by the community of geocachers through a well-designed groupware system. Here maintenance acts can be performed in the small, given their lightweight and well-defined nature, and become less about maintenance and more about personal participation. These findings provide insight into how community and groupware can be leveraged to support applications for location-based experiences. </span></div></div></td>

<td colspan="10" class="session_details" id="S93_details"><div class="paper"><span class="title">Expressive robots in education</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Martin Saerbeck" class="author">Martin Saerbeck</a> <a href="byAffiliation.html#Eindhoven University of Technology" class="affiliation">Eindhoven University of Technology</a>,<br /><a href="byAuthors.html#Tom Schut" class="author">Tom Schut</a> <a href="byAffiliation.html#Philips Research" class="affiliation">Philips Research</a>,<br /><a href="byAuthors.html#Christoph Bartneck" class="author">Christoph Bartneck</a> <a href="byAffiliation.html#Eindhoven University of Technology" class="affiliation">Eindhoven University of Technology</a>,<br /><a href="byAuthors.html#Maddy D. Janse" class="author">Maddy D. Janse</a> <a href="byAffiliation.html#Philips Research" class="affiliation">Philips Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Teaching is inherently a social interaction between teacher and student. Despite this knowledge, many educational tools, such as vocabulary training programs, still model the interaction in a tutoring scenario as unidirectional knowledge transfer rather than a social dialog. Therefore, ongoing research aims to develop virtual agents as more appropriate media in education. Virtual agents can induce the perception of a life-like social interaction partner that communicates through natural modalities such as speech, gestures and emotional expressions. This effect can be additionally enhanced with a physical robotic embodiment.      This paper presents the development of social supportive behaviors for a robotic tutor to be used in a language learning application. The effect of these behaviors on the learning performance of students was evaluated. The results support that employing social supportive behavior increases learning efficiency of students. </span></div></div><div class="paper"><span class="title">Exploring Affective Technologies for the Classroom with the Subtle Stone</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Madeline Balaam" class="author">Madeline Balaam</a> <a href="byAffiliation.html#University of Sussex" class="affiliation">University of Sussex</a>,<br /><a href="byAuthors.html#Geraldine Fitzpatrick" class="author">Geraldine Fitzpatrick</a> <a href="byAffiliation.html#Vienna University of Technology" class="affiliation">Vienna University of Technology</a>,<br /><a href="byAuthors.html#Judith Good" class="author">Judith Good</a> <a href="byAffiliation.html#University of Sussex" class="affiliation">University of Sussex</a>,<br /><a href="byAuthors.html#Rosemary Luckin" class="author">Rosemary Luckin</a> <a href="byAffiliation.html#London Knowledge Lab" class="affiliation">London Knowledge Lab</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Constructive emotional experiences are strongly related to effective learning. Yet, it is challenging for teachers, researchers and students alike to understand the emotions experienced in the classroom setting. Advances in wireless and sensor technologies open up possibilities for better supporting emotions. However, little work has explored how affective technologies in the classroom might operate. This paper describes a study where 15 high school students used the Subtle Stone: a tangible technology designed to support students' active emotional communication in the classroom. We report on how the students used and experienced this technology, and the values they demonstrated through this use: flexibility, privacy, agency, voice and reflection. We conclude by examining future possibilities for affective technologies in the classroom. </span></div></div><div class="paper"><span class="title">vSked:  Evaluation of a System to Support Classroom Activities for Children with Autism</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sen H. Hirano" class="author">Sen H. Hirano</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Michael T. Yeganyan" class="author">Michael T. Yeganyan</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Gabriela Marcu" class="author">Gabriela Marcu</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#David H. Nguyen" class="author">David H. Nguyen</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Lou Anne Boyd" class="author">Lou Anne Boyd</a> <a href="byAffiliation.html#Orange County Department of Education" class="affiliation">Orange County Department of Education</a>,<br /><a href="byAuthors.html#Gillian R. Hayes" class="author">Gillian R. Hayes</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Visual schedulesthe use of symbols to represent a series of activities or stepshave been successfully used by caregivers to help children with autism to understand, structure, and predict activities in their daily lives. Building from in-depth fieldwork and participatory design sessions, we developed vSked, an interactive and collaborative visual scheduling system designed for elementary school classrooms. We evaluated vSked in situ in one autism-specific classroom over three weeks. In this paper, we present the design principles, technical solution, and results from this successful deployment. Use of vSked resulted in reductions in staff effort required to use visual supports. vSked also resulted in improvements in the perceived quality and quantity of communication and social interactions in the classroom.</span></div></div></td>

<td colspan="10" class="session_details" id="S14_details"><div class="paper"><span class="title">Creating Prosocial Media for Children</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Glenda Revelle" class="author">Glenda Revelle</a> <a href="byAffiliation.html#University of Arkansas" class="affiliation">University of Arkansas</a>,<br /><a href="byAuthors.html#Ashley Fenwick-Naditch" class="author">Ashley Fenwick-Naditch</a> <a href="byAffiliation.html#Sesame Workshop" class="affiliation">Sesame Workshop</a>,<br /><a href="byAuthors.html#Liz Kronenberger" class="author">Liz Kronenberger</a> <a href="byAffiliation.html#Xeko" class="affiliation">Xeko</a>,<br /><a href="byAuthors.html#Makeda Mays Green" class="author">Makeda Mays Green</a> <a href="byAffiliation.html#Sesame Workshop" class="affiliation">Sesame Workshop</a></div></div></td>

<td colspan="10" class="session_details" id="S3_details"><div class="paper"><span class="title">Tangible Interfaces for Download: Initial Observations from Users' Everyday Environments</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Enrico Costanza" class="author">Enrico Costanza</a> <a href="byAffiliation.html#EPFL Media and Design Lab  University of Southampton  Southampton, UK" class="affiliation">EPFL Media and Design Lab  University of Southampton  Southampton, UK</a>,<br /><a href="byAuthors.html#Matteo Giaccone" class="author">Matteo Giaccone</a> <a href="byAffiliation.html#EPFL Media and Design Lab  WeLaika, Torino, Italy" class="affiliation">EPFL Media and Design Lab  WeLaika, Torino, Italy</a>,<br /><a href="byAuthors.html#Olivier Kueng" class="author">Olivier Kueng</a> <a href="byAffiliation.html#EPFL Media and Design Lab  EPFL CV Lab" class="affiliation">EPFL Media and Design Lab  EPFL CV Lab</a>,<br /><a href="byAuthors.html#Simon Shelley" class="author">Simon Shelley</a> <a href="byAffiliation.html#TUEindoven" class="affiliation">TUEindoven</a>,<br /><a href="byAuthors.html#Jeffrey Huang" class="author">Jeffrey Huang</a> <a href="byAffiliation.html#EPFL Media and Design Lab" class="affiliation">EPFL Media and Design Lab</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Tangible user interfaces (TUIs) have been promoted and discussed in the HCI community for 15 years. Most reported TUIs are research prototypes, available in laboratories or museums. This paper reports an attempt to understand the impact of TUIs in users' everyday environments through a low-cost, simple set-up tangible interface for music that can be freely downloaded from a website. The system requires only a regular computer, a webcam and a printer  the physical parts of the interface can be folded out of ordinary paper. Logging interaction with the interfaces and analyzing content posted by users on the web we observed that the TUIs were accepted as normal: just interfaces to make music rather than esoteric systems.</span></div></div><div class="paper"><span class="title">Tangible Video Bubbles</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kimiko Ryokai" class="author">Kimiko Ryokai</a> <a href="byAffiliation.html#University of California Berkeley" class="affiliation">University of California Berkeley</a>,<br /><a href="byAuthors.html#Hayes Raffle" class="author">Hayes Raffle</a> <a href="byAffiliation.html#Nokia Research Center Palo Alto" class="affiliation">Nokia Research Center Palo Alto</a>,<br /><a href="byAuthors.html#Hiroshii Horii" class="author">Hiroshii Horii</a> <a href="byAffiliation.html#Nokia Research Center Palo Alto" class="affiliation">Nokia Research Center Palo Alto</a>,<br /><a href="byAuthors.html#Yotam Mann" class="author">Yotam Mann</a> <a href="byAffiliation.html#University of California Berkeley" class="affiliation">University of California Berkeley</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We introduce the Tangible Video Bubbles, a new video-based drawing space for children to create expressive video art. A Tangible Video Bubble acts both as a container for childrens expressions, as well as an instrument with which children can perform with their recorded video by squeezing and stretching the physical bubble. We present our iterative design process and evaluation of the play space with children, and discuss a new approach to making video creation more concrete and playful for children.</span></div></div><div class="paper"><span class="title">Adaptive Mouse: A Deformable Computer Mouse Achieving Form-Function Synchronization</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sheng Kai Tang" class="author">Sheng Kai Tang</a> <a href="byAffiliation.html#User Experience Design Section,  Mechanical &amp; Industrial Design Center,  ASUSTek Computer Inc." class="affiliation">User Experience Design Section,  Mechanical &amp; Industrial Design Center,  ASUSTek Computer Inc.</a>,<br /><a href="byAuthors.html#Wen Yen Tang" class="author">Wen Yen Tang</a> <a href="byAffiliation.html#Virtual Reality Lab,  Department of Spatial Design,  Kun Shan University" class="affiliation">Virtual Reality Lab,  Department of Spatial Design,  Kun Shan University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper, we implement a computer mouse for demonstrating the idea of form-function synchronization by embedding deformation sensing modules consisting of deformable foam and Hall-effect sensors. Due to its automatic sensing, recognizing and actuating mechanisms actively responding to users diverse gestures, we have chosen to name it Adaptive Mouse. Working with Adaptive Mouse, all users have to do is to hold it with preferred hand gestures, then through the use of their fore and middle fingers the correct button functions will intuitively be triggered. Users can also freely move the mouse and always get accurate cursor feedbacks. This intuitive holds then clicks action creates sense of magic, and the mouse shape with minimum visual clues not only lowers mental loads but also achieves the goal of simplicity design.</span></div></div><div class="paper"><span class="title">Manual Deskterity : An Exploration of  Simultaneous Pen + Touch Direct Input</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ken Hinckley" class="author">Ken Hinckley</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Koji Yatani" class="author">Koji Yatani</a> <a href="byAffiliation.html#Microsoft Research  University of Toronto" class="affiliation">Microsoft Research  University of Toronto</a>,<br /><a href="byAuthors.html#Michel Pahud" class="author">Michel Pahud</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Nicole Coddington" class="author">Nicole Coddington</a> <a href="byAffiliation.html#Microsoft Corporation" class="affiliation">Microsoft Corporation</a>,<br /><a href="byAuthors.html#Jenny Rodenhouse" class="author">Jenny Rodenhouse</a> <a href="byAffiliation.html#Microsoft Corporation" class="affiliation">Microsoft Corporation</a>,<br /><a href="byAuthors.html#Hrvoje Benko" class="author">Hrvoje Benko</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Andy Wilson" class="author">Andy Wilson</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Bill Buxton" class="author">Bill Buxton</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Manual Deskterity is a prototype digital drafting table that supports both pen and touch input. We explore a division of labor between pen and touch that flows from natural human skill and differentiation of roles of the hands. We also explore the simultaneous use of pen and touch to support novel compound gestures.     We advocate a division of labor between pen and touch: the pen writes, touch manipulates, and the combination of pen+touch yields new tools. This articulates how our system interprets unimodal pen, unimodal touch, and multimodal pen + touch inputs, respectively. We contribute novel pen + touch gestures, while also raising, by way of examples, design questions that probe how the roles of pen and touch should be differentiated (or not) in UI design.  </span></div></div><div class="paper"><span class="title">Planz to put our digital information in its place</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#William Jones" class="author">William Jones</a> <a href="byAffiliation.html#The Information School, University of Washington" class="affiliation">The Information School, University of Washington</a>,<br /><a href="byAuthors.html#Dawei Hou" class="author">Dawei Hou</a> <a href="byAffiliation.html#The Information School, University of Washington" class="affiliation">The Information School, University of Washington</a>,<br /><a href="byAuthors.html#Bhuricha Deen Sethanandha" class="author">Bhuricha Deen Sethanandha</a> <a href="byAffiliation.html#Computer Science Dept.  Portland State University" class="affiliation">Computer Science Dept.  Portland State University</a>,<br /><a href="byAuthors.html#Eric Sheng Bi" class="author">Eric Sheng Bi</a> <a href="byAffiliation.html#The Information School, University of Washington" class="affiliation">The Information School, University of Washington</a>,<br /><a href="byAuthors.html#Jim Gemmell" class="author">Jim Gemmell</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Planz provides a single, integrative document-like overlay to a folder hierarchy through a dynamic, on-demand assembly of XML fragments. This overlay provides a context in which to create or reference not only files but also email messages and web pages. This paper describes an evaluation of Planz over a period of several days during which participants compared their experiences on two projects  one involving status quo methods, a second project involving Planz. </span></div></div><div class="paper"><span class="title">Only One Fitts Law Formula  Please!</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Heiko Drewes" class="author">Heiko Drewes</a> <a href="byAffiliation.html#University of Munich" class="affiliation">University of Munich</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The HCI community uses at least four different formulas for Fitts law. Each of them is derived from Shannons information theory. This raises the question which formula is wrong and which is right. While the HCI community on the one hand gives free choice for the formula, it demands good statistical values for the evaluation on the other hand. From a scientific point of view this situation is not satisfying.</span></div></div></td>

<td colspan="10" class="session_details" id="S94_details"><div class="paper"><span class="title">Comparing User Performance with Single-Finger,  Whole-Hand, and Hybrid Pointing Devices</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Xiang Cao" class="author">Xiang Cao</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Nicolas Villar" class="author">Nicolas Villar</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Shahram Izadi" class="author">Shahram Izadi</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Researchers have explored pointing devices operated by a single finger, but their advantage was not clear compared to conventional mice controlled by the whole hand. To incorporate the benefits of both, we prototyped hybrid pointing devices that combined both finger and hand movement to control the cursor, and experimentally compared their performance with single-finger and whole-hand devices. Results showed that such hybrid devices have the potential to improve pointing performance in terms of time, error, and bandwidth, especially for precise pointing.</span></div></div><div class="paper"><span class="title">How Users Manipulate Deformable Displays as Input Devices</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sang-Su Lee" class="author">Sang-Su Lee</a> <a href="byAffiliation.html#KAIST" class="affiliation">KAIST</a>,<br /><a href="byAuthors.html#Sohyun Kim" class="author">Sohyun Kim</a> <a href="byAffiliation.html#KAIST" class="affiliation">KAIST</a>,<br /><a href="byAuthors.html#Bopil Jin" class="author">Bopil Jin</a> <a href="byAffiliation.html#KAIST" class="affiliation">KAIST</a>,<br /><a href="byAuthors.html#Eunji Choi" class="author">Eunji Choi</a> <a href="byAffiliation.html#KAIST" class="affiliation">KAIST</a>,<br /><a href="byAuthors.html#Boa Kim" class="author">Boa Kim</a> <a href="byAffiliation.html#KAIST" class="affiliation">KAIST</a>,<br /><a href="byAuthors.html#Xu Jia" class="author">Xu Jia</a> <a href="byAffiliation.html#KAIST" class="affiliation">KAIST</a>,<br /><a href="byAuthors.html#Daeeop Kim" class="author">Daeeop Kim</a> <a href="byAffiliation.html#KAIST" class="affiliation">KAIST</a>,<br /><a href="byAuthors.html#Kun-pyo Lee" class="author">Kun-pyo Lee</a> <a href="byAffiliation.html#KAIST" class="affiliation">KAIST</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This study is aimed at understanding deformation-based user gestures by observing users interacting with artificial deformable displays with various levels of flexibility. We gained user-defined gestures that would help with the design and implementation of deformation-based interface, without considering current technical limitations. We found that when a display material gave more freedom from deformation, the level of consensus of gestures among the users as well as the intuitiveness and preferences were all enhanced. This study offers implications for deformation-based interaction which will be helpful for both designers and engineers who are trying to set the direction for future interface and technology development.  </span></div></div><div class="paper"><span class="title">Cord Input: An Intuitive, High-Accuracy, Multi-Degree-of-Freedom Input Method for Mobile Devices</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Julia Schwarz" class="author">Julia Schwarz</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Chris Harrison" class="author">Chris Harrison</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Scott Hudson" class="author">Scott Hudson</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Jennifer Mankoff" class="author">Jennifer Mankoff</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">A cord, although simple in form, has many interesting physical affordances that make it powerful as an input device. Not only can a length of cord be grasped in different locations, but also pulled, twisted, and bentfour distinct and expressive dimensions that could potentially act in concert. Such an input mechanism could be readily integrated into headphones, backpacks, and clothing. Once grasped in the hand, a cord can be used in an eyes-free manner to control mobile devices, which often feature small screens and cramped buttons. In this note, we describe a proof-of-concept cord-based sensor, which senses three of the four input dimensions we propose. In addition to a discussion of potential uses, we also present results from our preliminary user study. The latter sought to compare the targeting performance and selection accuracy of different cord-based input modalities. We conclude with brief set of design recommendations drawn upon results from our study.</span></div></div><div class="paper"><span class="title">Minput: Enabling Interaction on Small Mobile Devices with High-Precision, Low-Cost, Multipoint Optical Tracking</span> - <span class="type">Note</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Chris Harrison" class="author">Chris Harrison</a> <a href="byAffiliation.html#Human-Computer Interaction Institute, Carnegie Mellon University" class="affiliation">Human-Computer Interaction Institute, Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Scott E. Hudson" class="author">Scott E. Hudson</a> <a href="byAffiliation.html#Human-Computer Interaction Institute, Carnegie Mellon University" class="affiliation">Human-Computer Interaction Institute, Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present Minput, a sensing and input method that enables intuitive and accurate interaction on very small devices - ones too small for practical touch screen use and with limited space to accommodate physical buttons. We achieve this by incorporating two, inexpensive and high-precision optical sensors (like those found in optical mice) into the underside of the device. This allows the entire device to be used as an input mechanism, instead of the screen, avoiding occlusion by fingers. In addition to x/y translation, our system also captures twisting motion, enabling many interesting interaction opportunities typically found in larger and far more complex systems. </span></div></div></td>

<td colspan="10" class="session_details" id="S99_details"><div class="paper"><span class="title">Doctors and Psychosocial Information: Records and Reuse in Inpatient Care</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Xiaomu Zhou" class="author">Xiaomu Zhou</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Mark Ackerman" class="author">Mark Ackerman</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Kai Zheng" class="author">Kai Zheng</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We conducted a field-based study at a large teaching hospital to examine doctors' use and documentation of patient care information, with a special focus on a patient's psychosocial information. We were particularly interested in the gaps between the medical work and any representations of the patient. The paper describes how doctors record this information for immediate and long-term use. We found that doctors documented a considerable amount of psychosocial information in their electronic health records (EHR) system. Yet, we also observed that such information was recorded selectively, and a medicalized view-point is a key contributing factor. Our study shows how missing or problematic representations of a patient affect work activities and patient care. We accordingly suggest that EHR systems could be made more usable and useful in the long run, by supporting both representations of medical processes and of patients. </span></div></div><div class="paper"><span class="title">Supporting Coordination in Surgical Suites: Physical Aspects of Common Information Spaces</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Peter G. Scupelli" class="author">Peter G. Scupelli</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Yan Xiao" class="author">Yan Xiao</a> <a href="byAffiliation.html#Baylor Health Care System" class="affiliation">Baylor Health Care System</a>,<br /><a href="byAuthors.html#Susan R. Fussell" class="author">Susan R. Fussell</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Sara Kiesler" class="author">Sara Kiesler</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Mark D. Gross" class="author">Mark D. Gross</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">To accommodate frequent emergencies, interruptions, and delays, hospital staff continually make and coordinate changes to the surgery schedule. The technical and social aspects of coordination in surgical suites have been described by prior studies. This paper addresses an understudied aspect of coordination: the physical environment. Based on a field study of four surgical suites in two large academic centers, we show how the physical layout of hallways and rooms, and barriers and spaces around displays and key coordinators, support or fail to support the common information spaces used for coordination. We use the concept information hotspots to represent how physical places and their characteristics facilitate coordination. We developed design principles based on the concept of information hotspots that should guide architectural considerations for coordination in dynamic environments such as hospitals.</span></div></div><div class="paper"><span class="title">Documenting Transitional Information in EMR</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Yunan Chen" class="author">Yunan Chen</a> <a href="byAffiliation.html#University of California Irvine" class="affiliation">University of California Irvine</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">An observational study was conducted to examine EMR-based documentation in an Emergency Department (ED), with an emphasis on computerized documentation activities in the complex flow of clinical processes. This study revealed a gap between the formal EMR documentation and the actual clinical workflow, which leads ED staff to rely on intermediate - transitional artifacts to facilitate their work. The analysis of these transitional artifacts in four different clinical workflows shows that the EMR system's inability to document procedural information, capture key information, and present information according to the actual clinical workflow are accountable for leading to the use of transitional artifacts. The findings of this study call for designing EMR system not only for keeping patients' formal records, but also for documenting transitional information in the chart-writing process.</span></div></div></td>

<td colspan="10" class="session_details" id="S95_details"><div class="paper"><span class="title">How Power Users Help and Hinder Open Bug Reporting</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Andrew J. Ko" class="author">Andrew J. Ko</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Parmit K. Chilana" class="author">Parmit K. Chilana</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Many power users that contribute to open source projects have no intention of becoming regular contributors; they just want a bug fixed or a feature implemented. How often do these users participate in open source projects and what do they contribute? To investigate these questions, we analyzed the reports of Mozilla contributors who reported problems but were never assigned problems to fix. These analyses revealed that over 11 years and millions of reports, most of these 150,000 users reported non-issues that devolved into technical support, redundant reports with little new information, or narrow, expert feature requests. Reports that did lead to changes were reported by a comparably small group of experienced, frequent reporters, mostly before the release of Firefox 1. These results suggest that the primary value of open bug reporting is in recruiting talented reporters, and not in deriving value from the masses.</span></div></div><div class="paper"><span class="title">Bringing the field into focus: User-centered design of a patient expertise locator</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Andrea Civan-Hartzler" class="author">Andrea Civan-Hartzler</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#David W. McDonald" class="author">David W. McDonald</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Chris Powell" class="author">Chris Powell</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Meredith M. Skeels" class="author">Meredith M. Skeels</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Marlee Mukai" class="author">Marlee Mukai</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Wanda Pratt" class="author">Wanda Pratt</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Managing personal aspects of health is challenging for many patients, particularly those facing a serious condition such as cancer. Finding experienced patients, who can share their knowledge from managing a similar health situation, is of tremendous value. Users of health-related social software form a large base of such knowledge, yet these tools often lack features needed to locate peers with expertise. Informed directly by our field work with breast cancer patients, we designed a patient expertise locator for users of online health communities. Using feedback from two focus groups with breast cancer survivors, we took our design through two iterations. Focus groups concluded that expertise locating features proved useful for extending social software. They guided design enhancements by suggesting granular user control through (1) multiple mechanisms to identify expertise, (2) detailed user profiles to select expertise, and (3) varied collaboration levels. Our user-centered approach links field work to design through close collaboration with patients. By illustrating trade-offs made when sharing sensitive health information, our findings inform the incorporation of expertise locating features into social software for patients.</span></div></div><div class="paper"><span class="title">What Do You Know? Experts, Novices and Territoriality in Collaborative Systems</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jennifer Thom-Santelli" class="author">Jennifer Thom-Santelli</a> <a href="byAffiliation.html#IBM TJ Watson Research" class="affiliation">IBM TJ Watson Research</a>,<br /><a href="byAuthors.html#Dan R. Cosley" class="author">Dan R. Cosley</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Geri Gay" class="author">Geri Gay</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">When experts participate in collaborative systems, tension may arise between them and novice contributors. In particular, when experts perceive novices as a bother or a threat, the experts may express territoriality: behaviors communicating ownership of a target of interest. In this paper, we describe the results of a user study of a mobile social tagging system deployed within a museum gallery to a group of novices and experts collaboratively tagging part of the collection. We observed that experts express greater feelings of ownership towards their contributions to the system and the museum in general. Experts were more likely than novices to participate at higher rates and to negatively evaluate contributions made by others. We suggest a number of design strategies to balance experts' expressions of territoriality so as to motivate their participation while discouraging exclusionary behaviors. </span></div></div></td>

<td colspan="10" class="session_details" id="S97_details"><div class="paper"><span class="title">Clutching at Straws: Using Tangible Interaction to Provide Non-Visual Access to Graphs</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#David McGookin" class="author">David McGookin</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Euan Robertson" class="author">Euan Robertson</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a>,<br /><a href="byAuthors.html#Stephen Brewster" class="author">Stephen Brewster</a> <a href="byAffiliation.html#University of Glasgow" class="affiliation">University of Glasgow</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present a tangible user interface (TUI) called Tangible Graph Builder, that has been designed to allow visually impaired users to access graph and chart-based data.  We describe the current paper-based materials used to allow independent graph construction and browsing, before discussing how researchers have applied  virtual haptic and non-speech audio techniques to provide more flexible access.  We discuss why, although these technologies overcome many of the problems of non-visual graph access, they also introduce new issues and why the application of TUIs is important.  An evaluation of Tangible Graph Builder with 12 participants (8 sight deprived, 4 blind) revealed key design requirements for non-visual TUIs, including phicon design and handling marker detection failure.  We finish by presenting future work and improvements to our system.</span></div></div><div class="paper"><span class="title">Effects of Automated Transcription Quality on Non-native Speakers' Comprehension in Real-time Computer-mediated Communication</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Yingxin Pan" class="author">Yingxin Pan</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a>,<br /><a href="byAuthors.html#Danning Jiang" class="author">Danning Jiang</a> <a href="byAffiliation.html#IBM Research- China" class="affiliation">IBM Research- China</a>,<br /><a href="byAuthors.html#Lin Yao" class="author">Lin Yao</a> <a href="byAffiliation.html#Chinese Academy Institute" class="affiliation">Chinese Academy Institute</a>,<br /><a href="byAuthors.html#Michael Picheny" class="author">Michael Picheny</a> <a href="byAffiliation.html#IBM Research - Waston" class="affiliation">IBM Research - Waston</a>,<br /><a href="byAuthors.html#Yong Qin" class="author">Yong Qin</a> <a href="byAffiliation.html#IBM Research - China" class="affiliation">IBM Research - China</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Real-time transcription has been shown to be valuable in facilitating non-native speakers' comprehension in real-time communication. Automated speech recognition (ASR) technology is a critical ingredient for its practical deployment. This paper presents a series of studies investigating how the quality of transcripts generated by an ASR system impacts user comprehension and subjective evaluation. Experiments are first presented comparing performance across three different transcription conditions: no transcript, a perfect transcript, and a transcript with Word Error Rate (WER) =20%. We found 20% WER was the most likely critical point for transcripts to be just acceptable and useful. Then we further examined a lower WER of 10% (a lower bound for today's state-of-the-art systems) employing the same experimental design. The results indicated that at 10% WER comprehension performance was significantly improved compared to the no-transcript condition. Finally, implications for further system development and design are discussed.</span></div></div><div class="paper"><span class="title">Understanding the Impact of Abstracted Audio Preview of SMS</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Alireza Sahami Shirazi" class="author">Alireza Sahami Shirazi</a> <a href="byAffiliation.html#University of Duisburg-Essen" class="affiliation">University of Duisburg-Essen</a>,<br /><a href="byAuthors.html#Ari-Heikki Sarjanoja" class="author">Ari-Heikki Sarjanoja</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Florian Alt" class="author">Florian Alt</a> <a href="byAffiliation.html#University of Duisburg-Essen" class="affiliation">University of Duisburg-Essen</a>,<br /><a href="byAuthors.html#Albrecht Schmidt" class="author">Albrecht Schmidt</a> <a href="byAffiliation.html#University of Duisburg-Essen" class="affiliation">University of Duisburg-Essen</a>,<br /><a href="byAuthors.html#Jonna Häkkilä" class="author">Jonna Häkkilä</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Despite the availability of other mobile messaging applications, SMS has kept its position as a heavily used communication technology. However, there are many situations in which it is inconvenient or inappropriate to check a message's content immediately. In this paper, we introduce the concept of audio previews of SMS. Based on a real-time analysis of the content of a message, we provide auditory cues in addition to the notification tone upon receiving an SMS. We report on a field trial with 20 participants and show that the use of audio-enhanced SMS affects the reading and writing behavior of users. Our work is motivated by the results of an online survey among 347 SMS users of whose we analyzed 3400 text messages.</span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">2:30&nbsp;PM<br/><em>to</em><br/>4:00&nbsp;PM</td>
<td class="session" id="S103">
<span class="type">Papers/Notes</span>
<span class="title">Medical Data</span>
<span class="location">Centennial 1</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S107">
<span class="type">Paper + Panel</span>
<span class="title">Mapping the Landscape of Sustainable HCI</span>
<span class="location">Centennial 2</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S102">
<span class="type">Papers/Notes</span>
<span class="title">Earth, Wind, and Flyer</span>
<span class="location">Centennial 3</span>
</td>
<td class="session" id="S104">
<span class="type">Papers/Notes</span>
<span class="title">Social Media Users</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S15">
<span class="type">SIG</span>
<span class="title">End User Software Engineering: CHI 2010 Special Interest Group Meeting</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S4">
<span class="type">alt.chi</span>
<span class="title">Imagine all the People</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S101">
<span class="type">Papers/Notes</span>
<span class="title">Death and Fear</span>
<span class="location">Hanover FG</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S106">
<span class="type">Papers/Notes</span>
<span class="title">Tools Affecting the Enterprise</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S105">
<span class="type">Papers/Notes</span>
<span class="title">Subtle Expressions Through Sound and Text</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S100">
<span class="type">Papers/Notes</span>
<span class="title">Bikes and Buses</span>
<span class="location">Regency 7</span>
</td>
</tr>
<tr class="details_row">

<td colspan="10" class="session_details" id="S103_details"><div class="paper"><span class="title">Physician-Driven Management of Patient Progress Notes in an Intensive Care Unit</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Lauren Wilcox" class="author">Lauren Wilcox</a> <a href="byAffiliation.html#Columbia University, IBM Watson" class="affiliation">Columbia University, IBM Watson</a>,<br /><a href="byAuthors.html#Jie Lu" class="author">Jie Lu</a> <a href="byAffiliation.html#IBM Watson" class="affiliation">IBM Watson</a>,<br /><a href="byAuthors.html#Jennifer Lai" class="author">Jennifer Lai</a> <a href="byAffiliation.html#IBM Watson" class="affiliation">IBM Watson</a>,<br /><a href="byAuthors.html#Steven Feiner" class="author">Steven Feiner</a> <a href="byAffiliation.html#Columbia University" class="affiliation">Columbia University</a>,<br /><a href="byAuthors.html#Desmond Jordan" class="author">Desmond Jordan</a> <a href="byAffiliation.html#Columbia University" class="affiliation">Columbia University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We describe fieldwork in which we studied hospital ICU physicians and their strategies and documentation aids for composing patient progress notes. We then present a clini-cal documentation prototype, activeNotes, that supports the creation of these notes, using techniques designed based on our fieldwork. ActiveNotes integrates automated, context-sensitive patient data retrieval, and user control of automated data updates and alerts via tagging, into the documentation process. We performed a qualitative study of activeNotes with 15 physicians at the hospital to explore the utility of our information retrieval and tagging tech-niques. The physicians indicated their desire to use tags for a number of purposes, some of them extensions to what we intended, and others new to us and unexplored in other systems of which we are aware. We discuss the physicians' responses to our prototype and distill several of their pro-posed uses of tags: to assist in note content management, communication with other clinicians, and care delivery.</span></div></div><div class="paper"><span class="title">Mobile-izing Health Workers in Rural India</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Divya Ramachandran" class="author">Divya Ramachandran</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#John Canny" class="author">John Canny</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#Prabhu Dutta Das" class="author">Prabhu Dutta Das</a> <a href="byAffiliation.html#Dhirubhai Ambani Institute of Information and Communications Technology" class="affiliation">Dhirubhai Ambani Institute of Information and Communications Technology</a>,<br /><a href="byAuthors.html#Edward Cutrell" class="author">Edward Cutrell</a> <a href="byAffiliation.html#Microsoft Research India" class="affiliation">Microsoft Research India</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Researchers have long been interested in the potential of  ICTs to enable positive change in developing regions communities.  In these environments, ICT interventions often fail  because political, social and cultural forces work against the  changes ICTs entail. We argue that familiar uses of ICTs for  information services in these contexts are less potent than  their use for persuasion and motivation in order to facilitate  change. We focus on India's rural maternal health system  where health workers are employed in villages to persuade  pregnant women to utilize health services. Health workers  face challenges due to resistance to change in the village, and  because of their limited education, training and status. These  factors appear to reduce the motivation of health workers  and impair their performance. For two months, we deployed  short videos on mobile phones designed to persuade village  women and motivate health workers. We also asked health  workers to record their own videos. While our results are  preliminary, they show evidence that the creation and use  of videos did help (1) engage village women in dialogue,  (2) show positive effects toward health worker motivation  and learning, and (3) motivate key community influencers to  participate in promoting the health workers.</span></div></div><div class="paper"><span class="title">Who's Scribing? Documenting Patient Encounter during Trauma Resuscitation</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Aleksandra Sarcevic" class="author">Aleksandra Sarcevic</a> <a href="byAffiliation.html#Rutgers University" class="affiliation">Rutgers University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">With healthcare moving towards electronic health records, it is important to understand existing work practices to design effective systems. We conducted an observational study in a Level I trauma center to examine the documentation process and the role of the nurse recorder in trauma resuscitation. We identified several difficulties with current recording practices, including the late arrival of the nurse recorder, parallel activities of the trauma team, and multitasking by the recorder. Our observations showed that the recorder's role extends beyond archival responsibilities. The recorder, with the help of a paper record, manages the resuscitation process, rather than passively documenting it. Our findings highlighted the complexity of the recorder's role and the need to consider documentation in the broader context of trauma teamwork. We proposed a set of design challenges that emphasize important aspects of trauma care to be considered when designing technologies to support the documentation process.</span></div></div></td>

<td colspan="10" class="session_details" id="S107_details"><div class="paper"><span class="title">Mapping the Landscape of Sustainable HCI</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Carl DiSalvo" class="author">Carl DiSalvo</a> <a href="byAffiliation.html#Georgia Tech" class="affiliation">Georgia Tech</a>,<br /><a href="byAuthors.html#Phoebe Sengers" class="author">Phoebe Sengers</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Hrönn Brynjarsdóttir" class="author">Hrönn Brynjarsdóttir</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">With the recent growth in sustainable HCI, now is a good time to map out the approaches being taken and the intellectual commitments that underlie the area, to allow for community discussion about where the field should go. Here, we provide an empirical analysis of how sustainable HCI is defining itself as a research field. Based on a corpus of published works, we identify (1) established genres in the area, (2) key unrecognized intellectual differences, and (3) emerging issues, including urgent avenues for further exploration, opportunities for interdisciplinary engagement, and key topics for debate.</span></div></div></td>

<td colspan="10" class="session_details" id="S102_details"><div class="paper"><span class="title">UpStream: Motivating Water Conservation with Low-Cost Water Flow Sensing and Persuasive Displays</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Stacey Kuznetsov" class="author">Stacey Kuznetsov</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Eric Paulos" class="author">Eric Paulos</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Water is our most precious and most rapidly declining natural resource. We explore pervasive technology as an approach for promoting water conservation in public and private spaces. We hope to motivate immediate reduction in water use as well as higher-order behaviors (seeking new information, etc) through unobtrusive low-cost water flow sensing and several persuasive displays. Early prototypes were installed at public faucets and a private (shared) shower, logging water usage first without and then with ambient displays. This pilot study led to design iterations, culminating in long-term deployment of sensors in four private showers over the course of three weeks. Sensors first logged baseline water usage without visualization. Then, two display styles, ambient and numeric, were deployed in random order, each showing individual and average water consumption. Quantitative data along with participants feedback contrast the effectiveness of numeric displays against abstract visualization in this very important domain of water conservation and public health. </span></div></div><div class="paper"><span class="title">inAir: Sharing Indoor Air Quality Measurements and Visualizations</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sunyoung Kim" class="author">Sunyoung Kim</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Eric Paulos" class="author">Eric Paulos</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper describes inAir, a tool for sharing measurements  and visualizations of indoor air quality within ones social  network. Poor indoor air quality is difficult for humans to  detect through sight and smell alone and can contribute to  the development of chronic diseases. Through a four-week  long study of fourteen households as six groups, we found  that inAir (1) increased awareness of, and reflection on air  quality, (2) promoted behavioral changes that resulted in  improved indoor air quality, and (3) demonstrated the  persuasive power of sharing for furthering improvements to  indoor air quality in terms of fostering new social  awareness and behavior changes as well as strengthening  social bonds and prompting collaborative efforts across  social networks to improve human health and well being.</span></div></div><div class="paper"><span class="title">Exploring Sustainable Design with Reusable Paper</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Julie Wagner" class="author">Julie Wagner</a> <a href="byAffiliation.html#In|Situ|, LRI, INRIA" class="affiliation">In|Situ|, LRI, INRIA</a>,<br /><a href="byAuthors.html#Wendy E. Mackay" class="author">Wendy E. Mackay</a> <a href="byAffiliation.html#INRIA" class="affiliation">INRIA</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper explores the need for sustainable design with paper: how people really print and how we can take advantage of novel, reusable paper technology. We conducted two studies to investigate user's printing behavior.  A key finding of the first study was that users often need an intermediate state between the electronic and physical forms of their documents. The second study examined users' predictions of which types of documents required this intermediate state. We formulate these findings into design guidelines that take into account: examination phase, transitions, cognitive and emotional reasons, and task- and event-relevant documents. Finally, we discuss how the different physical characteristics of reusable paper affect the user interface and could effectively support sustainable design.</span></div></div><div class="paper"><span class="title">Finding the Lost Treasure: Understanding Reuse of Used Computing Devices</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Jina Huh" class="author">Jina Huh</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Kevin Nam" class="author">Kevin Nam</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Nikhil Sharma" class="author">Nikhil Sharma</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper, we report our findings on the adoption practices of used personal digital assistants (PDAs) to inform reuse of outdated computing products. Our interviews with 12 eBay users who bought used PDAs showed a variety of ways in which users indirectly supported sustainability. This allowed us to re-examine sustainability as something that is dynamically and arbitrarily shaped by the users and not just dependent on the sustainable feature of the product. We end with design implications for supporting users' shaping of sustainability. </span></div></div></td>

<td colspan="10" class="session_details" id="S104_details"><div class="paper"><span class="title">Social Network Activity and Social Well-Being</span> - <span class="type">Note</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Moira Burke" class="author">Moira Burke</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Cameron Marlow" class="author">Cameron Marlow</a> <a href="byAffiliation.html#Facebook" class="affiliation">Facebook</a>,<br /><a href="byAuthors.html#Thomas Lento" class="author">Thomas Lento</a> <a href="byAffiliation.html#Facebook" class="affiliation">Facebook</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Previous research has shown a relationship between use of social networking sites and feelings of social capital. However, most studies have relied on self-reports by college students. The goals of the current study are to (1) validate the common self-report scale using empirical data from Facebook, (2) test whether previous findings generalize to older and international populations, and (3) delve into the specific activities linked to feelings of social capital and loneliness. In particular, we investigate the role of directed interaction between pairssuch as wall posts, comments, and likesand consumption of friends' content, including status updates, photos, and friends' conversations with other friends. We find that directed communication is associated with greater feelings of bonding social capital and lower loneliness, but has only a modest relationship with bridging social capital, which is primarily related to overall friend network size. Surprisingly, users who consume greater levels of content report reduced bridging and bonding social capital and increased loneliness. Implications for designs to support well-being are discussed.</span></div></div><div class="paper"><span class="title">Predicting Influence in an Online Community of Creators</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Elisabeth Sylvan" class="author">Elisabeth Sylvan</a> <a href="byAffiliation.html#TERC" class="affiliation">TERC</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper introduces the concept of Online Communities of Creators (OCOCs), which are a subset of social network sites in which the core activity is sharing personal, original creations. Next it defines two distinct types of influence, Project Influence and Social Influence. Project Influence is a measure of the degree to which the community recognizes members' work. Social Influence is a measure of how much a member is a social bridge between otherwise unconnected members. These two types of influence are studied in an online programming community called the Scratch Online Community. Two multiple linear regressions determine the factors that predict each of the two types of influence. The factors predicting each were distinct, suggesting that these are two distinct constructs in this community. </span></div></div><div class="paper"><span class="title">Lurking? Cyclopaths? A Quantitative Lifecycle Analysis of User Behavior in a Geowiki</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Katherine Panciera" class="author">Katherine Panciera</a> <a href="byAffiliation.html#University of Minnesota" class="affiliation">University of Minnesota</a>,<br /><a href="byAuthors.html#Reid Priedhorsky" class="author">Reid Priedhorsky</a> <a href="byAffiliation.html#University of Minnesota" class="affiliation">University of Minnesota</a>,<br /><a href="byAuthors.html#Thomas Erickson" class="author">Thomas Erickson</a> <a href="byAffiliation.html#IBM" class="affiliation">IBM</a>,<br /><a href="byAuthors.html#Loren Terveen" class="author">Loren Terveen</a> <a href="byAffiliation.html#University of Minnesota" class="affiliation">University of Minnesota</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Online communities produce rich behavioral datasets, e.g., Usenet news conversations, Wikipedia edits, and Facebook friend networks. Analysis of such datasets yields important insights (like the long tail of user participation) and sug- gests novel design interventions (like targeting users with personalized opportunities and work requests). However, certain key user data typically are unavailable, specifically viewing, pre-registration, and non-logged-in activity. The absence of data makes some questions hard to answer; access to it can strengthen, extend, or cast doubt on previous results. We report on analysis of user behavior in Cyclopath, a geographic wiki and route-finder for bicyclists. With access to viewing and non-logged-in activity data, we were able to: (a) replicate and extend prior work on user lifecycles in Wikipedia, (b) bring to light some pre-registration activity, thus testing for the presence of educational lurking, and (c) demonstrate the locality of geographic activity and how editing and viewing are geographically correlated.</span></div></div><div class="paper"><span class="title">Motivations to Participate in Online Communities</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Cliff Lampe" class="author">Cliff Lampe</a> <a href="byAffiliation.html#Michigan State University" class="affiliation">Michigan State University</a>,<br /><a href="byAuthors.html#Rick Wash" class="author">Rick Wash</a> <a href="byAffiliation.html#Michigan State University" class="affiliation">Michigan State University</a>,<br /><a href="byAuthors.html#Alcides Velasquez" class="author">Alcides Velasquez</a> <a href="byAffiliation.html#Michigan State University" class="affiliation">Michigan State University</a>,<br /><a href="byAuthors.html#Elif Ozkaya" class="author">Elif Ozkaya</a> <a href="byAffiliation.html#Michigan State University" class="affiliation">Michigan State University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">A consistent theoretical and practical challenge in the design of socio-technical systems is that of motivating users to participate in and contribute to them.  This study examines the case of Everything2.com users from the theoretical perspectives of Uses and Gratifications and Organizational Commitment to compare individual versus organizational motivations in user participation.  We find evidence that users may continue to participate in a site for different reasons than those that led them to the site.  Feelings of belonging to a site are important for both anonymous and registered users across different types of uses.  Long-term users felt more dissatisfied with the site than anonymous users. Social and cognitive factors seem to be more important than issues of usability in predicting contribution to the site. </span></div></div></td>

<td colspan="10" class="session_details" id="S15_details"><div class="paper"><span class="title">End User Software Engineering: CHI 2010 Special Interest Group Meeting</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Brad Myers" class="author">Brad Myers</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Margaret Burnett" class="author">Margaret Burnett</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Andrew Ko" class="author">Andrew Ko</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Mary Beth Rosson" class="author">Mary Beth Rosson</a> <a href="byAffiliation.html#Pennsylvania State University" class="affiliation">Pennsylvania State University</a>,<br /><a href="byAuthors.html#Christopher Scaffidi" class="author">Christopher Scaffidi</a> <a href="byAffiliation.html#Oregon State University" class="affiliation">Oregon State University</a>,<br /><a href="byAuthors.html#Susan Wiedenbeck" class="author">Susan Wiedenbeck</a> <a href="byAffiliation.html#Drexel University" class="affiliation">Drexel University</a></div></div></td>

<td colspan="10" class="session_details" id="S4_details"><div class="paper"><span class="title">Edits &amp; Credits: Exploring Integration and Attribution in Online Creative Collaboration</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kurt Luther" class="author">Kurt Luther</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Nicholas Diakopoulos" class="author">Nicholas Diakopoulos</a> <a href="byAffiliation.html#Rutgers University" class="affiliation">Rutgers University</a>,<br /><a href="byAuthors.html#Amy Bruckman" class="author">Amy Bruckman</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Attribution allows online reputations to be formed and motivates many contributions to online creative collaboration. Yet, we know little about attribution practices in online creative collaboration and the technologies that shape them. This paper describes a study of online collaborative animation projects, focused on the practices surrounding integration and attribution. We found that both tasks are closely related and often completed by a single person, a process we call cr-editing.&quot; We also identify frustrations with existing practices and systems and propose design considerations for alleviating them. Our findings offer insights into the growing space of online remixing, mashups, and creativity.</span></div></div><div class="paper"><span class="title">Multi-lifespan Information System Design in Post-Conflict Societies: An Evolving Project in Rwanda</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Batya Friedman" class="author">Batya Friedman</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Lisa P. Nathan" class="author">Lisa P. Nathan</a> <a href="byAffiliation.html#University of British Columbia" class="affiliation">University of British Columbia</a>,<br /><a href="byAuthors.html#Milli Lake" class="author">Milli Lake</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Nell Carden Grey" class="author">Nell Carden Grey</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Trond T. Nilsen" class="author">Trond T. Nilsen</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Robert F. Utter" class="author">Robert F. Utter</a> <a href="byAffiliation.html#Unaffiliated" class="affiliation">Unaffiliated</a>,<br /><a href="byAuthors.html#Elizabeth J. Utter" class="author">Elizabeth J. Utter</a> <a href="byAffiliation.html#Unaffiliated" class="affiliation">Unaffiliated</a>,<br /><a href="byAuthors.html#Mark Ring" class="author">Mark Ring</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Zoe Kahn" class="author">Zoe Kahn</a> <a href="byAffiliation.html#Roosevelt High School" class="affiliation">Roosevelt High School</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we report on our early-stage research and design efforts to provide Rwandans with access to and reuse of video interviews from the International Criminal Tribunal for Rwanda.  More generally, we investigate methods and designs that can be deployed successfully within a post-conflict political climate concerned about recurring violence. This work: (1) directly supports the Rwandan people in their efforts to achieve justice, healing and reconciliation; (2) provides the HCI community with methods and approaches for undertaking design in post-conflict situations; and (3) describes the first empirical exploration of multi-lifespan information system design.</span></div></div><div class="paper"><span class="title">Cross Currents: Water Scarcity and Sustainable CHI</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Tad Hirsch" class="author">Tad Hirsch</a> <a href="byAffiliation.html#intel labs" class="affiliation">intel labs</a>,<br /><a href="byAuthors.html#Ken Anderson" class="author">Ken Anderson</a> <a href="byAffiliation.html#intel labs" class="affiliation">intel labs</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Growing awareness of the threats posed by global freshwater shortages coupled with increased interest in environmental sustainability among CHI researchers make water management a ripe area for new CHI applications. This paper presents a qualitative study of practices and attitudes in a water-stressed region of the United States. We describe water conservation as a culturally-situated activity influenced by a variety of social factors, and show sustainability to be a complicated concept rife with competing, often incompatible interpretations and prescriptions. We discuss implications for designing interfaces that encourage personal conservation, and identify environmental policy making as an area ripe for new CHI activity. Finally, we suggest that sustainability has the potential to move from the periphery of CHI research and become a galvanizing force for the community at large.</span></div></div><div class="paper"><span class="title">Connect 2 Congress: Visual Analytics for Civic Oversight</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Peter Kinnaird" class="author">Peter Kinnaird</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Mario Romero" class="author">Mario Romero</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Gregory Abowd" class="author">Gregory Abowd</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Strong representative democracies rely on educated, informed, and active citizenry to provide oversight of the government. We present Connect 2 Congress (C2C), a novel, high temporal-resolution and interactive visualization of legislative behavior. We present the results of focus group and domain expert interviews that demonstrate how different stakeholders use C2C for a variety of investigative activities. The evaluation provided evidence that users are able to support or reject claims made by candidates and conduct free-form, low-cost, exploratory analysis into the legislative behavior of representatives across time periods. </span></div></div><div class="paper"><span class="title">Who are the Crowdworkers? Shifting Demographics in Mechanical Turk</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Joel Ross" class="author">Joel Ross</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Lilly Irani" class="author">Lilly Irani</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#M. Six Silberman" class="author">M. Six Silberman</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Andrew Zaldivar" class="author">Andrew Zaldivar</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Bill Tomlinson" class="author">Bill Tomlinson</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Amazon Mechanical Turk (MTurk) is a crowdsourcing system in which tasks are distributed to a population of thousands of anonymous workers for completion. This system is increasingly popular with researchers and developers. Here we extend previous studies of the demographics and usage behaviors of MTurk workers. We describe how the worker population has changed over time, shifting from a primarily moderate-income, U.S.-based workforce towards an increasingly international group with a significant population of young, well-educated Indian workers. This change in population points to how workers may treat Turking as a full-time job, which they rely on to make ends meet.</span></div></div><div class="paper"><span class="title">Public Issues on Projected User Interface</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ju-Chun Ko" class="author">Ju-Chun Ko</a> <a href="byAffiliation.html#National Taiwan University, Graduate Institute of Networking and Multimedia" class="affiliation">National Taiwan University, Graduate Institute of Networking and Multimedia</a>,<br /><a href="byAuthors.html#Li-Wei Chan" class="author">Li-Wei Chan</a> <a href="byAffiliation.html#National Taiwan University, Graduate Institute of Networking and Multimedia" class="affiliation">National Taiwan University, Graduate Institute of Networking and Multimedia</a>,<br /><a href="byAuthors.html#Yi-Ping Hung" class="author">Yi-Ping Hung</a> <a href="byAffiliation.html#National Taiwan University, Graduate Institute of Networking and Multimedia" class="affiliation">National Taiwan University, Graduate Institute of Networking and Multimedia</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">What will happen when pocket projectors become mainstream personal display channels? What will be affected when numerous projections intrude our living space without proper control? Todays technology in projection has promised a big screen viewing experience from mobile devices, pushing us toward a truly ubiquitous display environment. But, is our society prepared for the next projection-generation?     We argue that the Projected user interface (PUI) will introduce new problems both in environmental and social aspects which are seldom been explored. This paper explores our rights to project and be projected in public space. Can we project on human body without asking for permission? Can we refuse to be projected? Can projection pollute the environment and influence the people therein?  This paper proposes several issues about peoples rights on projection, and provide discussions on possible solutions.</span></div></div></td>

<td colspan="10" class="session_details" id="S101_details"><div class="paper"><span class="title">A Death in the Family: Opportunities for Designing Technologies for the Bereaved</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Michael Massimi" class="author">Michael Massimi</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a>,<br /><a href="byAuthors.html#Ronald M. Baecker" class="author">Ronald M. Baecker</a> <a href="byAffiliation.html#University of Toronto" class="affiliation">University of Toronto</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Following the death of a loved one, bereaved family members use technology in several ways to respond to their loss. However, very little is known about how technology intersects with the lives of the bereaved. We present a survey and interview study which examines how the bereaved inherit personal digital devices, use technology to remember the deceased, and reflect on their own digital estates. The study provides one of the first characterizations of technology use by the bereaved, and presents a set of empirically-grounded design opportunities and challenges. </span></div></div><div class="paper"><span class="title">Passing On &amp; Putting To Rest: Understanding Bereavement in the Context of Interactive Technologies</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#William Odom" class="author">William Odom</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Richard Harper" class="author">Richard Harper</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Abigail Sellen" class="author">Abigail Sellen</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#David Kirk" class="author">David Kirk</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Richard Banks" class="author">Richard Banks</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">While it can be a delicate and emotionally-laden topic, new technological trends compel us to confront a range of problems and issues about death and bereavement. This area presents complex challenges and the associated literature is extensive. In this paper we offer a way of slicing through several perspectives in the social sciences to see clearly a set of salient issues related to bereavement. Following this, we present a theoretical lens to provide a way of conceptualizing how the HCI community could begin to approach such issues. We then report field evidence from 11 in-depth interviews conducted with bereaved participants and apply the proposed lens to unpack key emergent problems and tensions. We conclude with a discussion on how the HCI design space might be sensitized to better support the social processes that unfold when bereavement occurs. </span></div></div><div class="paper"><span class="title">Fear and the City - Role of Mobile Services in Harnessing Safety and Security in Urban Use Contexts</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Jan Blom" class="author">Jan Blom</a> <a href="byAffiliation.html#Nokia Research Center, Lausanne" class="affiliation">Nokia Research Center, Lausanne</a>,<br /><a href="byAuthors.html#Divya Viswanathan" class="author">Divya Viswanathan</a> <a href="byAffiliation.html#Nokia Research Center, Bangalore" class="affiliation">Nokia Research Center, Bangalore</a>,<br /><a href="byAuthors.html#Janet Go" class="author">Janet Go</a> <a href="byAffiliation.html#Nokia Research Center, Palo Alto" class="affiliation">Nokia Research Center, Palo Alto</a>,<br /><a href="byAuthors.html#Mirjana Spasojevic" class="author">Mirjana Spasojevic</a> <a href="byAffiliation.html#Nokia Research Center, Palo Alto" class="affiliation">Nokia Research Center, Palo Alto</a>,<br /><a href="byAuthors.html#Karthikeya Acharya" class="author">Karthikeya Acharya</a> <a href="byAffiliation.html#Nokia Research Center, Bangalore" class="affiliation">Nokia Research Center, Bangalore</a>,<br /><a href="byAuthors.html#Robert Ahonius" class="author">Robert Ahonius</a> <a href="byAffiliation.html#Nokia Research Center, Bangalore" class="affiliation">Nokia Research Center, Bangalore</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper describes investigation of a mobile communication system that helps alleviate fear experienced in the urban context. In order to obtain empirically grounded insights for the concept design, urban females in their twenties and thirties and living in Bangalore, New Delhi and San Francisco, were studied. More than 200 females filled in an online survey. Extensive qualitative data for 13 participants were collected through week long diaries, semi-structured interviews, and situated participative enactment of scenarios [1]. Fear-related concerns were voiced both in India and the U.S., suggesting that reducing fear, particularly in a pedestrian context after the onset of darkness, could be a globally applicable need. User research findings into subjective experiences of fear, contexts in which they occur, and behavioral strategies were used to design a mobile service titled ComfortZones. This concept was developed to the level of a high fidelity prototype and tested in a field trial in India. The investigation highlights further opportunities for design, particularly the notion of emphasizing positive and socially successful qualities of cities to communities concerned with their safety and security. </span></div></div></td>

<td colspan="10" class="session_details" id="S106_details"><div class="paper"><span class="title">Detecting Professional versus Personal Closeness Using an Enterprise Social Network Site</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Anna Wu" class="author">Anna Wu</a> <a href="byAffiliation.html#Pennsylvania State University" class="affiliation">Pennsylvania State University</a>,<br /><a href="byAuthors.html#Joan M. DiMicco" class="author">Joan M. DiMicco</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a>,<br /><a href="byAuthors.html#David R. Millen" class="author">David R. Millen</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this work we analyze the behavior on a company-internal social network site to determine which interaction patterns signal closeness between colleagues. Regression analysis suggests that employee behavior on social network sites (SNSs) reveals information about both professional and personal closeness. While some factors are predictive of general closeness (e.g. content recommendations), other factors signal that employees feel personal closeness towards their colleagues, but not professional closeness (e.g. mutual profile commenting). This analysis contributes to our understanding of how SNS behavior reflects relationship multiplexity: the multiple facets of our relationships with SNS connections. </span></div></div><div class="paper"><span class="title">Lessons Learned from Blog Muse: Audience-based Inspiration for Bloggers</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Casey Dugan" class="author">Casey Dugan</a> <a href="byAffiliation.html#IBM T.J. Watson Research" class="affiliation">IBM T.J. Watson Research</a>,<br /><a href="byAuthors.html#Werner Geyer" class="author">Werner Geyer</a> <a href="byAffiliation.html#IBM T.J. Watson Research" class="affiliation">IBM T.J. Watson Research</a>,<br /><a href="byAuthors.html#David R. Millen" class="author">David R. Millen</a> <a href="byAffiliation.html#IBM T.J. Watson Research" class="affiliation">IBM T.J. Watson Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Blogging in the enterprise is increasingly popular and recent research has shown that there are numerous benefits for both individuals and the organization, e.g. developing reputation or sharing knowledge. However, participation is very low, blogs are often abandoned and few users realize those benefits. We have designed and implemented a novel system - called Blog Muse - whose goal is to inspire potential blog writers by connecting them with their audience through a topic-suggestion system.  We describe our system design and report results from a 4-week study with 1004 users who installed our tool. Our data indicate that topics requested by users are effective at inspiring bloggers to write and lead to more social interactions around the resulting entries.</span></div></div><div class="paper"><span class="title">Factors Impeding Wiki Use in the Enterprise: A Case Study</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Lester Holtzblatt" class="author">Lester Holtzblatt</a> <a href="byAffiliation.html#MITRE Corporation" class="affiliation">MITRE Corporation</a>,<br /><a href="byAuthors.html#Laurie Damianos" class="author">Laurie Damianos</a> <a href="byAffiliation.html#MITRE Corporation" class="affiliation">MITRE Corporation</a>,<br /><a href="byAuthors.html#Daniel Weiss" class="author">Daniel Weiss</a> <a href="byAffiliation.html#MITRE Corporation" class="affiliation">MITRE Corporation</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Our research explored factors that impacted the use of wikis as a tool to support the dissemination of knowledge within an enterprise. Although we primarily talked to a population of wiki contributors and readers, we discovered two major factors which contributed to staffs unwillingness to share information on a wiki under certain circumstances. First, we uncovered a reluctance to share specific information due to a perceived extra cost, the nature of the information, the desire to share only finished content, and sensitivities to the openness of the sharing environment. Second, we discovered a heavy reliance on other, non-wiki tools based on a variety of factors including work practice, lack of guidelines, and cultural sensitivities. Our findings have several implications for how an enterprise may more fully reap the benefits of wiki technology. These include implementation of incentive structures, support for dynamic access control, documenting clear guidelines and policies, and making wikis more usable.</span></div></div></td>

<td colspan="10" class="session_details" id="S105_details"><div class="paper"><span class="title">Motivating Expressive Writing with a Text-to-Sound Application</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Amy Gonzales" class="author">Amy Gonzales</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Tiffany Ng" class="author">Tiffany Ng</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#OJ Zhao" class="author">OJ Zhao</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Geri Gay" class="author">Geri Gay</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Writing about emotional experiences has been shown to  have long-term physical and mental health benefits, but it  also creates short-term discomfort. There is currently no  research on how to motivate people to participate in  expressive writing. We designed a system to motivate  expressive writing by enhancing enjoyment and pleasure.  Using automated language analysis techniques, we  designed a system that maps sound onto categories of  language resulting in a musical interpretation of expressive  writing texts. An experimental design compared the  experience of 126 participants across musical and non-musical  writing platforms Participants found the musical  system to be more pleasurable. Despite reports of enjoying  the system more, participants that received musical  feedback reported greater negative affect following the  exercise. This suggests that the music may have enhanced  the effectiveness of the expressive writing paradigm in  improving health.</span></div></div><div class="paper"><span class="title">Artificial Subtle Expressions: Intuitive Notification Methodology of Artifacts</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Takanori Komatsu" class="author">Takanori Komatsu</a> <a href="byAffiliation.html#Shinshu University" class="affiliation">Shinshu University</a>,<br /><a href="byAuthors.html#Seiji Yamada" class="author">Seiji Yamada</a> <a href="byAffiliation.html#National Institute of Informatics" class="affiliation">National Institute of Informatics</a>,<br /><a href="byAuthors.html#Kazuki Kobayashi" class="author">Kazuki Kobayashi</a> <a href="byAffiliation.html#Shinshu University" class="affiliation">Shinshu University</a>,<br /><a href="byAuthors.html#Kotaro Funakoshi" class="author">Kotaro Funakoshi</a> <a href="byAffiliation.html#HRIJ" class="affiliation">HRIJ</a>,<br /><a href="byAuthors.html#Mikio Nakano" class="author">Mikio Nakano</a> <a href="byAffiliation.html#HRIJ" class="affiliation">HRIJ</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We describe artificial subtle expressions (ASEs) as intuitive notification methodology for artifacts' internal states for users. We prepared two types of audio ASEs; one was a flat artificial sound (flat ASE), and the other was a sound that decreased in pitch (decreasing ASE). These two ASEs were played after a robot made a suggestion to the users. Specifically, we expected that the decreasing ASE would inform users of the robot's lower level of confidence about the suggestions. We then conducted a simple experiment to observe whether the participants accepted or rejected the robot's suggestion in terms of the ASEs. The results showed that they accepted the robot's suggestion when the flat ASE was used, whereas they rejected it when the decreasing ASE was used. Therefore, we found that the ASEs succeeded in conveying the robot's internal state to the users accurately and intuitively.</span></div></div><div class="paper"><span class="title">SoundNet: Investigating a Language Composed of Environmental Sounds</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Xiaojuan Ma" class="author">Xiaojuan Ma</a> <a href="byAffiliation.html#Princeton University" class="affiliation">Princeton University</a>,<br /><a href="byAuthors.html#Christiane Fellbaum" class="author">Christiane Fellbaum</a> <a href="byAffiliation.html#Princeton University" class="affiliation">Princeton University</a>,<br /><a href="byAuthors.html#Perry Cook" class="author">Perry Cook</a> <a href="byAffiliation.html#Princeton University" class="affiliation">Princeton University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Auditory displays have been used in both human-machine and computer interfaces.  However, the use of non-speech audio in assistive communication for people with language disabilities, or in other applications that employ visual representations, is still under-investigated. In this paper, we introduce SoundNet, a linguistic database that associates natural environmental sounds with words and concepts. A sound labeling study was carried out to verify SoundNet associations and to investigate how well the sounds evoke concepts. A second study was conducted using the verified SoundNet data to explore the power of environmental sounds to convey concepts in sentence contexts, compared with conventional icons and animations. Our results show that sounds can effectively illustrate (especially concrete) concepts and can be applied to assistive interfaces.</span></div></div></td>

<td colspan="10" class="session_details" id="S100_details"><div class="paper"><span class="title">Understanding the space for co-design in riders' interactions with a transit service</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Daisy Yoo" class="author">Daisy Yoo</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#John Zimmerman" class="author">John Zimmerman</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Aaron Steinfeld" class="author">Aaron Steinfeld</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Anthony Tomasic" class="author">Anthony Tomasic</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The recent advances in web 2.0 technologies and the rapid adoption of smart phones raises many opportunities for public services to improve their services by engaging their users (who are also owners of the service) in co-design: a dialog where users help design the services they use. To investigate this opportunity, we began a service design project investigating how to create repeated information exchanges between riders and a transit agency in order to create a virtual place from which the dialog on services could take place. Through interviews with riders, a workshop with a transit agency, and speed dating of design concepts, we have developed a design direction. Specifically, we propose a service that combines vehicle location and fullness ratings provided by riders with dynamic route change information from the transit agency as a foundation for a dialog around riders conveying input for continuous service improvement.</span></div></div><div class="paper"><span class="title">OneBusAway: Results from Providing Real-Time Arrival Information for Public Transit</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Brian Ferris" class="author">Brian Ferris</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Kari Watkins" class="author">Kari Watkins</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Alan Borning" class="author">Alan Borning</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Public transit systems play an important role in combating traffic congestion, reducing carbon emissions, and promoting compact, sustainable urban communities.  The usability of public transit can be significantly enhanced by providing good traveler information systems.  We describe OneBusAway, a set of transit tools focused on providing real-time arrival information for Seattle-area bus riders.  We then present results from a survey of OneBusAway users that show a set of important positive outcomes: strongly increased overall satisfaction with public transit, decreased waiting time, increased transit trips per week, increased feelings of safety, and even a health benefit in terms of increased distance walked when using transit.  Finally, we discuss the design and policy implications of these results and plans for future research in this area.</span></div></div><div class="paper"><span class="title">Biketastic: Sensing and Mapping for Better Biking</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Sasank Reddy" class="author">Sasank Reddy</a> <a href="byAffiliation.html#University of California Los Angeles" class="affiliation">University of California Los Angeles</a>,<br /><a href="byAuthors.html#Katie Shilton" class="author">Katie Shilton</a> <a href="byAffiliation.html#University of California Los Angeles" class="affiliation">University of California Los Angeles</a>,<br /><a href="byAuthors.html#Gleb Denisov" class="author">Gleb Denisov</a> <a href="byAffiliation.html#University of California Los Angeles" class="affiliation">University of California Los Angeles</a>,<br /><a href="byAuthors.html#Christian Cenizal" class="author">Christian Cenizal</a> <a href="byAffiliation.html#University of California Los Angeles" class="affiliation">University of California Los Angeles</a>,<br /><a href="byAuthors.html#Deborah Estrin" class="author">Deborah Estrin</a> <a href="byAffiliation.html#University of California Los Angeles" class="affiliation">University of California Los Angeles</a>,<br /><a href="byAuthors.html#Mani Srivastava" class="author">Mani Srivastava</a> <a href="byAffiliation.html#University of California Los Angeles" class="affiliation">University of California Los Angeles</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Bicycling is an affordable, environmentally friendly alternative transportation mode to motorized travel. A common task performed by bikers is to find good routes in an area, where the quality of a route is based on safety, efficiency, and enjoyment. Finding routes involves trial and error as well as exchanging information between members of a bike community. Biketastic is a platform that enriches this experimentation and route sharing process making it both easier and more effective. Using a mobile phone application and online map visualization, bikers are able to document and share routes, ride statistics, sensed information to infer route roughness and noisiness, and media that documents ride experience. Biketastic was designed to ensure the link between information gathering, visualization, and bicycling practices. In this paper, we present architecture and algorithms for route data inferences and visualization.  We evaluate the system based on feedback from bicyclists provided during a two-week pilot.</span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">4:30&nbsp;PM<br/><em>to</em><br/>6:00&nbsp;PM</td>
<td class="session" id="S31">
<span class="type">ToCHI</span>
<span class="title">Activities, Access Control &amp; Networking</span>
<span class="location"></span>
</td>
<td class="session" id="S110">
<span class="type">Papers/Notes</span>
<span class="title">Remember and Reflect</span>
<span class="location">Centennial 1</span>
</td>
<td class="session" id="S26">
<span class="type">Panel</span>
<span class="title">HCI, Communities and Politics</span>
<span class="location">Centennial 2</span>
</td>
<td class="session" id="S108">
<span class="type">Papers/Notes</span>
<span class="title">Home Eco Behavior</span>
<span class="location">Centennial 3</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S111">
<span class="type">Papers/Notes</span>
<span class="title">Sharing in Specific Communities</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S16">
<span class="type">SIG</span>
<span class="title">Designing User Interfaces for Multi-Touch and Surface-Gesture Devices</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S109">
<span class="type">Papers/Notes</span>
<span class="title">On the Phone</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S112">
<span class="type">Papers/Notes</span>
<span class="title">Something Eye Catching</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S113">
<span class="type">Papers/Notes</span>
<span class="title">Therapy and Rehabilitation</span>
<span class="location">Regency 7</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
</tr>
<tr class="details_row">

<td colspan="9" class="session_details" id="S31_details"><div class="paper"><span class="title">Activity-Based Computing for Medical Work in Hospitals</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jakob Bardram" class="author">Jakob Bardram</a> <a href="byAffiliation.html#IT University of Copenhagen" class="affiliation">IT University of Copenhagen</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The visions of the future ubiquitous computing are to have users transparently use a wide range of heterogeneous computing devices and services in their daily work and life. To meet this goal there is a need for moving the level of computational support from the level of files and applications to support human activities. In this paper we present the concept of Activity-Based Computing (ABC). ABC covers a set of design principles for an ubiquitous computing environment that helps users to arrange and adapt computational resource into support for carrying out parallel, alternating, cooperative activities while moving around in this computing environment. The paper presents our current Java-based implementation of such an activity-based ubiquitous computing environments, called the ABC Framework. The ABC Framework has, among other things, special support for Activity Roaming, enabling users to work nomadically while preserving computational support for their activities, and support for Activity Sharing, enabling users to seamlessly cooperate around an activity. The paper presents how the ABC Framework was evaluated by creating an ABC-aware electronic patient record (EPR) on top of the framework, and how this ABC EPR was evaluated during 15+ evaluation and design workshops. The paper discusses the outcome of these evaluation session, both concerning the usability of the ABC Framework as well as on a more conceptual level.</span></div></div><div class="paper"><span class="title">Computer Supported Access Control</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Gunnar Stevens" class="author">Gunnar Stevens</a> <a href="byAffiliation.html#University of Siegen" class="affiliation">University of Siegen</a>,<br /><a href="byAuthors.html#Volker Wulf" class="author">Volker Wulf</a> <a href="byAffiliation.html#University of Siegen and Fraunhofer FIT" class="affiliation">University of Siegen and Fraunhofer FIT</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Traditionally, access control is understood to be a purely technical mechanism which rejects or accepts access attempts automatically based on a preconfiguration. In this paper, we reconceptualize the issue of access control on a theoretical, methodological and practical level. On a theoretical level, we develop a terminology which allows differentiating between access control practices and the technical support mechanisms. On a methodological level, we analyze empirical research into access control practices from a situated action perspective. Applying these findings to a practical level, we enhance the design space of technical mechanisms for computer supported access control.</span></div></div><div class="paper"><span class="title">Experiences with Recombinant Computing: Exploring Ad Hoc Interoperability in Evolving Networks</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#W. Keith Edwards" class="author">W. Keith Edwards</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Mark Newman" class="author">Mark Newman</a> <a href="byAffiliation.html#University of Michigan" class="affiliation">University of Michigan</a>,<br /><a href="byAuthors.html#Jana Sedivy" class="author">Jana Sedivy</a> <a href="byAffiliation.html#Palo Alto Research Center" class="affiliation">Palo Alto Research Center</a>,<br /><a href="byAuthors.html#Trevor Smith" class="author">Trevor Smith</a> <a href="byAffiliation.html#Palo Alto Research Center" class="affiliation">Palo Alto Research Center</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We describe an infrastructure that supports evolution of networked systems while maintaining interoperability among those systems. Our approach uses mobile code to extend the behavior of peers at runtime. While this approach removes many constraints to interoperability, it limits the user experience of systems that use it: since devices may work with peers about which they have no detailed semantic knowledge, users must perform the arbitration necessary to determine how devices will be used together. We describe the motivation and details of our infrastructure, its user experience implications, and our experiences in using it over a period of several years.</span></div></div><div class="paper"><span class="title">The Ins and Outs of Home Networking: The Case for Useful and Usable Domestic Networking</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Rebecca E. Grinter" class="author">Rebecca E. Grinter</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#W. Keith Edwards" class="author">W. Keith Edwards</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Marshini Chetty" class="author">Marshini Chetty</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Erika Shehan Poole" class="author">Erika Shehan Poole</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Ja-Young Sung" class="author">Ja-Young Sung</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Jeonghwa Yang" class="author">Jeonghwa Yang</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Andy Crabtree" class="author">Andy Crabtree</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Peter Tolmie" class="author">Peter Tolmie</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Tom Rodden" class="author">Tom Rodden</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Chris Greenhalgh" class="author">Chris Greenhalgh</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Steve Benford" class="author">Steve Benford</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Home networks are increasingly being adopted as a solution to technical complexity in the home: multiple computers, devices, and users are driving the demand. Current network solutions are derived from the world of work and provide poor support for the needs of the home. We present the key findings to emerge from qualitative studies of home networks in the UK and US. The studies reveal two key kinds of work that effective home networking relies upon: one, the technical work of setting up and maintaining the home network, and the other, the collaborative and socially organized work of the home in which the network is embedded and supports. The two are thoroughly intertwined and rely upon one another for their realization, yet neither is adequately supported by current networking technologies and applications. Explication of the work to make the home network work opens up the design space for the continued integration of the home network in domestic life and elaboration of future support. Key issues for development include the development of networking facilities that do not require advanced networking knowledge, that are flexible and support the local social order of the home and the evolution of its routines, and which ultimately make the home network visible and accountable to household members.</span></div></div></td>

<td colspan="9" class="session_details" id="S110_details"><div class="paper"><span class="title">Pensieve: Supporting Everyday Reminiscence</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#S. Tejaswi Peesapati" class="author">S. Tejaswi Peesapati</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Victoria Schwanda" class="author">Victoria Schwanda</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Johnathon Schultz" class="author">Johnathon Schultz</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Matt Lepage" class="author">Matt Lepage</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#So-yae Jeong" class="author">So-yae Jeong</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Dan Cosley" class="author">Dan Cosley</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Reminiscing is a valuable activity that people of all ages spontaneously and informally partake in as part of their everyday lives. This paper discusses the design and use of Pensieve, a system that supports everyday reminiscence by emailing memory triggers to people that contain either social media content they previously created on third-party websites or text prompts about common life experiences. We discuss how the literature on reminiscence informed Pensieve's design, then analyze data from 91 users over five months. We find that people value spontaneous reminders to reminisce as well as the ability to write about their reminiscing. Shorter, more general triggers draw more responses, as do triggers containing people's own photosalthough responses to photos tended to contain more metadata elements than storytelling elements. We compare these results to data from a second, Pensieve-like system developed for Facebook, and suggest a number of important aspects to consider for both designers and researchers around technology and reminiscence.</span></div></div><div class="paper"><span class="title">Involving Reflective Users in Design</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Paula M. Bach" class="author">Paula M. Bach</a> <a href="byAffiliation.html#Graduate School of Library and Information Science, University of Illinois" class="affiliation">Graduate School of Library and Information Science, University of Illinois</a>,<br /><a href="byAuthors.html#Michael Twidale" class="author">Michael Twidale</a> <a href="byAffiliation.html#Graduate School of Library and Information Science, University of Illinois" class="affiliation">Graduate School of Library and Information Science, University of Illinois</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We draw on the idea of the reflective practitioner to consider how end users can directly contribute to user experience design discussions in open source projects. People with expertise in their own use context but without programming or user experience analysis and design skills can provide reflections on personal experiences. </span></div></div><div class="paper"><span class="title">Designing Games for Learning: Insights from Conversations with Designers</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Katherine Isbister" class="author">Katherine Isbister</a> <a href="byAffiliation.html#NYU-Poly" class="affiliation">NYU-Poly</a>,<br /><a href="byAuthors.html#Mary Flanagan" class="author">Mary Flanagan</a> <a href="byAffiliation.html#Dartmouth College" class="affiliation">Dartmouth College</a>,<br /><a href="byAuthors.html#Chelsea Hash" class="author">Chelsea Hash</a> <a href="byAffiliation.html#NYU-Poly" class="affiliation">NYU-Poly</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper presents insights about design practices that can lead to effective and fun games for learning, gleaned from interviews with experienced game developers. We based our approach on Schön's notion of practitioners evolving shared appreciation systems' for discussing and critiquing work, and aimed to gather and share some of game designers' appreciation system' for games and learning. The resulting insights provide valuable pointers to other designers in the CHI community crafting game-like experiences.</span></div></div><div class="paper"><span class="title">Now Let Me See Where I Was: Understanding How Lifelogs Mediate Memory</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Vaiva Kalnikaite" class="author">Vaiva Kalnikaite</a> <a href="byAffiliation.html#The University of Sheffield" class="affiliation">The University of Sheffield</a>,<br /><a href="byAuthors.html#Abigail Sellen" class="author">Abigail Sellen</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Steve Whittaker" class="author">Steve Whittaker</a> <a href="byAffiliation.html#IBM Research Almaden" class="affiliation">IBM Research Almaden</a>,<br /><a href="byAuthors.html#David Kirk" class="author">David Kirk</a> <a href="byAffiliation.html#The University of Nottingham" class="affiliation">The University of Nottingham</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Lifelogging technologies can capture both mundane and important experiences in our daily lives, resulting in a rich record of the places we visit and the things we see. This study moves beyond technology demonstrations, in aiming to better understand how and why different types of Lifelogs aid memory. Previous work has demonstrated that Lifelogs can aid recall, but that they do many other things too. They can help us look back at the past in new ways, or to reconstruct what we did in our lives, even if we don't recall exact details. Here we extend the notion of Lifelogging to include locational information. We augment streams of Lifelog images with geographic data to examine how different types of data (visual or locational) might affect memory. Our results show that visual cues promote detailed memories (akin to recollection). In contrast locational information supports inferential processes - allowing participants to reconstruct habits in their behaviour.</span></div></div></td>

<td colspan="9" class="session_details" id="S26_details"><div class="paper"><span class="title">HCI, Communities and Politics</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Carl DiSalvo" class="author">Carl DiSalvo</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Ann Light" class="author">Ann Light</a> <a href="byAffiliation.html#Sheffield Hallam University" class="affiliation">Sheffield Hallam University</a>,<br /><a href="byAuthors.html#Tad Hirsch" class="author">Tad Hirsch</a> <a href="byAffiliation.html#Intel" class="affiliation">Intel</a>,<br /><a href="byAuthors.html#Christopher A. Le Dantec" class="author">Christopher A. Le Dantec</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Katie Hill" class="author">Katie Hill</a> <a href="byAffiliation.html#Leeds Metropolitan University" class="affiliation">Leeds Metropolitan University</a>,<br /><a href="byAuthors.html#Elizabeth Goodman" class="author">Elizabeth Goodman</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Working with communities around social change presents a challenge to common HCI methods, as politics often comes to the fore. In some cases, the politics of a community are explicit, for example, when working with activists or advocacy groups. In other cases, political aspects are less explicit but surface in considering the allocation of resources or in groups wherein issues of race, gender or class are of major importance. To address these dynamics, HCI researchers have to go beyond traditional HCI tools and metrics, which too often bracket out the political in an effort to focus on the instrumental issues and uses of technology. This panel juxtaposes several community-based HCI research projects in which politics have been a significant factor and asks How do we address the politics inherent in community-based HCI research? </span></div></div></td>

<td colspan="9" class="session_details" id="S108_details"><div class="paper"><span class="title">Home, Habits, and Energy: Examining Domestic Interactions and Energy Consumption</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#James Pierce" class="author">James Pierce</a> <a href="byAffiliation.html#Computer Science Laboratory, Palo Alto Research Center (PARC),   HCI Institute, Carnegie Mellon University" class="affiliation">Computer Science Laboratory, Palo Alto Research Center (PARC),   HCI Institute, Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Diane J. Schiano" class="author">Diane J. Schiano</a> <a href="byAffiliation.html#Search and Advertising Metrics &amp; Analysis (SAMA), Yahoo!, Inc.,    Palo Alto Research Center (PARC)" class="affiliation">Search and Advertising Metrics &amp; Analysis (SAMA), Yahoo!, Inc.,    Palo Alto Research Center (PARC)</a>,<br /><a href="byAuthors.html#Eric Paulos" class="author">Eric Paulos</a> <a href="byAffiliation.html#HCI Institute, Carnegie Mellon University" class="affiliation">HCI Institute, Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper presents findings from a qualitative study of people's everyday interactions with energy-consuming products and systems in the home. Initial results from a large online survey are also considered. This research focuses not only on conservation behavior but importantly investigates interactions with technology that may be characterized as normal consumption or over-consumption. A novel vocabulary for analyzing and designing energy-conserving interactions is proposed based on our findings, including: cutting, trimming, switching, upgrading, and shifting. Using the proposed vocabulary, and informed by theoretical developments from various literatures, this paper demonstrates ways in which everyday interactions with technology in the home are performed without conscious consideration of energy consumption but rather are unconscious, habitual, and irrational. Implications for the design of energy-conserving interactions with technology and broader challenges for HCI research are proposed.  </span></div></div><div class="paper"><span class="title">Studying Always-On Electricity Feedback in the Home</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Yann Riche" class="author">Yann Riche</a> <a href="byAffiliation.html#Riche Design" class="affiliation">Riche Design</a>,<br /><a href="byAuthors.html#Jonathan Dodge" class="author">Jonathan Dodge</a> <a href="byAffiliation.html#School of EECS  Oregon State University" class="affiliation">School of EECS  Oregon State University</a>,<br /><a href="byAuthors.html#Ronald A. Metoyer" class="author">Ronald A. Metoyer</a> <a href="byAffiliation.html#School of EECS  Oregon State University" class="affiliation">School of EECS  Oregon State University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The recent emphasis on sustainability has made consumers more aware of their responsibility for saving resources, in particular, electricity. Consumers can better understand how to save electricity by gaining awareness of their consumption beyond the typical monthly bill.   We conducted a study to understand consumers' awareness of energy consumption in the home and to determine their requirements for an interactive, always-on interface for exploring data to gain awareness of home energy consumption. In this paper, we describe a three-stage approach to supporting electricity conservation routines: raise awareness, inform complex changes, and maintain sustainable routines. We then present the findings from our study to support design implications for energy consumption feedback interfaces.</span></div></div><div class="paper"><span class="title">The Design of Eco-Feedback Technology</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Jon Froehlich" class="author">Jon Froehlich</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Leah Findlater" class="author">Leah Findlater</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#James Landay" class="author">James Landay</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Eco-feedback technology provides feedback on individual or group behaviors with a goal of reducing environmental impact. The history of eco-feedback extends back more than 40 years to the origins of environmental psychology. Despite its stated purpose, few HCI eco-feedback studies have attempted to measure behavior change. This leads to two overarching questions: (1) what can HCI learn from environmental psychology and (2) what role should HCI have in designing and evaluating eco-feedback technology? To help answer these questions, this paper conducts a comparative survey of eco-feedback technology, including 89 papers from environmental psychology and 44 papers from the HCI and UbiComp literature. We also provide an overview of predominant models of proenvironmental behaviors and a summary of key motivation techniques to promote this behavior. </span></div></div></td>

<td colspan="9" class="session_details" id="S111_details"><div class="paper"><span class="title">The Prayer Companion: Openness and Specificity, Materiality and Spirituality</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#William Gaver" class="author">William Gaver</a> <a href="byAffiliation.html#Goldsmiths, University of London" class="affiliation">Goldsmiths, University of London</a>,<br /><a href="byAuthors.html#Mark Blythe" class="author">Mark Blythe</a> <a href="byAffiliation.html#University of York" class="affiliation">University of York</a>,<br /><a href="byAuthors.html#Andy Boucher" class="author">Andy Boucher</a> <a href="byAffiliation.html#Goldsmiths, University of London  " class="affiliation">Goldsmiths, University of London  </a>,<br /><a href="byAuthors.html#Nadine Jarvis" class="author">Nadine Jarvis</a> <a href="byAffiliation.html#Goldsmiths, University of London" class="affiliation">Goldsmiths, University of London</a>,<br /><a href="byAuthors.html#John Bowers" class="author">John Bowers</a> <a href="byAffiliation.html#Goldsmiths, University of London" class="affiliation">Goldsmiths, University of London</a>,<br /><a href="byAuthors.html#Peter Wright" class="author">Peter Wright</a> <a href="byAffiliation.html#Sheffield Hallam University" class="affiliation">Sheffield Hallam University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we describe the Prayer Companion, a device we developed as a resource for the spiritual activity of a group of cloistered nuns. The device displays a stream of information sourced from RSS news feeds and social networking sites to suggest possible topics for prayers.  The nuns have engaged with the device enthusiastically over the first ten months of an ongoing deployment, and, notwithstanding some initial irritation with the balance of content, report that it plays a significant and continuing role in their prayer life. We discuss how we balanced specificity in the design with a degree of openness for interpretation to create a resource that the nuns could both understand and appropriate, describe the importance of materiality to the device's successful adoption, consider its implications as a design for older people, and reflect on the example it provides of how computation may serve spirituality.</span></div></div><div class="paper"><span class="title">What's Your Idea? A Case Study of a Grassroots Innovation Pipeline within a Large Software Company</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Brian Bailey" class="author">Brian Bailey</a> <a href="byAffiliation.html#Department of Computer Science, University of Illinois and    Microsoft Research  " class="affiliation">Department of Computer Science, University of Illinois and    Microsoft Research  </a>,<br /><a href="byAuthors.html#Eric Horvitz" class="author">Eric Horvitz</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Establishing a grassroots innovation pipeline has come to the fore as strategy for nurturing innovation within large organizations. A key element of such pipelines is the use of an idea management system that enables and encourages community ideation on defined business problems. The value of these systems can be highly sensitive to design choices, as different designs may influence participation. We report the results of a case study examining the use of one particular idea management system and pipeline. We analyzed the content, interaction, and participation from three creativity challenges organized via the pipeline and conducted interviews with users to uncover motivations for participating and perceptions of the outcomes. Additional interviews were conducted with senior managers to learn about the objectives, successes, and unique nature of the pipeline. From the results, we formulate recommendations for improving the design of idea management systems and execution of the pipelines within organizations.</span></div></div><div class="paper"><span class="title">ASL-STEM Forum: Enabling Sign Language to Grow Through Online Collaboration</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Anna C. Cavender" class="author">Anna C. Cavender</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Daniel S. Otero" class="author">Daniel S. Otero</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Jeffrey P. Bigham" class="author">Jeffrey P. Bigham</a> <a href="byAffiliation.html#University of Rochester" class="affiliation">University of Rochester</a>,<br /><a href="byAuthors.html#Richard E. Ladner" class="author">Richard E. Ladner</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">American Sign Language (ASL) currently lacks agreed-upon signs for complex terms in scientific fields, causing deaf students to miss or misunderstand course material. Furthermore, the same term or concept may have multiple signs, resulting in inconsistent standards and strained collaboration. The ASL-STEM Forum is an online, collaborative, video forum for sharing ASL signs and discussing them. An initial user study of the Forum has shown its viability and revealed lessons in accommodating varying user types, from lurkers to advanced contributors, until critical mass is achieved.</span></div></div><div class="paper"><span class="title">Curator: A Game with a Purpose for Collection Recommendation</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Greg Walsh" class="author">Greg Walsh</a> <a href="byAffiliation.html#University of Maryland, College Park" class="affiliation">University of Maryland, College Park</a>,<br /><a href="byAuthors.html#Jennifer Golbeck" class="author">Jennifer Golbeck</a> <a href="byAffiliation.html#University of Maryland, College Park" class="affiliation">University of Maryland, College Park</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Collection recommender systems suggest groups of items that work well as a whole. The interaction effects between items is an important consideration, but the vast space of possible collections makes it difficult to analyze. In this paper, we present a class of games with a purpose for building collections where users create collections and, using an output agreement model, they are awarded points based on the collections that match. The data from these games will help researchers develop guidelines for collection recommender systems among other applications. We conducted a pilot study of the game prototype which indicated that it was fun and challenging for users, and that the data obtained had the characteristics necessary to gain insights into the interaction effects among items. We present the game and these results followed by a discussion of the next steps necessary to bring games to bear on the problem of creating harmonious groups.</span></div></div></td>

<td colspan="9" class="session_details" id="S16_details"><div class="paper"><span class="title">Designing User Interfaces for Multi-Touch and Surface-Gesture Devices</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Daniel Wigdor" class="author">Daniel Wigdor</a> <a href="byAffiliation.html#Microsoft Surface " class="affiliation">Microsoft Surface </a>,<br /><a href="byAuthors.html#Gerald Morrison" class="author">Gerald Morrison</a> <a href="byAffiliation.html#Smart Technologies" class="affiliation">Smart Technologies</a></div></div></td>

<td colspan="9" class="session_details" id="S109_details"><div class="paper"><span class="title">Mobile Taskflow in Context: A Screenshot Study of Smartphone Usage</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Amy K. Karlson" class="author">Amy K. Karlson</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Shamsi T. Iqbal" class="author">Shamsi T. Iqbal</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Brian Meyers" class="author">Brian Meyers</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Gonzalo Ramos" class="author">Gonzalo Ramos</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a>,<br /><a href="byAuthors.html#Kathy Lee" class="author">Kathy Lee</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a>,<br /><a href="byAuthors.html#John C. Tang" class="author">John C. Tang</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The impact of interruptions on workflow and productivity has been extensively studied in the PC domain, but while fragmented user attention is recognized as an inherent aspect of mobile phone usage, little formal evidence exists of its effect on mobile productivity. Using a survey and a screenshot-based diary study we investigated the types of barriers people face when performing tasks on their mobile phones, the ways they follow up with such suspended tasks, and how frustrating the experience of task disruption is for mobile users. From 386 situated samples provided by 12 iPhone and 12 Pocket PC users, we distill a classification of barriers to the completion of mobile tasks. Our data suggest that moving to a PC to complete a phone task is common, yet not inherently problematic, depending on the task. Finally, we relate our findings to prior design guidelines for desktop workflow, and discuss how the guidelines can be extended to mitigate disruptions to mobile taskflow.</span></div></div><div class="paper"><span class="title">An Adaptive Speed-Call List Algorithm and Its Evaluation with ESM</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Seunghwan Lee" class="author">Seunghwan Lee</a> <a href="byAffiliation.html#Korea Advanced Institute of Science and Technology" class="affiliation">Korea Advanced Institute of Science and Technology</a>,<br /><a href="byAuthors.html#Jungsuk Seo" class="author">Jungsuk Seo</a> <a href="byAffiliation.html#Korea Advanced Institute of Science and Technology" class="affiliation">Korea Advanced Institute of Science and Technology</a>,<br /><a href="byAuthors.html#Geehyuk Lee" class="author">Geehyuk Lee</a> <a href="byAffiliation.html#Korea Advanced Institute of Science and Technology" class="affiliation">Korea Advanced Institute of Science and Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We designed an algorithm to build a speed-call list adaptively based on mobile phone call logs. Call logs provide the time-dependent calling patterns of mobile phone users, and therefore a speed-call list based on them will be more successful in recommending a desired number than a speed-call list based on recent calls only. This paper presents the design process of our algorithm for an adaptive speed-call list, its verification result with recorded call logs, and in-situ evaluation results of the algorithm using an Experience Sampling Method (ESM) system.</span></div></div><div class="paper"><span class="title">Evaluation of Text Entry Methods for Korean Mobile Phones, a User Study</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Ivaylo Ilinkin" class="author">Ivaylo Ilinkin</a> <a href="byAffiliation.html#Gettysburg College" class="affiliation">Gettysburg College</a>,<br /><a href="byAuthors.html#Sunghee Kim" class="author">Sunghee Kim</a> <a href="byAffiliation.html#Gettysburg College" class="affiliation">Gettysburg College</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper reports the results of a user study designed to evaluate text entry methods for mobile phones used in Korea. At present the keypad layout for Korean mobile phones has not been standardized and different manufacturers produce phones with different layouts. Included in the evaluation are three of the dominant text entry methods: Chon-ji-in, EZ-Hangul, and SKY. The metrics used in the analysis are key strokes per character, words per minute, and total error rate. The results suggest that SKY offers a good balance between speed, effort, and accuracy. The paper also introduces a phrase set that has high correlation with the Korean language and could be used in other experiments on Korean text entry methods.</span></div></div><div class="paper"><span class="title">Contacts 3.0: Bringing together research and design teams to reinvent the phonebook</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Frank Bentley" class="author">Frank Bentley</a> <a href="byAffiliation.html#Motorola Applied Research" class="affiliation">Motorola Applied Research</a>,<br /><a href="byAuthors.html#Rafiq Ahmed" class="author">Rafiq Ahmed</a> <a href="byAffiliation.html#Motorola Mobile Devices" class="affiliation">Motorola Mobile Devices</a>,<br /><a href="byAuthors.html#JoEllen Kames" class="author">JoEllen Kames</a> <a href="byAffiliation.html#Motorola Mobile Devices" class="affiliation">Motorola Mobile Devices</a>,<br /><a href="byAuthors.html#Lauren Schwendimann" class="author">Lauren Schwendimann</a> <a href="byAffiliation.html#Motorola Mobile Devices" class="affiliation">Motorola Mobile Devices</a>,<br /><a href="byAuthors.html#Rhiannon Zivin" class="author">Rhiannon Zivin</a> <a href="byAffiliation.html#Motorola Mobile Devices" class="affiliation">Motorola Mobile Devices</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present a narrative of the design of Contacts 3.0, a service and updated phonebook application on a mobile device that combines on-device communication with communication from online social networks to create a central hub for communication on the device.  We discuss how research and design teams worked together to create design assets, technical architectures, and business cases around this concept.</span></div></div></td>

<td colspan="9" class="session_details" id="S112_details"><div class="paper"><span class="title">Modeling Dwell-Based Eye Pointing Target Acquisition</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Xinyong Zhang" class="author">Xinyong Zhang</a> <a href="byAffiliation.html#Renmin University of China, Peking University, Beijing Institute of Technology" class="affiliation">Renmin University of China, Peking University, Beijing Institute of Technology</a>,<br /><a href="byAuthors.html#Xiangshi Ren" class="author">Xiangshi Ren</a> <a href="byAffiliation.html#Kochi University of Technology" class="affiliation">Kochi University of Technology</a>,<br /><a href="byAuthors.html#Hongbin Zha" class="author">Hongbin Zha</a> <a href="byAffiliation.html#Peking University" class="affiliation">Peking University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We propose a quantitative model for dwell-based eye pointing tasks. Using the concepts of information theory to analogize eye pointing, we define an index of difficulty (IDeye) for the corresponding tasks in a similar manner to the definition that Fitts made for hand pointing. According to our validations in different situations, IDeye, which takes account of the distinct characteristics of rapid saccades and involuntary eye jitters, can accurately and meaningfully describe eye pointing tasks. To the best of our knowledge, this work is the first successful attempt to model gaze interactions.</span></div></div><div class="paper"><span class="title">Gazemarks - Gaze-Based Visual Placeholders to Ease Attention Switching</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Dagmar Kern" class="author">Dagmar Kern</a> <a href="byAffiliation.html#Pervasive Computing and User Interface Engineering Group, University of Duisburg-Essen" class="affiliation">Pervasive Computing and User Interface Engineering Group, University of Duisburg-Essen</a>,<br /><a href="byAuthors.html#Paul Marshall" class="author">Paul Marshall</a> <a href="byAffiliation.html#Pervasive Interaction Lab,  Open University" class="affiliation">Pervasive Interaction Lab,  Open University</a>,<br /><a href="byAuthors.html#Albrecht Schmidt" class="author">Albrecht Schmidt</a> <a href="byAffiliation.html#Pervasive Computing and User Interface Engineering Group, University of Duisburg-Essen" class="affiliation">Pervasive Computing and User Interface Engineering Group, University of Duisburg-Essen</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Many tasks require attention switching. For example, searching for information on one sheet of paper and then entering this information onto another one. With paper we see that people use fingers or objects as placeholders. Using these simple aids, the process of switching attention between displays can be simplified and speeded up. With large or multiple visual displays we have many tasks where both attention areas are on the screen and where using a finger as a placeholder is not suitable. One way users deal with this is to use the mouse and highlight their current focus. However, this also has its limitations - in particular in environments where there is no pointing device. Our approach is to utilize the user's gaze position to provide a visual placeholder. The last area where a user fixated on the screen (before moving their attention away) is highlighted; we call this visual reminder a Gazemark. Gazemarks ease orientation and the resumption of the interrupted task when coming back to this display. In this paper we report on a study where the effectiveness of using Gazemarks was investigated, in particular we show how they can ease attention switching. Our results show faster completion times for a resumed simple visual search task when using this technique. The paper analyzes relevant parameters for the implementation of Gazemarks and discusses some further application areas for this approach.</span></div></div><div class="paper"><span class="title">Knowing Where and When to Look in &amp;#8232;a Time-Critical Multimodal Dual Task</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Anthony J. Hornof" class="author">Anthony J. Hornof</a> <a href="byAffiliation.html#University of Oregon" class="affiliation">University of Oregon</a>,<br /><a href="byAuthors.html#Yunfeng Zhang" class="author">Yunfeng Zhang</a> <a href="byAffiliation.html#University of Oregon" class="affiliation">University of Oregon</a>,<br /><a href="byAuthors.html#Tim Halverson" class="author">Tim Halverson</a> <a href="byAffiliation.html#University of Oregon" class="affiliation">University of Oregon</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Human-computer systems intended for time-critical multitasking need to be designed with an understanding of how humans can coordinate and interleave perceptual, memory, and motor processes.  This paper presents human performance data for a highly-practiced time-critical dual task.  In the first of the two interleaved tasks, participants tracked a target with a joystick.  In the second, participants keyed-in responses to objects moving across a radar display.  Task manipulations include the peripheral visibility of the secondary display (visible or not) and the presence or absence of auditory cues to assist with the radar task.  Eye movement analyses reveal extensive coordination and overlapping of human information processes and the extent to which task manipulations helped or hindered dual task performance.  For example, auditory cues helped only a little when the secondary display was peripherally visible, but they helped a lot when it was not peripherally visible.</span></div></div></td>

<td colspan="9" class="session_details" id="S113_details"><div class="paper"><span class="title">Towards Customizable Games for Stroke Rehabilitation</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Gazihan Alankus" class="author">Gazihan Alankus</a> <a href="byAffiliation.html#Washington University in St. Louis" class="affiliation">Washington University in St. Louis</a>,<br /><a href="byAuthors.html#Amanda Lazar" class="author">Amanda Lazar</a> <a href="byAffiliation.html#University of California, San Diego" class="affiliation">University of California, San Diego</a>,<br /><a href="byAuthors.html#Matt May" class="author">Matt May</a> <a href="byAffiliation.html#Washington University in St. Louis" class="affiliation">Washington University in St. Louis</a>,<br /><a href="byAuthors.html#Caitlin Kelleher" class="author">Caitlin Kelleher</a> <a href="byAffiliation.html#Washington University in St. Louis" class="affiliation">Washington University in St. Louis</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Stroke is the leading cause of long term disability among adults in industrialized nations. The partial paralysis that stroke patients often experience can make independent living difficult or impossible. Research suggests that many of these patients could recover by performing hundreds of daily repetitions of motions with their affected limbs. Yet, only 31% of patients perform the exercises recommended by their therapists. Home-based stroke rehabilitation games may help motivate stroke patients to perform the necessary exercises to recover. In this paper, we describe a formative study in which we designed and user tested stroke rehabilitation games with both stroke patients and therapists. We describe the lessons we learned about what makes games useful from a therapeutic point of view.</span></div></div><div class="paper"><span class="title">Designing Patient-Centric Information Displays for Hospitals</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Lauren Wilcox" class="author">Lauren Wilcox</a> <a href="byAffiliation.html#Columbia University" class="affiliation">Columbia University</a>,<br /><a href="byAuthors.html#Dan Morris" class="author">Dan Morris</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Desney Tan" class="author">Desney Tan</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Justin Gatewood" class="author">Justin Gatewood</a> <a href="byAffiliation.html#Washington Hospital Center" class="affiliation">Washington Hospital Center</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Electronic medical records are increasingly comprehensive, and this vast repository of information has already contri-buted to medical efficiency and hospital procedure. However, this information is not typically accessible to patients, who are frequently under-informed and unclear about their own hospital courses. In this paper, we propose a design for in-room, patient-centric information displays, based on iterative design with physicians. We use this as the basis for a Wizard-of-Oz study in an emergency department, to assess patient and provider responses to in-room information displays. 18 patients were presented with real-time information displays based on their medical records. Semi-structured interviews with patients, family members, and hospital staff reveal that subjective response to in-room displays was overwhelmingly positive, and through these interviews we elicited guidelines regarding specific information types, privacy, use cases, and information presentation techniques. We describe these findings, and we discuss the feasibility of a fully-automatic implementation of our design.</span></div></div><div class="paper"><span class="title">Supporting Sandtray Therapy on an Interactive Tabletop</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Mark Hancock" class="author">Mark Hancock</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a>,<br /><a href="byAuthors.html#Thomas Ten Cate" class="author">Thomas Ten Cate</a> <a href="byAffiliation.html#University of Groningen" class="affiliation">University of Groningen</a>,<br /><a href="byAuthors.html#Sheelagh Carpendale" class="author">Sheelagh Carpendale</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a>,<br /><a href="byAuthors.html#Tobias Isenberg" class="author">Tobias Isenberg</a> <a href="byAffiliation.html#University of Groningen" class="affiliation">University of Groningen</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present the iterative design of a virtual sandtray application for a tabletop display. The purpose of our prototype is to support sandtray therapy, a form of art therapy typically used for younger clients. A significant aspect of this therapy is the insight gained by the therapist as they observe the client interact with the figurines they use to create a scene in the sandtray. In this manner, the therapist can gain increased understanding of the client's psyche. We worked with three sandtray therapists throughout the evolution of our prototype. We describe the details of the three phases of this design process: initial face-to-face meetings, iterative design and development via distance collaboration, and a final face-to-face feedback session. This process revealed that our prototype was sufficient for therapists to gain insight about a person's psyche through their interactions with the virtual sandtray.</span></div></div></td>

</tr>
</table>
</div>
<div class="day" id="04/15/10">
<h1>Thursday, April 15</h1>
<table cellspacing="0" class="program">
<tr class="timeslot">
<td class="time">9:00&nbsp;AM<br/><em>to</em><br/>10:30&nbsp;AM</td>
<td class="session" id="S114">
<span class="type">Papers/Notes</span>
<span class="title">Everyday Gestures</span>
<span class="location">Centennial 1</span>
</td>
<td class="session" id="S116">
<span class="type">Papers/Notes</span>
<span class="title">Multitouch</span>
<span class="location">Centennial 3</span>
</td>
<td class="session" id="S117">
<span class="type">Papers/Notes</span>
<span class="title">Perspectives on Design</span>
<span class="location">Centennial 4</span>
</td>
<td class="session" id="S17">
<span class="type">SIG</span>
<span class="title">Contextual User Experience: How to reflect it in Interaction Designs?</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S115">
<span class="type">Papers/Notes</span>
<span class="title">HCI in China</span>
<span class="location">Hanover CDE</span>
</td>
<td class="session" id="S121">
<span class="type">Papers/Notes</span>
<span class="title">We Are Family</span>
<span class="location">Hanover FG</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S118">
<span class="type">Papers/Notes</span>
<span class="title">Public Displays</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S119">
<span class="type">Papers/Notes</span>
<span class="title">Sensing</span>
<span class="location">Regency 6</span>
</td>
<td class="session" id="S120">
<span class="type">Papers/Notes</span>
<span class="title">Usability Methods and New Domains</span>
<span class="location">Regency 7</span>
</td>
</tr>
<tr class="details_row">

<td colspan="9" class="session_details" id="S114_details"><div class="paper"><span class="title">MAGIC: A Motion Gesture Design Tool</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Daniel Ashbrook" class="author">Daniel Ashbrook</a> <a href="byAffiliation.html#Georgia Tech &amp; Nokia Research Center Hollywood" class="affiliation">Georgia Tech &amp; Nokia Research Center Hollywood</a>,<br /><a href="byAuthors.html#Thad Starner" class="author">Thad Starner</a> <a href="byAffiliation.html#Georgia Tech" class="affiliation">Georgia Tech</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Devices capable of gestural interaction through motion sensing are increasingly becoming available to consumers; however, motion gesture control has yet to appear outside of game consoles. Interaction designers are frequently not expert in pattern recognition, which may be one reason for this lack of availability. Another issue is how to effectively test gestures to ensure that they are not unintentionally activated by a user's normal movements during everyday usage. We present MAGIC, a gesture design tool that addresses both of these issues, and detail the results of an evaluation.</span></div></div><div class="paper"><span class="title">Protractor: A Fast and Accurate Gesture Recognizer</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Yang Li" class="author">Yang Li</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Protractor is a novel gesture recognizer that can be easily implemented and quickly customized for different users. Protractor uses a nearest neighbor approach, which recognizes an unknown gesture based on its similarity to each of the known gestures, e.g., training samples or examples given by a user. In particular, it employs a novel method to measure the similarity between gestures, by calculating a minimum angular distance between them with a closed-form solution. As a result, Protractor is more accurate, naturally covers more gesture variation, runs significantly faster and uses much less memory than its peers. This makes Protractor suitable for mobile computing, which is limited in processing power and memory. An evaluation on both a previously published gesture data set and a newly collected gesture data set indicates that Protractor outperforms its peers in many aspects.</span></div></div><div class="paper"><span class="title">GesText: Accelerometer-Based Gestural Text-Entry Systems</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Eleanor Jones" class="author">Eleanor Jones</a> <a href="byAffiliation.html#University of Bristol" class="affiliation">University of Bristol</a>,<br /><a href="byAuthors.html#Jason Alexander" class="author">Jason Alexander</a> <a href="byAffiliation.html#University of Bristol" class="affiliation">University of Bristol</a>,<br /><a href="byAuthors.html#Andreas Andreou" class="author">Andreas Andreou</a> <a href="byAffiliation.html#University of Bristol" class="affiliation">University of Bristol</a>,<br /><a href="byAuthors.html#Pourang Irani" class="author">Pourang Irani</a> <a href="byAffiliation.html#University of Manitoba" class="affiliation">University of Manitoba</a>,<br /><a href="byAuthors.html#Sriram Subramanian" class="author">Sriram Subramanian</a> <a href="byAffiliation.html#University of Bristol" class="affiliation">University of Bristol</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Accelerometers are common on many devices, including those required for text-entry. We investigate how to enter text with devices that are solely enabled with accelerometers. The challenge of text-entry with such devices can be overcome by the careful investigation of the human limitations in gestural movements with accelerometers. Preliminary studies provide insight into two potential text-entry designs that purely use accelerometers for gesture recognition. In two experiments, we evaluate the effectiveness of each of the text-entry designs. The first experiment involves novice users over a 45 minute period while the second in-vestigates the possible performance increases over a four day period. Our results reveal that a matrix-based text-entry system with a small set of simple gestures is the most efficient (5.4wpm) and subjectively preferred by participants.</span></div></div></td>

<td colspan="9" class="session_details" id="S116_details"><div class="paper"><span class="title">Multi-touch techniques for Exploring Large-Scale 3D Astrophysical Simulations</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Chi-Wing Fu" class="author">Chi-Wing Fu</a> <a href="byAffiliation.html#Nanyang Technological University" class="affiliation">Nanyang Technological University</a>,<br /><a href="byAuthors.html#Wooi Boon Goh" class="author">Wooi Boon Goh</a> <a href="byAffiliation.html#Nanyang Technological University" class="affiliation">Nanyang Technological University</a>,<br /><a href="byAuthors.html#Junxiang Allen Ng" class="author">Junxiang Allen Ng</a> <a href="byAffiliation.html#Nanyang Technological University" class="affiliation">Nanyang Technological University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Enabling efficient exploration of large-scale virtual environments such as those simulating astrophysical environments is highly challenging.  Astrophysical virtual worlds span exceptionally large spatial scales occupied mostly by empty space, and this makes it difficult for the user to comprehend the spatial context during exploratory navigation.  Public exhibits, where novice users have little experience using complicated virtual navigation interfaces, pose additional challenges.    To address these issues, we propose multi-touch techniques to deliver an effective interface to navigate the unique features of large-scale 3D environments such as astrophysical simulations.  In this work,  we carefully study conventional multi-touch methods and adapt them to the practical requirements of this application.  A novel technique called the powers-of-ten ladder is introduced to support efficient movement across huge spatial scales using multi-touch interactions.  We also investigate user experiences with various multi-touch finger gestures on our prototype digital planetarium.</span></div></div><div class="paper"><span class="title">Graspables Revisited: Multi-Touch vs. Tangible Input for Tabletop Displays in Acquisition and Manipulation Tasks</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Philip Tuddenham" class="author">Philip Tuddenham</a> <a href="byAffiliation.html#University of Cambridge" class="affiliation">University of Cambridge</a>,<br /><a href="byAuthors.html#David Kirk" class="author">David Kirk</a> <a href="byAffiliation.html#University of Nottingham" class="affiliation">University of Nottingham</a>,<br /><a href="byAuthors.html#Shahram Izadi" class="author">Shahram Izadi</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present an experimental comparison of multi-touch and tangible user interfaces for basic interface actions. Twelve participants completed manipulation and acquisition tasks on an interactive surface in each of three conditions: tangible user interface; multi-touch; and mouse and puck. We found that interface control objects in the tangible condition were easiest to acquire and, once acquired, were easier/more accurate to manipulate. Further qualitative analysis suggested that in the evaluated tasks tangibles offer greater adaptability of control and specifically highlighted a problem of exit error that can undermine fine-grained control in multi-touch interactions. We discuss the implications of these findings for interface design.</span></div></div><div class="paper"><span class="title">The Design and Evaluation of Multitouch Marking Menus</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Julian Lepinski" class="author">Julian Lepinski</a> <a href="byAffiliation.html#Autodesk Research" class="affiliation">Autodesk Research</a>,<br /><a href="byAuthors.html#Tovi Grossman" class="author">Tovi Grossman</a> <a href="byAffiliation.html#Autodesk Research" class="affiliation">Autodesk Research</a>,<br /><a href="byAuthors.html#George Fitzmaurice" class="author">George Fitzmaurice</a> <a href="byAffiliation.html#Autodesk Research" class="affiliation">Autodesk Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Despite the considerable quantity of research directed towards multitouch technologies, a set of standardized UI components have not been developed. Menu systems provide a particular challenge, as traditional GUI menus require a level of pointing precision inappropriate for direct finger input. Marking menus are a promising alternative, but have yet to be investigated or adapted for use within multitouch systems. In this paper, we first investigate the human capabilities for performing directional chording gestures, to assess the feasibility of multitouch marking menus. Based on the positive results collected from this study, and in particular, high angular accuracy, we discuss our new multitouch marking menu design, which can increase the number of items in a menu, and eliminate a level of depth. A second experiment showed that multitouch marking menus perform significantly faster than traditional hierarchal marking menus, reducing acquisition times in both novice and expert usage modalities.</span></div></div></td>

<td colspan="9" class="session_details" id="S117_details"><div class="paper"><span class="title">Multi-lifespan Information System Design: A Research Initiative for the HCI Community</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Batya Friedman" class="author">Batya Friedman</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Lisa P. Nathan" class="author">Lisa P. Nathan</a> <a href="byAffiliation.html#University of British Columbia" class="affiliation">University of British Columbia</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This CHI Note proposes a new research initiative for the HCI community: multi-lifespan information system design.  The central idea begins with the identification of categories of problems that are unlikely to be solved within a single human lifespan.  Three such categories are proposed: limitations of the human psyche, limitations of the structure of society, and slower moving natural time-scales.  We then examine possible opportunities and roles for information systems to help construct longer-term solutions to such problems and, in turn, identify key challenges for such systems.  Finally, we conclude by discussing significant real world problems that would benefit from a multi-lifespan design approach and point to open questions.  This CHI Note's key contribution entails the articulation of a promising new research initiative for the HCI community.</span></div></div><div class="paper"><span class="title">Designing Interactivity in Media Interfaces: A Communications Perspective</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#S. Shyam Sundar" class="author">S. Shyam Sundar</a> <a href="byAffiliation.html#Penn State University" class="affiliation">Penn State University</a>,<br /><a href="byAuthors.html#Qian Xu" class="author">Qian Xu</a> <a href="byAffiliation.html#Penn State University" class="affiliation">Penn State University</a>,<br /><a href="byAuthors.html#Saraswathi Bellur" class="author">Saraswathi Bellur</a> <a href="byAffiliation.html#Penn State University" class="affiliation">Penn State University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Interactivity has become ubiquitous in the digital media landscape. Numerous interactive tools are designed, tested, deployed and evaluated. Yet, we do not have generalizable knowledge about the larger concept of interactivity and its psychological impact on user experience. As a first step toward a theory of interface interactivity, this paper identifies three species of interactivity corresponding to three central elements of communication - source, medium, and message. Interactivity situated in any of these three loci of communication can provide cues and affordances that operate either individually or together to capture users' attention and determine the nature and depth of their processing of online content as well as contribute to their perceptions, attitudes and behavioral intentions. This paper discusses psychological mechanisms by which the three classes of interactivity tools affect users, with the specific purpose of drawing out design implications and outlining UI challenges for strategic development of interactive interfaces.</span></div></div><div class="paper"><span class="title">Designing with Interactive Example Galleries</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Brian Lee" class="author">Brian Lee</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Savil Srivastava" class="author">Savil Srivastava</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Ranjitha Kumar" class="author">Ranjitha Kumar</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Ronen Brafman" class="author">Ronen Brafman</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Scott R. Klemmer" class="author">Scott R. Klemmer</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Designers often use examples for inspiration; examples offer contextualized instances of how form and content integrate. Can interactive example galleries bring this practice to everyday users doing design work, and does working with examples help the designs they create? This paper explores whether people can realize significant value from explicit mechanisms for designing by example modification. We present the results of three studies, finding that independent raters prefer designs created with the aid of examples, that users prefer adaptively selected examples to random ones, and that users make use of multiple examples when creating new designs. To enable these studies and demonstrate how software tools can facilitate designing with examples, we introduce interface techniques for browsing and borrowing from a corpus of examples, manifest in the Adaptive Ideas Web design tool. Adaptive Ideas leverages a faceted metadata interface for viewing and navigating example galleries.</span></div></div></td>

<td colspan="9" class="session_details" id="S17_details"><div class="paper"><span class="title">Contextual User Experience: How to reflect it in Interaction Designs?</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Manfred Tscheligi" class="author">Manfred Tscheligi</a> <a href="byAffiliation.html#University of Salzburg - ICT&amp;S" class="affiliation">University of Salzburg - ICT&amp;S</a>,<br /><a href="byAuthors.html#Marianna Obrist" class="author">Marianna Obrist</a> <a href="byAffiliation.html#University of Salzburg - ICT&amp;S" class="affiliation">University of Salzburg - ICT&amp;S</a>,<br /><a href="byAuthors.html#Boris De Ruyter" class="author">Boris De Ruyter</a> <a href="byAffiliation.html#Philips Research Europe" class="affiliation">Philips Research Europe</a>,<br /><a href="byAuthors.html#Albrecht Schmidt" class="author">Albrecht Schmidt</a> <a href="byAffiliation.html#University of Duisburg-Essen" class="affiliation">University of Duisburg-Essen</a></div></div></td>

<td colspan="9" class="session_details" id="S115_details"><div class="paper"><span class="title">Predicting Chinese Text Entry Speeds on Mobile Phones</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Ying Liu" class="author">Ying Liu</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Kari-Jouko Räihä" class="author">Kari-Jouko Räihä</a> <a href="byAffiliation.html#Unit for Computer-Human Interaction, Department of Computer Science, University of Tampere" class="affiliation">Unit for Computer-Human Interaction, Department of Computer Science, University of Tampere</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Chinese text entry on mobile phones is critical considering the large number of Chinese speakers worldwide and as a key task in many core applications. But there is still a lack of both empirical data and predictive models that explore the pattern of user behavior in the process. We propose a model to predict user performance with two types of Chinese pinyin input methods on mobile phones. The model integrates a language model (digraph probability) with Fitts' law for key presses, a keystroke-level model for navigation, and a linear model for visual search in pinyin marks and Chinese characters. We tested the model by comparing its predictions with the empirical measures. The predictions are satisfactory and the percentage differences are all within 4% of the empirical results, suggesting that the model can be used to evaluate user performance of Chinese pinyin text entry solutions on mobile phones.</span></div></div><div class="paper"><span class="title">Chinese Online Communities: Balancing Management Control and Individual Autonomy</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Qinying Liao" class="author">Qinying Liao</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a>,<br /><a href="byAuthors.html#Yingxin Pan" class="author">Yingxin Pan</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a>,<br /><a href="byAuthors.html#Michelle X. Zhou" class="author">Michelle X. Zhou</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a>,<br /><a href="byAuthors.html#Fei Ma" class="author">Fei Ma</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Existing studies of online social communities mainly focus on communities in the United States. Since Chinese social beliefs and behaviors largely differ from that of Americans, we hypothesize that Chinese online communities also greatly differ from their U.S. counterparts. In particular, we believe that Chinese online communities must balance management control and individual autonomy to accommodate both Chinese tradition and the social nature of online societies. In this paper, we present three studies to test our hypothesis. First, we use a structured observation (Study I) to examine community governance practices of 32 Chinese and American social sites. Based on the identified community governance practices, we use a cross-cultural survey of 208 Chinese and Americans (Study II) to learn about their behavior and attitude toward these practices. Finally, we interview 38 Chinese users (Study III) to help us further understand how Chinese online communities balance the needs of management and users. Not only do the studies confirm our hypothesis, but they also help us abstract two key design implications of social software to meet the needs of Chinese. </span></div></div><div class="paper"><span class="title">How Socio-Economic Structure Influences Rural Users' Acceptance of Mobile Entertainment</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jun Liu" class="author">Jun Liu</a> <a href="byAffiliation.html#Tsinghua University" class="affiliation">Tsinghua University</a>,<br /><a href="byAuthors.html#Ying Liu" class="author">Ying Liu</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Pei-Luen Patrick Rau" class="author">Pei-Luen Patrick Rau</a> <a href="byAffiliation.html#Tsinghua University" class="affiliation">Tsinghua University</a>,<br /><a href="byAuthors.html#Hui Li" class="author">Hui Li</a> <a href="byAffiliation.html#Tsinghua University" class="affiliation">Tsinghua University</a>,<br /><a href="byAuthors.html#Xia Wang" class="author">Xia Wang</a> <a href="byAffiliation.html#Nokia Research Center" class="affiliation">Nokia Research Center</a>,<br /><a href="byAuthors.html#Dingjun Li" class="author">Dingjun Li</a> <a href="byAffiliation.html#Tsinghua University" class="affiliation">Tsinghua University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Mobile entertainment services are rapidly and widely developing. However, in emerging markets like Chinese rural area, entertainment related services are still not fully accepted by mobile phone users. This primary research aimed to study Chinese rural people's acceptance for mobile entertainment, to provide comprehensive models, and to explain the problem from its socio-economic roots. Interview and survey data were collected. Using explorative factor analysis method, two mobile entertainment acceptance models were built: one for rural people in North China and the other in East China. The models show that social influence is the most influential factor for north rural users while users' self efficacy carries the largest weight in East China. Both factors are more important than product and service quality. The socio-economic roots of the results were analyzed from the differences between the traditional interdependent society in North China and the more independent society in East China. It primarily reveals the possibility to predict users' technology acceptance with socio-economic variables. Implications for mobile entertainment design were discussed.</span></div></div></td>

<td colspan="9" class="session_details" id="S121_details"><div class="paper"><span class="title">Designing a Technological Playground: A Field Study of the Emergence of Play in Household Messaging</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Siân E. Lindley" class="author">Siân E. Lindley</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Richard Harper" class="author">Richard Harper</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Abigail Sellen" class="author">Abigail Sellen</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present findings from a field study of Wayve, a situated messaging device for the home that incorporates handwriting and photography. Wayve was used by 24 households (some of whom were existing social networks of family and friends) over a three-month period. We consider the various types of playfulness that emerged during the study, both through the sending of Wayve messages and through the local display of photos and notes. The findings are explored in the context of the literature on play, with the aim of identifying aspects of Wayve's design, as well as the context in which it was used, that engendered playfulness. We also highlight the role of play in social relationships, before concluding with design implications.</span></div></div><div class="paper"><span class="title">The Family Window: The Design and Evaluation of a Domestic Media Space</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Tejinder K. Judge" class="author">Tejinder K. Judge</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a>,<br /><a href="byAuthors.html#Carman Neustaedter" class="author">Carman Neustaedter</a> <a href="byAffiliation.html#Kodak Research Labs" class="affiliation">Kodak Research Labs</a>,<br /><a href="byAuthors.html#Andrew F. Kurtz" class="author">Andrew F. Kurtz</a> <a href="byAffiliation.html#Kodak Research Labs" class="affiliation">Kodak Research Labs</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Families have a strong need to connect with their loved ones over distance. However, most technologies do not provide the same feelings of connectedness that one feels from seeing remote family members. Hence our goal was to understand if a video connection, in the form of a media space, could help families feel more connected and what design factors would be critical for its success. To answer this, we designed a video media space called the Family Window and deployed it within the homes of two families for eight months and four families for five weeks. Our results show that always-on video can lead to an increase in feelings of connectedness by providing availability awareness and opportunities for sharing everyday life. However usage and value of such media spaces hinges on close-knit relationships and control over one's autonomy.</span></div></div><div class="paper"><span class="title">FM Radio: Family Interplay with Sonic Mementos</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Daniela Petrelli" class="author">Daniela Petrelli</a> <a href="byAffiliation.html#University of Sheffield" class="affiliation">University of Sheffield</a>,<br /><a href="byAuthors.html#Nicolas Villar" class="author">Nicolas Villar</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Vaiva Kalnikaite" class="author">Vaiva Kalnikaite</a> <a href="byAffiliation.html#University of Sheffield" class="affiliation">University of Sheffield</a>,<br /><a href="byAuthors.html#Lina Dib" class="author">Lina Dib</a> <a href="byAffiliation.html#Rice University" class="affiliation">Rice University</a>,<br /><a href="byAuthors.html#Steve Whittaker" class="author">Steve Whittaker</a> <a href="byAffiliation.html#University of Sheffield" class="affiliation">University of Sheffield</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Digital mementos are increasingly problematic, as people acquire large amounts of digital belongings that are hard to access and often forgotten. Based on fieldwork with 10 families, we designed a new type of embodied digital memento, the FM Radio. It allows families to access and play sonic mementos of their previous holidays. We describe our underlying design motivation where recordings are presented as a series of channels on an old fashioned radio. User feedback suggests that the device met our design goals: being playful and intriguing, easy to use and social. It facilitated family interaction, and allowed ready access to mementos, thus sharing many of the properties of physical mementos that we intended to trigger.</span></div></div></td>

<td colspan="9" class="session_details" id="S118_details"><div class="paper"><span class="title">Worlds of Information: Designing for Engagement at a Public Multi-Touch Display</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Giulio Jacucci" class="author">Giulio Jacucci</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology HIIT, Aalto University" class="affiliation">Helsinki Institute for Information Technology HIIT, Aalto University</a>,<br /><a href="byAuthors.html#Ann Morrison" class="author">Ann Morrison</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology HIIT, Aalto University" class="affiliation">Helsinki Institute for Information Technology HIIT, Aalto University</a>,<br /><a href="byAuthors.html#Gabriela T. Richard" class="author">Gabriela T. Richard</a> <a href="byAffiliation.html#Educational Communication and Technology, New York University" class="affiliation">Educational Communication and Technology, New York University</a>,<br /><a href="byAuthors.html#Jari Kleimola" class="author">Jari Kleimola</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology HIIT, Aalto University" class="affiliation">Helsinki Institute for Information Technology HIIT, Aalto University</a>,<br /><a href="byAuthors.html#Peter Peltonen" class="author">Peter Peltonen</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology HIIT, Aalto University" class="affiliation">Helsinki Institute for Information Technology HIIT, Aalto University</a>,<br /><a href="byAuthors.html#Lorenza Parisi" class="author">Lorenza Parisi</a> <a href="byAffiliation.html#Facoltà di Scienze della Comunicazione, Sapienza Università di Roma" class="affiliation">Facoltà di Scienze della Comunicazione, Sapienza Università di Roma</a>,<br /><a href="byAuthors.html#Toni Laitinen" class="author">Toni Laitinen</a> <a href="byAffiliation.html#Helsinki Institute for Information Technology HIIT, Aalto University" class="affiliation">Helsinki Institute for Information Technology HIIT, Aalto University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In designing for engagement at a public multi-touch installation, we identified supporting multiple users and allowing for gradual discovery as challenges. In this paper, we present Worlds of Information, a multi-touch application featuring 3D Worlds, which provide access to different content. These 3D widgets gradually unfold and allow for temporal navigation of multimedia in parallel, while also providing a 2D plane where media can be shared. We report on a field trial at an exhibition using questionnaires and video ethnography. We studied engagement through questions adapted from Flow, Presence and Intrinsic Motivation questionnaires, which showed that users, overall, had a positive and social experience with the installation. The worlds effectively invited multiple users and provided for parallel interaction. While functionality was discovered gradually through social learning, the study demonstrates the challenges of designing multi-touch applications for walk-up-and-use displays.</span></div></div><div class="paper"><span class="title">Designing Urban Media Façades: Cases and Challenges</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Peter Dalsgaard" class="author">Peter Dalsgaard</a> <a href="byAffiliation.html#Aarhus University, Centre for Digital Urban Living" class="affiliation">Aarhus University, Centre for Digital Urban Living</a>,<br /><a href="byAuthors.html#Kim Halskov" class="author">Kim Halskov</a> <a href="byAffiliation.html#Aarhus University, Centre for Digital Urban Living" class="affiliation">Aarhus University, Centre for Digital Urban Living</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Media façades comprise a category of urban computing concerned with the integration of displays into the built environment, including buildings and street furniture. This paper identifies and discusses eight challenges faced when designing urban media façades. The challenges concern a broad range of issues: interfaces, physical integration, robustness, content, stakeholders, situation, social relations, and emerging use. The challenges reflect the fact that the urban setting as a domain for interaction design is characterized by a number of circumstances and socio-cultural practices that differ from those of other domains. In order to exemplify the challenges and discuss how they may be addressed, we draw on our experiences from five experimental design cases, ranging from a 180 m2 interactive building façade to displays integrated into bus shelters. </span></div></div><div class="paper"><span class="title">Touch Projector: Mobile Interaction through Video</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sebastian Boring" class="author">Sebastian Boring</a> <a href="byAffiliation.html#University of Munich" class="affiliation">University of Munich</a>,<br /><a href="byAuthors.html#Dominikus Baur" class="author">Dominikus Baur</a> <a href="byAffiliation.html#University of Munich" class="affiliation">University of Munich</a>,<br /><a href="byAuthors.html#Andreas Butz" class="author">Andreas Butz</a> <a href="byAffiliation.html#University of Munich" class="affiliation">University of Munich</a>,<br /><a href="byAuthors.html#Sean Gustafson" class="author">Sean Gustafson</a> <a href="byAffiliation.html#Hasso Plattner Institute" class="affiliation">Hasso Plattner Institute</a>,<br /><a href="byAuthors.html#Patrick Baudisch" class="author">Patrick Baudisch</a> <a href="byAffiliation.html#Hasso Plattner Institute" class="affiliation">Hasso Plattner Institute</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In 1992, Tani et al. proposed remotely operating machines in a factory by manipulating a live video image on a computer screen. In this paper we revisit this metaphor and investigate its suitability for mobile use. We present Touch Projector, a system that enables users to interact with remote screens through a live video image on their mobile device. The handheld device tracks itself with respect to the surrounding displays. Touch on the video image is &quot;projected&quot; onto the target display in view, as if it had occurred there. This literal adaptation of Tani's idea, however, fails because handheld video does not offer enough stability and control to enable precise manipulation. We address this with a series of improvements, including zooming and freezing the video image. In a user study, participants selected targets and dragged targets between displays using the literal and three improved versions. We found that participants achieved highest performance with automatic zooming and temporary image freezing.</span></div></div></td>

<td colspan="9" class="session_details" id="S119_details"><div class="paper"><span class="title">High Accuracy Position and Orientation Detection in Two-Dimensional Communication Network</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Kei Nakatsuma" class="author">Kei Nakatsuma</a> <a href="byAffiliation.html#The University of Tokyo" class="affiliation">The University of Tokyo</a>,<br /><a href="byAuthors.html#Hiroyuki Shinoda" class="author">Hiroyuki Shinoda</a> <a href="byAffiliation.html#The University of Tokyo" class="affiliation">The University of Tokyo</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we describe a method of high accuracy device position and orientation detection for HCI environments. Our position and orientation detection is an additional function to the Two-Dimensional Communication technology, which enables devices placed on a thin sheet to achieve two key functions for ubiquitous computing, to communicate one another and to receive electricity through the sheet wirelessly. This paper discusses the method developed to specify the positions and orientation of devices placed on the sheet. It evaluates the accuracy of obtained position and orientation through an experiment using a prototype of our positioning sensor. </span></div></div><div class="paper"><span class="title">Rethinking RFID: Awareness and Control For Interaction With RFID Systems</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Nicolai Marquardt" class="author">Nicolai Marquardt</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a>,<br /><a href="byAuthors.html#Alex S. Taylor" class="author">Alex S. Taylor</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Nicolas Villar" class="author">Nicolas Villar</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Saul Greenberg" class="author">Saul Greenberg</a> <a href="byAffiliation.html#University of Calgary" class="affiliation">University of Calgary</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">People now routinely carry radio frequency identification (RFID) tags - in passports, driver's licenses, credit cards, and other identifying cards - from which nearby RFID readers can access privacy-sensitive information. The problem is that people are often unaware of security and privacy risks associated with RFID, likely because the technology remains largely invisible and uncontrollable for the individual. To mitigate this problem, we introduce a collection of novel yet simple and inexpensive tag designs. Our tags provide reader awareness, where people get visual, audible, or tactile feedback as tags come into the range of RFID readers. Our tags also provide information control, where people can allow or disallow access to the information stored on the tag by how they touch, orient, move, press or illuminate the tag. </span></div></div><div class="paper"><span class="title">SensorTune: a Mobile Auditory Interface for DIY Wireless  Sensor Networks</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Enrico Costanza" class="author">Enrico Costanza</a> <a href="byAffiliation.html#School of Computer &amp; Communication Sciences, EPFL, now  ECS School, University of Southampton, UK" class="affiliation">School of Computer &amp; Communication Sciences, EPFL, now  ECS School, University of Southampton, UK</a>,<br /><a href="byAuthors.html#Jaques Panchard" class="author">Jaques Panchard</a> <a href="byAffiliation.html#School of Computer &amp; Communication Sciences, EPFL, now   Itecor - IT Governance, Geneva,    Switzerland" class="affiliation">School of Computer &amp; Communication Sciences, EPFL, now   Itecor - IT Governance, Geneva,    Switzerland</a>,<br /><a href="byAuthors.html#Guillaume Zufferey" class="author">Guillaume Zufferey</a> <a href="byAffiliation.html#School of Computer &amp; Communication Sciences, EPFL" class="affiliation">School of Computer &amp; Communication Sciences, EPFL</a>,<br /><a href="byAuthors.html#Julien Nembrini" class="author">Julien Nembrini</a> <a href="byAffiliation.html#School of Computer &amp; Communication Sciences, EPFL, now  Constructive and Structural Design Lab, UdK Berlin, Germany" class="affiliation">School of Computer &amp; Communication Sciences, EPFL, now  Constructive and Structural Design Lab, UdK Berlin, Germany</a>,<br /><a href="byAuthors.html#Julien Freudiger" class="author">Julien Freudiger</a> <a href="byAffiliation.html#School of Computer &amp; Communication Sciences, EPFL" class="affiliation">School of Computer &amp; Communication Sciences, EPFL</a>,<br /><a href="byAuthors.html#Jeffrey Huang" class="author">Jeffrey Huang</a> <a href="byAffiliation.html#School of Computer &amp; Communication Sciences, EPFL" class="affiliation">School of Computer &amp; Communication Sciences, EPFL</a>,<br /><a href="byAuthors.html#Jean-Pierre Hubaux" class="author">Jean-Pierre Hubaux</a> <a href="byAffiliation.html#School of Computer &amp; Communication Sciences, EPFL" class="affiliation">School of Computer &amp; Communication Sciences, EPFL</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Wireless Sensor Networks (WSNs) allow the monitoring of activity or environmental conditions over a large area, from homes to industrial plants, from agriculture fields to forests and glaciers. They can support a variety of applications, from assisted living to natural disaster prevention. WSNs can, however, be challenging to setup and maintain, reducing the potential for real-world adoption. To address this limitation, this paper introduces SensorTune, a novel mobile interface to support non-expert users in iteratively setting up a WSN. SensorTune uses non-speech audio to present to its users information regarding the connectivity of the network they are setting up, allowing them to decide how to extend it. To simplify the interpretation of the data presented, the system adopts the metaphor of tuning a consumer analog radio, a very common and well known operation. SensorTune represents the first attempt to apply mobile sonification to the domain of WSNs. A user study was conducted in which 20 subjects setup real multi-hop networks inside a large building using a limited number of wireless nodes. Subjects repeated the task with SensorTune and with a comparable mobile GUI interface. Experimental results show a statistically significant difference in the task completion time and a clear preference of users for the auditory interface.  </span></div></div></td>

<td colspan="9" class="session_details" id="S120_details"><div class="paper"><span class="title">API Usability Peer Reviews: A Method for Evaluating the Usability of Application Programming Interfaces</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Umer Farooq" class="author">Umer Farooq</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a>,<br /><a href="byAuthors.html#Leon Welicki" class="author">Leon Welicki</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a>,<br /><a href="byAuthors.html#Dieter Zirkler" class="author">Dieter Zirkler</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We describe a usability inspection method to evaluate Application Programming Interfaces (APIs). We found the method useful as it identified usability defects in part of Microsoft's .NET Framework, of which 59% were new and 21% were fixed. Based on a comparison of usability defects identified between API usability peer reviews and API usability tests, API usability tests were found to expose design issues related to actually using an API whereas API usability peer reviews were found to expose the design rationale of an API. We reflect on the efficiency and productivity of each method: each API usability test is equivalent to approximately 16 API usability peer reviews. We discuss how API usability peer reviews can be used in conjunction with API usability tests to increase usability coverage on APIs. </span></div></div><div class="paper"><span class="title">Understanding Usability Practices in Complex Domains</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Parmit K. Chilana" class="author">Parmit K. Chilana</a> <a href="byAffiliation.html#University of Washington (UW)" class="affiliation">University of Washington (UW)</a>,<br /><a href="byAuthors.html#Jacob O. Wobbrock" class="author">Jacob O. Wobbrock</a> <a href="byAffiliation.html#University of Washington (UW)" class="affiliation">University of Washington (UW)</a>,<br /><a href="byAuthors.html#Andrew J. Ko" class="author">Andrew J. Ko</a> <a href="byAffiliation.html#University of Washington (UW)" class="affiliation">University of Washington (UW)</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Although usability methods are widely used for evaluating conventional graphical user interfaces and websites, there is a growing concern that current approaches are inadequate for evaluating complex, domain-specific tools. We interviewed 21 experienced usability professionals, including in-house experts, external consultants, and managers working in a variety of complex domains, and uncovered the challenges commonly posed by domain complexity and how practitioners work around them. We found that despite the best efforts by usability professionals to get familiar with complex domains on their own, the lack of formal domain expertise can be a significant hurdle for carrying out effective usability evaluations. Partnerships with domain experts lead to effective results as long as domain experts are willing to be an integral part of the usability team. These findings suggest that for achieving usability in complex domains, some fundamental educational changes may be needed in the training of usability professionals. </span></div></div><div class="paper"><span class="title">Average Task Times in Usability Tests: What to Report?</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Jeff Sauro" class="author">Jeff Sauro</a> <a href="byAffiliation.html#Oracle, Measuring Usability LLC" class="affiliation">Oracle, Measuring Usability LLC</a>,<br /><a href="byAuthors.html#James Lewis" class="author">James Lewis</a> <a href="byAffiliation.html#IBM" class="affiliation">IBM</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">The distribution of task time data in usability studies is positively skewed. Practitioners who are aware of this positive skew tend to report the sample median. Monte Carlo simulations using data from 61 large-sample usability tasks showed that the sample median is a biased estimate of the population median. Using the geometric mean to estimate the center of the population will, on average, have 13% less error and 22% less bias than the sample median. Other estimates of the population center (trimmed, harmonic and Winsorized means) had worse performance than the sample median.</span></div></div><div class="paper"><span class="title">Concept Mapping in Agile Usability: A Case Study</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jeremy T. Barksdale" class="author">Jeremy T. Barksdale</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a>,<br /><a href="byAuthors.html#Scott McCrickard" class="author">Scott McCrickard</a> <a href="byAffiliation.html#Virginia Tech" class="affiliation">Virginia Tech</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we report on the experience of using our concept mapping approach on an agile software project to assess its fitness. Participants used our novel concept mapping approach over a four week period during the development of a software tool for a local nonprofit agency. Results indicate that our concept mapping approach has value as a visual tool in agile usability environments.</span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">11:30&nbsp;AM<br/><em>to</em><br/>1:00&nbsp;PM</td>
<td class="session" id="S124">
<span class="type">Papers/Notes</span>
<span class="title">Displays Where You Least Expect Them</span>
<span class="location">Centennial 1</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S128">
<span class="type">Papers/Notes</span>
<span class="title">Users and Attention on the Web</span>
<span class="location">Centennial 3</span>
</td>
<td class="session" id="S125">
<span class="type">Papers/Notes</span>
<span class="title">Domestic Life</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S18">
<span class="type">SIG</span>
<span class="title">Special Interest Group for the CHI 2010 Management Community</span>
<span class="location">Chicago ABC</span>
</td>
<td class="session" id="S126">
<span class="type">Papers/Notes</span>
<span class="title">Finding Your Mojo and Doing Some Good</span>
<span class="location">Hanover FG</span>
</td>
<td class="session" id="S123">
<span class="type">Papers/Notes</span>
<span class="title">Cooking, Classrooms, and Craft</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S127">
<span class="type">Papers/Notes</span>
<span class="title">Software Understanding and Maintenance</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S122">
<span class="type">Papers/Notes</span>
<span class="title">1001 Users</span>
<span class="location">Regency 7</span>
</td>
</tr>
<tr class="details_row">

<td colspan="8" class="session_details" id="S124_details"><div class="paper"><span class="title">LensMouse: Augmenting the Mouse with an Interactive Touch Display</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Xing Dong Yang" class="author">Xing Dong Yang</a> <a href="byAffiliation.html#University of Alberta" class="affiliation">University of Alberta</a>,<br /><a href="byAuthors.html#Edward Mak" class="author">Edward Mak</a> <a href="byAffiliation.html#University of Manitoba" class="affiliation">University of Manitoba</a>,<br /><a href="byAuthors.html#David McCallum" class="author">David McCallum</a> <a href="byAffiliation.html#University of Manitoba" class="affiliation">University of Manitoba</a>,<br /><a href="byAuthors.html#Pourang Irani" class="author">Pourang Irani</a> <a href="byAffiliation.html#University of Manitoba" class="affiliation">University of Manitoba</a>,<br /><a href="byAuthors.html#Xiang Cao" class="author">Xiang Cao</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a>,<br /><a href="byAuthors.html#Shahram Izadi" class="author">Shahram Izadi</a> <a href="byAffiliation.html#Microsoft Research Cambridge" class="affiliation">Microsoft Research Cambridge</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We introduce LensMouse, a novel device that embeds a touch-screen display - or tangible lens' - onto a mouse. Users interact with the display of the mouse using direct touch, whilst also performing regular cursor-based mouse interactions. We demonstrate some of the unique capabilities of such a device, in particular for interacting with auxiliary windows, such as toolbars, palettes, pop-ups and dialog-boxes. By migrating these windows onto LensMouse, challenges such as screen real-estate use and window management can be alleviated. In a controlled experiment, we evaluate the effectiveness of LensMouse in reducing cursor movements for interacting with auxiliary windows. We also consider the concerns involving the view separation that results from introducing such a display-based device. Our results reveal that overall users are more effective with LenseMouse than with auxiliary application windows that are managed either in single or dual-monitor setups. We conclude by presenting other application scenarios that LensMouse could support.</span></div></div><div class="paper"><span class="title">PACER: Fine-grained Interactive Paper via Camera-touch Hybrid Gestures on a Cell Phone</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Chunyuan Liao" class="author">Chunyuan Liao</a> <a href="byAffiliation.html#FXPAL" class="affiliation">FXPAL</a>,<br /><a href="byAuthors.html#Qiong Liu" class="author">Qiong Liu</a> <a href="byAffiliation.html#FXPAL" class="affiliation">FXPAL</a>,<br /><a href="byAuthors.html#Bee Liew" class="author">Bee Liew</a> <a href="byAffiliation.html#FXPAL" class="affiliation">FXPAL</a>,<br /><a href="byAuthors.html#Lynn Wilcox" class="author">Lynn Wilcox</a> <a href="byAffiliation.html#FXPAL" class="affiliation">FXPAL</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">PACER is a gesture-based interactive paper system that supports fine-grained paper document content manipulation through the touch screen of a cameraphone. Using the phone's camera, PACER links a paper document to its digital version based on visual features. It adopts camera-based phone motion detection for embodied gestures (e.g. marquees, underlines and lassos), with which users can flexibly select and interact with document details (e.g. individual words, symbols and pixels). The touch input is incorporated to facilitate target selection at fine granularity, and to address some limitations of the embodied interaction, such as hand jitter and low input sampling rate. This hybrid interaction is coupled with other techniques such as semi-real time document tracking and loose physical-digital document registration, offering a gesture-based command system. We demonstrate the use of PACER in various scenarios including work-related reading, maps and music score playing. A preliminary user study on the design has produced encouraging user feedback, and suggested future research for better understanding of embodied vs. touch interaction and one vs. two handed interaction. </span></div></div><div class="paper"><span class="title">MouseLight: Bimanual Interaction on Digital Paper using a Pen and a Spatially-Aware Mobile Projector</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Hyunyoung Song" class="author">Hyunyoung Song</a> <a href="byAffiliation.html#University of Maryland, College Park" class="affiliation">University of Maryland, College Park</a>,<br /><a href="byAuthors.html#Francois Guimbretiere" class="author">Francois Guimbretiere</a> <a href="byAffiliation.html#Cornell University" class="affiliation">Cornell University</a>,<br /><a href="byAuthors.html#Tovi Grossman" class="author">Tovi Grossman</a> <a href="byAffiliation.html#Autodesk Research" class="affiliation">Autodesk Research</a>,<br /><a href="byAuthors.html#George Fitzmaurice" class="author">George Fitzmaurice</a> <a href="byAffiliation.html#Autodesk Research" class="affiliation">Autodesk Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">MouseLight is a spatially-aware standalone mobile projector with the form factor of a mouse that can be used in combination with digital pens on paper. By interacting with the projector and the pen bimanually, users can visualize and modify the virtually augmented contents on top of the paper, and seamlessly transition between virtual and physical information. We present a high fidelity hardware prototype of the system and demonstrate a set of novel interactions specifically tailored to the unique properties of MouseLight. MouseLight differentiates itself from related systems such as PenLight in two aspects. First, MouseLight presents a rich set of bimanual interactions inspired by the ToolGlass interaction metaphor, but applied to physical paper. Secondly, our system explores novel displaced interactions, that takes advantage of the independent input and output that is spatially aware of the underneath paper. These properties enable users to issue remote commands such as copy and paste or search. We also report on a preliminary evaluation of the system, which produced encouraging observations and feedback.</span></div></div></td>

<td colspan="8" class="session_details" id="S128_details"><div class="paper"><span class="title">Enhancing Web Page Readability for Non-native Readers</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Chen-Hsiang Yu" class="author">Chen-Hsiang Yu</a> <a href="byAffiliation.html#Massachusetts Institute of Technology" class="affiliation">Massachusetts Institute of Technology</a>,<br /><a href="byAuthors.html#Robert C. Miller" class="author">Robert C. Miller</a> <a href="byAffiliation.html#Massachusetts Institute of Technology" class="affiliation">Massachusetts Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Readers face many obstacles on today's Web, including distracting content competing for the user's attention and other factors interfering with comfortable reading. On today's primarily English-language Web, non-native readers encounter even more problems, even if they have some fluency in English. In this paper, we focus on the presentation of content and propose a new transformation method, Jenga Format, to enhance web page readability. To evaluate the Jenga Format, we conducted a user study on 30 Asian users with moderate English fluency and the results indicated that the proposed transformation method improved reading comprehension without negatively affecting reading speed. We also describe Froggy, a Firefox extension which implements the Jenga format.</span></div></div><div class="paper"><span class="title">The Mystique of Numbers: Belief in Quantitative Approaches to Segmentation and Persona Development</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#David Siegel" class="author">David Siegel</a> <a href="byAffiliation.html#Dray &amp; Associates, Inc." class="affiliation">Dray &amp; Associates, Inc.</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Quantitative market research and qualitative user-centered design research have long had an uneasy and complex relationship.  A trend toward increasingly complex statistical segmentations and associated personas will once again increase the urgency of addressing paradigm differences to allow the two disciplines to collaborate effectively.    We present an instructive case in which qualitative field research helped contribute to abandoning a state of the art quantitative user segmentation that was used in an attempt to unify both marketing and user experience planning around a shared model of users.   This case exposes risks in quantitative segmentation research, common fallacies in the evolving practice of segmentation and use of personas, and the dangers of excessive deference to quantitative research generally.  </span></div></div><div class="paper"><span class="title">Automating UI Guidelines verification by leveraging pattern based UI and model based development</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Satya Viswanathan" class="author">Satya Viswanathan</a> <a href="byAffiliation.html#SAP Labs" class="affiliation">SAP Labs</a>,<br /><a href="byAuthors.html#Peters Johan Christiaan" class="author">Peters Johan Christiaan</a> <a href="byAffiliation.html#SAP Labs" class="affiliation">SAP Labs</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In large enterprises different teams work on different parts of a big software application. Therefore, retaining user interaction paradigms and concepts becomes important. However, during the development of a large software product, these principles and paradigms get  progressively diluted, due to trade-offs, differences in interpretation, communication errors and many other reasons. In order to remain true to design rationale and communicating them to a wider audience/consumers, often User Interface (UI) Style Guide are created. The style guide attempts to sensitize and educate its consumers about design principles and document some of these design rationales for references.  However, the usability, usage and adoption of these UI guidelines within an organization are topics frequently discussed and debated in several forums for years.  Post the design and definition phase of software development lifecycle, UI designers are often required to do quality checks as the UIs get developed. Despite painstakingly defining every interaction to its finest level of granularity, in practice the guidelines are often not followed or interpreted incorrectly.  The method of manually inspecting the implemented user interface for compliance to UI guidelines has the following pitfalls:  &amp;#56256;&amp;#56440; Highly effort and time consuming  &amp;#56256;&amp;#56440; Outcome is often inaccurate, unreliable and  sub-optimal in quality  &amp;#56256;&amp;#56440; Findings are too late in the process to be fixed.  &amp;#56256;&amp;#56440; Not an efficient process for tracking issues to  resolution  This case study talks about the challenges we faced with our UI Style guide and how we tackled them. Based on internal user research and design thinking we defined an approach of better integrating UI style guide into the software design and development process. We  leveraged the benefits of pattern based UI approach and a model based development environment to achieve compliance to our UI guidelines by:  1. Providing tools to automate verification of UI  guidelines in the model based development  environment  2. Redefining the development process to support UI  verification early-on during the design and  development process</span></div></div></td>

<td colspan="8" class="session_details" id="S125_details"><div class="paper"><span class="title">How Routine Learners can Support Family Coordination</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Scott Davidoff" class="author">Scott Davidoff</a> <a href="byAffiliation.html#Carnegie Mellon" class="affiliation">Carnegie Mellon</a>,<br /><a href="byAuthors.html#John Zimmerman" class="author">John Zimmerman</a> <a href="byAffiliation.html#Carnegie Mellon" class="affiliation">Carnegie Mellon</a>,<br /><a href="byAuthors.html#Anind K. Dey" class="author">Anind K. Dey</a> <a href="byAffiliation.html#Carnegie Mellon" class="affiliation">Carnegie Mellon</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Researchers have detailed the importance of routines in how people live and work, while also cautioning system designers about the importance of people's idiosyncratic behavior patterns and the challenges they would present to learning systems. We wish to take up their challenge, and offer a vision of how simple sensing technology could capture and model idiosyncratic routines, enabling applications to solve many real world problems.  To identify how a simple routine learner can demonstrate this in support of family coordination, we conducted six months of nightly interviews with six families, focusing on how they make and execute plans. Our data reveals that only about 40% of events unfold in a routine manner. When deviations do occur, family members often need but do not have access to accurate information about their routines. With about 90% of their content concerning deviations, not routines, families do not rely on calendars to support them during these moments. We discuss how coordination tools, like calendars and reminder systems, would improve coordination and reduce stress when augmented with routine information, and how commercial mobile phones can support the automatic creation of routine models.</span></div></div><div class="paper"><span class="title">The Design and Evaluation of an End-User-Deployable, Whole House, Contactless Power Consumption Sensor</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Shwetak N. Patel" class="author">Shwetak N. Patel</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Sidhant Gupta" class="author">Sidhant Gupta</a> <a href="byAffiliation.html#University of Washington" class="affiliation">University of Washington</a>,<br /><a href="byAuthors.html#Matthew S. Reynolds" class="author">Matthew S. Reynolds</a> <a href="byAffiliation.html#Duke University" class="affiliation">Duke University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present the design, development, and evaluation of an end-user installable, whole house power consumption sensing system capable of gathering accurate real-time power use that does not require installing a current transformer around the electrical feeds in a home. Rather, our sensor system offers contactless operation by simply placing it on the outside of the breaker panel in a home. Although there are a number of existing commercial systems for gathering energy use in a home, almost none can easily and safely be installed by a homeowner (especially for homes in the U.S.). Our approach leverages advances in magnetoresistive materials and circuit design to allow contactless operation by reliably sensing the magnetic field induced by the 60 Hz current and a closed loop circuit allows us to precisely infer the power consumption in real-time. The contribution of this work is an enabling technology for researchers in the fields of Ubiquitous Computing and Human-Computer Interaction wanting to conduct practical large-scale deployments of end-user-deployable energy monitoring applications. We discuss the technical details, the iterative design, and end-user evaluations of our sensing approach.</span></div></div><div class="paper"><span class="title">InPhase: Evaluation of a Communication System Focused on Happy Coincidences of Daily Behaviors</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Hitomi Tsujita" class="author">Hitomi Tsujita</a> <a href="byAffiliation.html#Ochanomizu University" class="affiliation">Ochanomizu University</a>,<br /><a href="byAuthors.html#Koji Tsukada" class="author">Koji Tsukada</a> <a href="byAffiliation.html#Ochanomizu University" class="affiliation">Ochanomizu University</a>,<br /><a href="byAuthors.html#Itiro Siio" class="author">Itiro Siio</a> <a href="byAffiliation.html#Ochanomizu University" class="affiliation">Ochanomizu University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">To supplement existing forms of communication such as telephone and e-mail, this research proposes a new method of communicating awareness between people who are separated by long distances.  In this paper, we investigate cases where coincidences in daily activities lead to casual conversation and thus intimacy and togetherness.  We propose a new method of communicating these happy coincidences between a pair of remotely located locations.  By equipping furniture and appliances such as doors, sofas, refrigerators and televisions with sensors, we developed a system wherein these items are connected to remote equivalents and their near simultaneous use is communicated.  We conducted a two month field test of the system in a laboratory setting and a three month field test in an actual home.  The study showed that the participant felt the presence of other people and thought about, imagined or even confirmed the habits of others by intentionally triggering the coincidence notification.</span></div></div></td>

<td colspan="8" class="session_details" id="S18_details"><div class="paper"><span class="title">Special Interest Group for the CHI 2010 Management Community</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Garett Dworman" class="author">Garett Dworman</a> <a href="byAffiliation.html#TecEd" class="affiliation">TecEd</a>,<br /><a href="byAuthors.html#Jim Nieters" class="author">Jim Nieters</a> <a href="byAffiliation.html#Yahoo, Inc." class="affiliation">Yahoo, Inc.</a></div></div></td>

<td colspan="8" class="session_details" id="S126_details"><div class="paper"><span class="title">O Job Can You Return My Mojo?:  Improving Human Engagement and Enjoyment in  Routine Activities</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Dvijesh Shastri" class="author">Dvijesh Shastri</a> <a href="byAffiliation.html#University Of Houston" class="affiliation">University Of Houston</a>,<br /><a href="byAuthors.html#Yuichi Fujiki" class="author">Yuichi Fujiki</a> <a href="byAffiliation.html#University Of Houston" class="affiliation">University Of Houston</a>,<br /><a href="byAuthors.html#Ross Buffington" class="author">Ross Buffington</a> <a href="byAffiliation.html#University Of Houston" class="affiliation">University Of Houston</a>,<br /><a href="byAuthors.html#Panagiotis Tsiamyrtzis" class="author">Panagiotis Tsiamyrtzis</a> <a href="byAffiliation.html#University Of Houston" class="affiliation">University Of Houston</a>,<br /><a href="byAuthors.html#Ioannis Pavlidis" class="author">Ioannis Pavlidis</a> <a href="byAffiliation.html#University Of Houston" class="affiliation">University Of Houston</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Unlike machines, we humans are prone to boredom when we perform routine activities for long periods of time. Workers' mental engagement in boring tasks diminishes, which eventually, compromises their performance. The result is a double-whammy because the workers do not get job satisfaction and their employers do not receive optimal return on investment.  This paper proposes a novel way for improving workers' mental engagement and hence, enjoyment, in routine activities. Specifically, we propose to blend in routine tasks mild mental/physical challenges. To test our hypothesis, we chose to experiment on a monitoring task typical of security guard operations. We combined this routine task with an iPhone-based game to make it more enjoyable. The results from 10 participants show that their mental engagement and enjoyment were significantly higher during the combined task.</span></div></div><div class="paper"><span class="title">Identifying Drivers and Hindrances of Social User Experience in Web Services</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Kaisa Väänänen-Vainio-Mattila" class="author">Kaisa Väänänen-Vainio-Mattila</a> <a href="byAffiliation.html#Tampere University of Technology, Nokia Research Center" class="affiliation">Tampere University of Technology, Nokia Research Center</a>,<br /><a href="byAuthors.html#Minna Wäljas" class="author">Minna Wäljas</a> <a href="byAffiliation.html#Tampere University of Technology" class="affiliation">Tampere University of Technology</a>,<br /><a href="byAuthors.html#Jarno Ojala" class="author">Jarno Ojala</a> <a href="byAffiliation.html#Tampere University of Technology" class="affiliation">Tampere University of Technology</a>,<br /><a href="byAuthors.html#Katarina Segerståhl" class="author">Katarina Segerståhl</a> <a href="byAffiliation.html#University of Oulu" class="affiliation">University of Oulu</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Social activity is becoming a central contributor to user experience (UX) in many modern Web services. The motivations, norms and rules of online communities have been widely researched, however, social activity and its UX in modern Web services is a less studied area. We conducted a four-week-long field study with three Web services - Facebook, Nokia Sports Tracker and Dopplr - which all support social activity. The aim of this study was to identify the central drivers and hindrances of social UX, user experience of online social activity. Our results show that the main drivers of social UX include self-expression, reciprocity, learning and curiosity, whereas unsuitability of content and functionality, incompleteness of user networks and lack of trust and privacy are often experienced as hindrances for social UX. Our findings also reveal the pragmatic and hedonic nature of the drivers and hindrances. The results can be used to inform design and evaluation of social UX in Web services. </span></div></div><div class="paper"><span class="title">A Novel Way to Conduct Human Studies and Do Some Good</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Pradeep Buddharaju" class="author">Pradeep Buddharaju</a> <a href="byAffiliation.html#Dept. of Computer Science, University of Houston" class="affiliation">Dept. of Computer Science, University of Houston</a>,<br /><a href="byAuthors.html#Yuichi Fujiki" class="author">Yuichi Fujiki</a> <a href="byAffiliation.html#Dept. of Computer Science, University of Houston" class="affiliation">Dept. of Computer Science, University of Houston</a>,<br /><a href="byAuthors.html#Ioannis Pavlidis" class="author">Ioannis Pavlidis</a> <a href="byAffiliation.html#Dept. of Computer Science, University of Houston" class="affiliation">Dept. of Computer Science, University of Houston</a>,<br /><a href="byAuthors.html#Ergun Akleman" class="author">Ergun Akleman</a> <a href="byAffiliation.html#Visualization Sciences Program, Texas A&amp;M University  " class="affiliation">Visualization Sciences Program, Texas A&amp;M University  </a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper the authors describe a novel way to conduct large-scale human studies achieving the maximum outreach and impact with the minimum cost. An iPhone health application, `Walk n Play, was developed and released for free in the App Store. The application measures calories spent due to walking activities through the iPhones accelerometer. It is a real-time awareness tool that helps people to keep their sedentariness in check. Furthermore, it uses motivational mechanisms based on buddy support/competition and social networking to increase daily physical activity. The anonymous data gathered from thousands of users around the world, reveal patterns of human behavior at a resolution and scale not feasible before. </span></div></div><div class="paper"><span class="title">More than a Feeling: Understanding the Desirability Factor in User Experience</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Carol M. Barnum" class="author">Carol M. Barnum</a> <a href="byAffiliation.html#Southern Polytechnic State University" class="affiliation">Southern Polytechnic State University</a>,<br /><a href="byAuthors.html#Laura A. Palmer" class="author">Laura A. Palmer</a> <a href="byAffiliation.html#Southern Polytechnic State University" class="affiliation">Southern Polytechnic State University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Interest in understanding the desirability factor in user experience continues to grow while the use of post-test questionnaires to measure desirability continues to be problematic. Microsoft created a toolkit to address desirability in studies, and their use of the product reaction cards from that kit was presented at conferences in 2002 and 2004. Since then, however, little has been published about how others have used the cards to measure desirability. We began using the product reaction cards in 2006, and we report on the results in case studies from the past several years. We find that the cards prompt users to tell a rich and revealing story of their experience. Triangulating these findings with post-test questionnaire data and direct observation strengthens the understanding of the desirability factor.</span></div></div></td>

<td colspan="8" class="session_details" id="S123_details"><div class="paper"><span class="title">Spyn: Augmenting the Creative and Communicative Potential of Craft</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Daniela Rosner" class="author">Daniela Rosner</a> <a href="byAffiliation.html#School of Information" class="affiliation">School of Information</a>,<br /><a href="byAuthors.html#Kimiko Ryokai" class="author">Kimiko Ryokai</a> <a href="byAffiliation.html#School of Information" class="affiliation">School of Information</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present data collected from a field study of 12 needle-crafters introduced to Spynmobile phone software that associates digital records (audio/visual media, text, and geographic data) with locations on fabric. We observed leisure needle-crafters use Spyn to create one or more handmade garments over two to four weeks and then give those garments to friends, partners, and family members. Using Spyn, creators left behind digital and physical traces that heightened recipients' appreciation for the gift and enabled a diverse set of meanings to emerge. Digital engagements with Spyn became a means for unraveling the value of the gift: recipients used digital information associated with the physical objects to interpret the story behind the objects and their creators. We discuss the nature of this relationship between digital and physical material and its implications for craft.</span></div></div><div class="paper"><span class="title">Toque: Designing a Cooking-Based Programming Language For and With Children</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sureyya Tarkan" class="author">Sureyya Tarkan</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Vibha Sazawal" class="author">Vibha Sazawal</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Allison Druin" class="author">Allison Druin</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Evan Golub" class="author">Evan Golub</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Elizabeth M. Bonsignore" class="author">Elizabeth M. Bonsignore</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Greg Walsh" class="author">Greg Walsh</a> <a href="byAffiliation.html#University of Maryland" class="affiliation">University of Maryland</a>,<br /><a href="byAuthors.html#Zeina Atrash" class="author">Zeina Atrash</a> <a href="byAffiliation.html#Northwestern University" class="affiliation">Northwestern University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">An intergenerational design team of children (ages 7-11 years old) along with graduate students and faculty in computer science and information studies developed a programming language for children, Toque. Concrete real-world cooking scenarios were used as programming metaphors to support an accessible programming learning experience. The Wiimote and Nunchuk were used as physical programming input devices. The programs that were created were pictorial recipes which dynamically controlled animations of an on-screen chef preparing virtual dishes in a graphical kitchen environment. Through multiple design sessions, programming strategies were explored, cooking metaphors were developed and, prototypes of the Toque environment were iterated. Results of these design experiences have shown us the importance of pair-programming, programming by storytelling, parallel programming, function-argument relationships, and the role of tangibility in overcoming challenges with constraints imposed by the system design.</span></div></div><div class="paper"><span class="title">Cooking with Robots: Designing a Household System Working in Open Environments</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Yuta Sugiura" class="author">Yuta Sugiura</a> <a href="byAffiliation.html#Graduate School of Media Design, Keio University / JST ERATO IGARASHI Design UI Project" class="affiliation">Graduate School of Media Design, Keio University / JST ERATO IGARASHI Design UI Project</a>,<br /><a href="byAuthors.html#Daisuke Sakamoto" class="author">Daisuke Sakamoto</a> <a href="byAffiliation.html#The University of Tokyo / JST ERATO IGARASHI Design UI Project" class="affiliation">The University of Tokyo / JST ERATO IGARASHI Design UI Project</a>,<br /><a href="byAuthors.html#Anusha Withana" class="author">Anusha Withana</a> <a href="byAffiliation.html#Graduate School of Media Design, Keio University / JST ERATO IGARASHI Design UI Project" class="affiliation">Graduate School of Media Design, Keio University / JST ERATO IGARASHI Design UI Project</a>,<br /><a href="byAuthors.html#Masahiko Inami" class="author">Masahiko Inami</a> <a href="byAffiliation.html#Graduate School of Media Design, Keio University / JST ERATO IGARASHI Design UI Project" class="affiliation">Graduate School of Media Design, Keio University / JST ERATO IGARASHI Design UI Project</a>,<br /><a href="byAuthors.html#Takeo Igarashi" class="author">Takeo Igarashi</a> <a href="byAffiliation.html#The University of Tokyo / JST ERATO IGARASHI Design UI Project" class="affiliation">The University of Tokyo / JST ERATO IGARASHI Design UI Project</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We propose a cooking system that operates in an open environment. The system cooks a meal by pouring various ingredients into a boiling pot on an induction heating cooker and adjusts the heating strength according to the user's instructions. We then describe how the system incorporates robotic and human elements interoperating in a shared workspace so as to achieve a rudimentary cooking capability. First, we use small mobile robots instead of built-in arms to save space, improve flexibility and increase safety. Second, we use detachable visual markers to allow the user to easily configure the real-world environment. Third, we provide a graphical user interface to display detailed cooking instructions to the user. We hope insights obtained in this experiment will be useful for the design of other household systems in the future.</span></div></div><div class="paper"><span class="title">Designing a Pen-based Flashcard Application to Support Classroom Learning Environment</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#YoungJoo Jeong" class="author">YoungJoo Jeong</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Ananda Gunawardena" class="author">Ananda Gunawardena</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Kenneth R. Koedinger" class="author">Kenneth R. Koedinger</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Pen-based Flash Cards Application (application) offers the flexibility of handwritten input while benefiting a wide set of users to increase their memory retention. It is particularly useful in learning mathematics where typing the material using a keyboard can be difficult. In this study, we describe the observations and major findings in a two-year case study in an eighth-grade geometry class. We found that this application may enhance teacher-student interaction, increase autonomy in students for self-guided learning, and encourage collaborative learning. </span></div></div></td>

<td colspan="8" class="session_details" id="S127_details"><div class="paper"><span class="title">Code Bubbles: A Working Set-based Interface for Code Understanding and Maintenance</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Andrew Bragdon" class="author">Andrew Bragdon</a> <a href="byAffiliation.html#Brown University" class="affiliation">Brown University</a>,<br /><a href="byAuthors.html#Robert Zeleznik" class="author">Robert Zeleznik</a> <a href="byAffiliation.html#Brown University" class="affiliation">Brown University</a>,<br /><a href="byAuthors.html#Suman Karumuri" class="author">Suman Karumuri</a> <a href="byAffiliation.html#Brown University" class="affiliation">Brown University</a>,<br /><a href="byAuthors.html#Steven P. Reiss" class="author">Steven P. Reiss</a> <a href="byAffiliation.html#Brown University" class="affiliation">Brown University</a>,<br /><a href="byAuthors.html#Joshua Kaplan" class="author">Joshua Kaplan</a> <a href="byAffiliation.html#Brown University" class="affiliation">Brown University</a>,<br /><a href="byAuthors.html#William Cheung" class="author">William Cheung</a> <a href="byAffiliation.html#Brown University" class="affiliation">Brown University</a>,<br /><a href="byAuthors.html#Christopher Coleman" class="author">Christopher Coleman</a> <a href="byAffiliation.html#Brown University" class="affiliation">Brown University</a>,<br /><a href="byAuthors.html#Ferdi Adeputra" class="author">Ferdi Adeputra</a> <a href="byAffiliation.html#Brown University" class="affiliation">Brown University</a>,<br /><a href="byAuthors.html#Joseph J. LaViola Jr." class="author">Joseph J. LaViola Jr.</a> <a href="byAffiliation.html#University of Central Florida" class="affiliation">University of Central Florida</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Developers spend significant time reading and navigating code fragments spread across multiple locations. The file-based nature of contemporary IDEs makes it prohibitively difficult to create and maintain a simultaneous view of such fragments. We propose a novel user interface metaphor for code understanding based on collections of lightweight, editable fragments called bubbles, which form concurrently visible working sets. We present the results of a qualitative usability evaluation, and the results of a quantitative study which indicates Code Bubbles significantly improved code understanding time, while reducing navigation interactions over a widely-used IDE, for two controlled tasks.</span></div></div><div class="paper"><span class="title">How to Support Designers in Getting Hold of the Immaterial Material of Software</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Fatih Kursat Ozenc" class="author">Fatih Kursat Ozenc</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Miso Kim" class="author">Miso Kim</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#John Zimmerman" class="author">John Zimmerman</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Stephen Oney" class="author">Stephen Oney</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Brad Myers" class="author">Brad Myers</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">When designing novel interactive controls for software interfaces, interaction designers are challenged by the immaterial' materiality of the digital domain and lack of tools to support conceiving, refining, and communicating these controls. In order to address these two issues and investigate the creative processes of designing interactive controls, we conducted two participatory design workshops. In the first workshop, which focused on conceiving, we identified that participants designed controls by exploring gestures, context, and examples. In the second workshop, on refining and communicating, participants proposed tools capturing gestures, deriving and manipulating properties from examples, and generating scenarios and code illustrating contexts. We discovered the underlying need to create more effective boundary objects. Participants while reflecting in and on action redefined such boundary objects as dynamic processes rather than static representations; the processes were an ongoing conversation between the designer and the material in which developer acts as a media-tor between designer and the software material.  </span></div></div><div class="paper"><span class="title">Fit and Finish Using a Bug Tracking System  Challenges and Recommendations</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Yossi Avnon" class="author">Yossi Avnon</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a>,<br /><a href="byAuthors.html#Scott L. Boggan" class="author">Scott L. Boggan</a> <a href="byAffiliation.html#Microsoft" class="affiliation">Microsoft</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This article shares practical lessons for using a bug management tool to manage user interface fit and finish process for a software product. It describes common challenges and provides recommendations for processes that will lead to enhanced product quality.</span></div></div></td>

<td colspan="8" class="session_details" id="S122_details"><div class="paper"><span class="title">Think-Aloud Protocols: A Comparison of Three Think Aloud Protocols for use in Testing Data Dissemination Web Sites for Usability</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Erica L. Olmsted-Hawala" class="author">Erica L. Olmsted-Hawala</a> <a href="byAffiliation.html#U.S. Census Bureau" class="affiliation">U.S. Census Bureau</a>,<br /><a href="byAuthors.html#Elizabeth D. Murphy" class="author">Elizabeth D. Murphy</a> <a href="byAffiliation.html#U.S. Census Bureau" class="affiliation">U.S. Census Bureau</a>,<br /><a href="byAuthors.html#Sam Hawala" class="author">Sam Hawala</a> <a href="byAffiliation.html#U.S. Census Bureau" class="affiliation">U.S. Census Bureau</a>,<br /><a href="byAuthors.html#Kathleen T. Ashenfelter" class="author">Kathleen T. Ashenfelter</a> <a href="byAffiliation.html#U.S. Census Bureau" class="affiliation">U.S. Census Bureau</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We describe an empirical, between-subjects study on the use of think-aloud protocols in usability testing of a federal data-dissemination Web site.  This double-blind study used three different types of think-aloud protocols: a traditional protocol, a speech-communication protocol, and a coaching protocol. A silent condition served as the control. Eighty participants were recruited and randomly pre-assigned to one of four conditions. Accuracy and efficiency measures were collected, and participants rated their subjective satisfaction with the site. Results show that accuracy is significantly higher in the coaching condition than in the other conditions. The traditional protocol and the speech-communication protocol are not statistically different from each other with regard to accuracy. Participants in the coaching condition are more satisfied with the Web site than participants in the traditional or speech-communication condition. In addition, there are no significant differences with respect to efficiency (time-on-task). This paper concludes with recommendations for usability practitioners. </span></div></div><div class="paper"><span class="title">Powerful and consistent analysis of Likert-type rating scales</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Maurits Kaptein" class="author">Maurits Kaptein</a> <a href="byAffiliation.html#Eindhoven University of Technology" class="affiliation">Eindhoven University of Technology</a>,<br /><a href="byAuthors.html#Clifford Nass" class="author">Clifford Nass</a> <a href="byAffiliation.html#Stanford University" class="affiliation">Stanford University</a>,<br /><a href="byAuthors.html#Panos Markopoulos" class="author">Panos Markopoulos</a> <a href="byAffiliation.html#Eindhoven University of Technology" class="affiliation">Eindhoven University of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Likert-type scales are used extensively during usability evaluations,  and more generally evaluations of interactive experiences,  to obtain quantified data regarding attitudes, behaviors,  and judgments of participants. Very often this data is  analyzed using parametric statistics like the Student t-test or  ANOVAs. These methods are chosen to ensure higher statistical  power of the test (which is necessary in this field of  research and practice where sample sizes are often small),  or because of the lack of software to handle multi-factorial  designs nonparametrically. With this paper we present to  the HCI audience new developments from the field of medical  statistics that enable analyzing multiple factor designs  nonparametrically. We demonstrate the necessity of this approach  by showing the errors in the parametric treatment of  nonparametric data in experiments of the size typically reported  in HCI research. We also provide a practical resource  for researchers and practitioners who wish to use these new  methods.</span></div></div><div class="paper"><span class="title">Measuring the User Experience on a Large Scale: User-Centered Metrics for Web Applications</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Kerry Rodden" class="author">Kerry Rodden</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a>,<br /><a href="byAuthors.html#Hilary Hutchinson" class="author">Hilary Hutchinson</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a>,<br /><a href="byAuthors.html#Xin Fu" class="author">Xin Fu</a> <a href="byAffiliation.html#Google" class="affiliation">Google</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">More and more products and services are being deployed on the web, and this presents new challenges and opportunities for measurement of user experience on a large scale.  There is a strong need for user-centered metrics for web applications, which can be used to measure progress towards key goals, and drive product decisions.  In this note, we describe the HEART framework for user-centered metrics, as well as a process for mapping product goals to metrics. We include practical examples of how HEART metrics have helped product teams make decisions that are both data-driven and user-centered.  The framework and process have generalized to enough of our company's own products that we are confident that teams in other organizations will be able to reuse or adapt them. We also hope to encourage more research into metrics based on large-scale behavioral data.</span></div></div><div class="paper"><span class="title">Are your participants gaming the system? Screening Mechanical Turk Workers</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Julie S. Downs" class="author">Julie S. Downs</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Mandy B. Holbrook" class="author">Mandy B. Holbrook</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Steve Sheng" class="author">Steve Sheng</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a>,<br /><a href="byAuthors.html#Lorrie Faith Cranor" class="author">Lorrie Faith Cranor</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we discuss a screening process used in conjunction with a survey administered via Amazon.com's Mechanical Turk. We sought an easily implementable method to disqualify those people who participate but don't take the study tasks seriously. By using two previously pilot tested screening questions, we identified 764 of 1,962 people who did not answer conscientiously. Young men seem to be most likely to fail the qualification task. Those that are professionals, students, and non-workers seem to be more likely to take the task seriously than financial workers, hourly workers, and other workers. Men over 30 and women were more likely to answer seriously.</span></div></div><div class="paper"><span class="title">Trained to Accept? A Field Experiment on Consent Dialogs</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Rainer Boehme" class="author">Rainer Boehme</a> <a href="byAffiliation.html#International Computer Science Institute Berkeley" class="affiliation">International Computer Science Institute Berkeley</a>,<br /><a href="byAuthors.html#Stefan Koepsell" class="author">Stefan Koepsell</a> <a href="byAffiliation.html#Technische Universitaet Dresden" class="affiliation">Technische Universitaet Dresden</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">A typical consent dialog was shown in 2 x 2 x 3 experimental variations to 80,000 users of an online privacy tool. We find that polite requests and button texts pointing to a voluntary decision decrease the probability of consent---in contrast to findings in social psychology. Our data suggests that subtle positive effects of polite requests indeed exist, but stronger negative effects of heuristic processing dominate the aggregated results. Participants seem to be habituated to coercive interception dialogs---presumably due to ubiquitous EULAs---and blindly accept terms the more their presentation resembles a EULA. Response latency and consultation of online help were taken as indicators to distinguish more systematic from heuristic responses. </span></div></div></td>

</tr>
<tr class="timeslot">
<td class="time">2:30&nbsp;PM<br/><em>to</em><br/>4:00&nbsp;PM</td>
<td class="session" id="S32">
<span class="type">ToCHI</span>
<span class="title">Data Mining for Understanding User Needs</span>
<span class="location"></span>
</td>
<td class="session" id="S130">
<span class="type">Papers/Notes</span>
<span class="title">Graphs</span>
<span class="location">Centennial 4</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." />
<br />
</td>
<td class="session" id="S132">
<span class="type">Papers/Notes</span>
<span class="title">No Touch</span>
<span class="location">Regency 5</span>
</td>
<td class="session" id="S131">
<span class="type">Papers/Notes</span>
<span class="title">HCI and the Developing World</span>
<span class="location">Regency 6</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." />
<br />
</td>
<td class="session" id="S129">
<span class="type">Papers/Notes</span>
<span class="title">Going to the Mall: Shopping and Product Design</span>
<span class="location">Regency 7</span>
</td>
</tr>
<tr class="details_row">

<td colspan="5" class="session_details" id="S32_details"><div class="paper"><span class="title">Potential for Personalization</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jaime Teevan" class="author">Jaime Teevan</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Susan T. Dumais" class="author">Susan T. Dumais</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a>,<br /><a href="byAuthors.html#Eric Horvitz" class="author">Eric Horvitz</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Current Web search tools do a good job of retrieving documents that satisfy the most common intentions associated with a query, but do not do a very good job of discerning different individuals unique search goals. We explore the variation in what different people consider relevant to the same query by mining three data sources: 1) explicit relevance judgments, 2) clicks on search results (a behavior-based implicit measure of relevance), and 3) the similarity of desktop content to search results (a content-based implicit measure of relevance). We find that peoples explicit judgments for the same queries differ greatly. As a result, there is a large gap between how well search engines could perform if they were to tailor results to the individual, and how well they currently perform by returning results designed to satisfy everyone. We call this gap the potential for personalization. The two implicit indicators we studied provide complementary value for approximating this variation in result relevance among people. We discuss several uses of our findings, including a personalized search system that takes advantage of the implicit measures by ranking personally relevant results more highly and improving click-through rates.</span></div></div><div class="paper"><span class="title">Brief encounters: sensing, modelling and visualizing urban mobility and copresence networks</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Vassilis Kostakos" class="author">Vassilis Kostakos</a> <a href="byAffiliation.html#University of Madeira" class="affiliation">University of Madeira</a>,<br /><a href="byAuthors.html#Eamonn O'Neill" class="author">Eamonn O'Neill</a> <a href="byAffiliation.html#University of Bath" class="affiliation">University of Bath</a>,<br /><a href="byAuthors.html#Alan Penn" class="author">Alan Penn</a> <a href="byAffiliation.html#University College London" class="affiliation">University College London</a>,<br /><a href="byAuthors.html#Dikaios Papadogkonas" class="author">Dikaios Papadogkonas</a> <a href="byAffiliation.html#Birkbeck College" class="affiliation">Birkbeck College</a>,<br /><a href="byAuthors.html#George Roussos" class="author">George Roussos</a> <a href="byAffiliation.html#Birkbeck College" class="affiliation">Birkbeck College</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Moving human-computer interaction off the desktop and into our cities requires new approaches to understanding people and technologies in the built environment. We approach the city as a system, with human, physical and digital components and behaviours. In creating effective and usable urban pervasive computing systems, we need to take into account the patterns of movement and encounter amongst people, locations, and mobile and fixed devices in the city. Advances in mobile and wireless communications have enabled us to detect and record the presence and movement of devices through cities. This paper makes a number of methodological and empirical contributions. We present a toolkit of algorithms and visualisation techniques that we have developed to model and make sense of spatial and temporal patterns of mobility, presence and encounter. Applying this toolkit, we provide an analysis of urban Bluetooth data based on a longitudinal dataset containing millions of records associated with more than 70000 unique devices in the city of Bath, UK. Through a novel application of established complex network analysis techniques, we demonstrate a significant finding on the relationship between temporal factors and network structure. Finally, we suggest how our understanding and exploitation of these data may begin to inform the design and use of urban pervasive systems.</span></div></div><div class="paper"><span class="title">Creating a Lightweight UIDL: An Overview and Analysis of the Personal Universal Controller Project</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jeffrey Nichols" class="author">Jeffrey Nichols</a> <a href="byAffiliation.html#IBM Research" class="affiliation">IBM Research</a>,<br /><a href="byAuthors.html#Brad A. Myers" class="author">Brad A. Myers</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Over six years, we iterated on the design of a language for describing the functionality of appliances, such as televisions, telephones, VCRs, and copiers. This language has been used to describe more than thirty diverse appliances, and those descriptions have been used to automatically generate both graphical and speech user interfaces on handheld computers, mobile phones, and desktop computers. In this paper, we describe the final design of our language and analyze the key design choices that led to this design. Through this analysis, we  hope to provide a useful guide for the designers of future user interface description languages.</span></div></div></td>

<td colspan="5" class="session_details" id="S130_details"><div class="paper"><span class="title">A Model of Symbol Size Discrimination in Scatterplots</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jing Li" class="author">Jing Li</a> <a href="byAffiliation.html#Eindhoven University of Techonology" class="affiliation">Eindhoven University of Techonology</a>,<br /><a href="byAuthors.html#Jean-Bernard Martens" class="author">Jean-Bernard Martens</a> <a href="byAffiliation.html#Eindhoven University of Techonology" class="affiliation">Eindhoven University of Techonology</a>,<br /><a href="byAuthors.html#Jarke J. Van Wijk" class="author">Jarke J. Van Wijk</a> <a href="byAffiliation.html#Eindhoven University of Techonology" class="affiliation">Eindhoven University of Techonology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Symbols are used in scatterplots to encode data in a way that is appropriate for perception through human visual channels. Symbol size is believed to be the second dominant channel after color. We study symbol size perception in scatterplots in the context of analytic tasks requiring size discrimination. More specifically, we performed an experiment to measure human performance in three visual analytic tasks. Circles are used as the representative symbol, with eight, linearly varying radii; 24 persons, divided across three groups, participated; and both objective and subjective measures were obtained. We propose a model to describe the results. The perception of size is assumed to be an early step in the complex cognitive process to mediate discrimination, and psychophysical laws are used to describe this perceptual mapping. Different mapping schemes are compared by regression on the experimental data. The results show that approximate homogeneity of size perception exists in our complex tasks and can be closely described by a power law transformation with an exponent of 0.4. This yields an optimal scale for symbol size discrimination.</span></div></div><div class="paper"><span class="title">Individual Models of Colour Differentiation to Improve Interpretability of Information Visualization</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#David R. Flatla" class="author">David R. Flatla</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a>,<br /><a href="byAuthors.html#Carl Gutwin" class="author">Carl Gutwin</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Color is commonly used to represent categories and values in many computer applications, but differentiating these colors can be difficult in many situations (e.g., for users with color vision deficiency (CVD), or in bright light). Current solutions to this problem can adapt colors based on standard simulations of CVD, but these models cover only a fraction of the ways in which color perception can vary. To improve the specificity and accuracy of these approaches, we have developed the first ever individualized model of color differentiation (ICD). The model is based on a short calibration performed by a particular user for a particular display, and so automatically covers all aspects of the user's ability to see and differentiate colors in an environment. In this paper we introduce the new model and the manner in which differentiability limits are predicted. We gathered empirical data from 16 users to assess the model's accuracy and robustness. We found that the model is highly effective at capturing individual differentiation abilities, works for users with and without CVD, can be tuned to balance accuracy and color availability, and can serve as the basis for improved color adaptation schemes.</span></div></div><div class="paper"><span class="title">Useful Junk? The Effects of Visual Embellishment on Comprehension and Memorability of Charts</span> - <span class="type">Paper</span>
<img class="bpWinner" src="best_paper_winner.png" title="Session has a best paper winner." /><span style="display: none">Best paper winner best paper winner</span><div class="authors"><a href="byAuthors.html#Scott Bateman" class="author">Scott Bateman</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a>,<br /><a href="byAuthors.html#Regan L. Mandryk" class="author">Regan L. Mandryk</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a>,<br /><a href="byAuthors.html#Carl Gutwin" class="author">Carl Gutwin</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a>,<br /><a href="byAuthors.html#Aaron Genest" class="author">Aaron Genest</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a>,<br /><a href="byAuthors.html#David McDine" class="author">David McDine</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a>,<br /><a href="byAuthors.html#Christopher Brooks" class="author">Christopher Brooks</a> <a href="byAffiliation.html#University of Saskatchewan" class="affiliation">University of Saskatchewan</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">Guidelines for designing information charts (such as bar charts) often state that the presentation should reduce or remove chart junk' - visual embellishments that are not essential to understanding the data. In contrast, some popular chart designers wrap the presented data in detailed and elaborate imagery, raising the questions of whether this imagery is really as detrimental to understanding as has been proposed, and whether the visual embellishment may have other benefits. To investigate these issues, we conducted an experiment that compared embellished charts with plain ones, and measured both interpretation accuracy and long-term recall. We found that people's accuracy in describing the embellished charts was no worse than for plain charts, and that their recall after a two-to-three-week gap was significantly better. Although we are cautious about recommending that all charts be produced in this style, our results question some of the premises of the minimalist approach to chart design.</span></div></div></td>

<td colspan="5" class="session_details" id="S132_details"><div class="paper"><span class="title">Interactivity and Non-Interactivity on Tabletops</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Kenton O'Hara" class="author">Kenton O'Hara</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In the growing field of tabletop computing research, there has been an understandable focus on interactive aspects of tabletop use, in terms of technology, design, and behavioural analysis. In this paper, I highlight the importance of considering also non-interactive aspects of tabletop computing and the mutually dependent relationship between interactive and non-interactive. We illustrate aspects of this relationship using findings from a deployment of an interactive tabletop in a public setting. The findings highlight how consequences of interaction can impact on non-interactive behaviours and intentions and how non-interactive actions can constrain interactive behaviours on the tabletop. In doing this we aim to raise more awareness of the relationship between interactivity and non-interactivity within tabletop computing research.</span></div></div><div class="paper"><span class="title">Clutch-Free Panning and Integrated Pan-Zoom Control on Sensitive Surfaces: The CycloStar Approach</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sylvain Malacria" class="author">Sylvain Malacria</a> <a href="byAffiliation.html#Télécom ParisTech" class="affiliation">Télécom ParisTech</a>,<br /><a href="byAuthors.html#Eric Lecolinet" class="author">Eric Lecolinet</a> <a href="byAffiliation.html#Télécom ParisTech" class="affiliation">Télécom ParisTech</a>,<br /><a href="byAuthors.html#Yves Guiard" class="author">Yves Guiard</a> <a href="byAffiliation.html#Télécom ParisTech" class="affiliation">Télécom ParisTech</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This paper introduces two novel navigation techniques, CycloPan, for clutch-free 2D panning and browsing, and CycloZoom+, for integrated 2D panning and zooming. These techniques instantiate a more generic concept which we call Cyclo* (CycloStar). The basic idea is that users can exert closed-loop control over several continuous variables by voluntarily modulating the parameters of a sustained oscillation. Touch-sensitive surfaces tend to offer impoverished input resources. Cyclo* techniques seem particularly promising on these surfaces because oscillations have multiple geometrical and kinematic parameters many of which may be used as controls. While CycloPan and CycloZoom+ are compatible with each other and with much of the state of the art, our experimental evaluations suggest that these two novel techniques outperform flicking and rubbing techniques. </span></div></div><div class="paper"><span class="title">Touching the Void: Direct-Touch Interaction for Intangible Displays</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Li-Wei Chan" class="author">Li-Wei Chan</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a>,<br /><a href="byAuthors.html#Hui-Shan Kao" class="author">Hui-Shan Kao</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a>,<br /><a href="byAuthors.html#Yen-Yang Chen" class="author">Yen-Yang Chen</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a>,<br /><a href="byAuthors.html#Ming-Sui Lee" class="author">Ming-Sui Lee</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a>,<br /><a href="byAuthors.html#Jane Yung-jen Hsu" class="author">Jane Yung-jen Hsu</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a>,<br /><a href="byAuthors.html#Yi-Ping Hung" class="author">Yi-Ping Hung</a> <a href="byAffiliation.html#National Taiwan University" class="affiliation">National Taiwan University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper, we explore the challenges in applying and investigate methodologies to improve direct-touch interaction on intangible displays. Direct-touch interaction simplifies object manipulation, because it combines the input and display into a single integrated interface. While traditional tangible display-based direct-touch technology is commonplace, similar direct-touch interaction within an intangible display paradigm presents many challenges. Given the lack of tactile feedback, direct-touch interaction on an intangible display may show poor performance even on the simplest of target acquisition tasks. In order to study this problem, we have created a prototype of an intangible display. In the initial study, we collected user discrepancy data corresponding to the interpretation of 3D location of targets shown on our intangible display. The result showed that participants performed poorly in determining the z-coordinate of the targets and were imprecise in their execution of screen touches within the system. Thirty percent of positioning operations showed errors larger than 30mm from the actual surface. This finding triggered our interest to design a second study, in which we quantified task time in the presence of visual and audio feedback. The pseudo-shadow visual feedback was shown to be helpful both in improving user performance and satisfaction.</span></div></div></td>

<td colspan="5" class="session_details" id="S131_details"><div class="paper"><span class="title">Intermediated Technology Use in Developing Communities</span> - <span class="type">Paper</span>
<img class="bpNominee" src="best_paper_nominee.png" title="Session has a best paper nominee." /><span style="display: none">Best paper nominee</span><div class="authors"><a href="byAuthors.html#Nithya Sambasivan" class="author">Nithya Sambasivan</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Ed Cutrell" class="author">Ed Cutrell</a> <a href="byAffiliation.html#Microsoft Research India" class="affiliation">Microsoft Research India</a>,<br /><a href="byAuthors.html#Kentaro Toyama" class="author">Kentaro Toyama</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a>,<br /><a href="byAuthors.html#Bonnie Nardi" class="author">Bonnie Nardi</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We describe a prevalent mode of information access in low-income communities of the developing worldintermediated interactions. They enable persons for whom technology is inaccessible due to non-literacy, lack of technology-operation skills, or financial constraints, to benefit from technologies through digitally skilled usersthus, expanding the reach of technologies. Reporting the results of our ethnography in two urban slums of Bangalore, India, we present three distinct intermediated interactions: inputting intent into the device in proximate enabling, interpretation of device output in proximate translation, and both input of intent and interpretation of output in surrogate usage. We present some requirements and challenges in interface design of these interactions and explain how they are different from direct interactions. We then explain the broader effects of these interactions on low-income communities, and present some implications for design.</span></div></div><div class="paper"><span class="title">Deliberate Interactions: Characterizing Technology Use in Nairobi, Kenya</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Susan P. Wyche" class="author">Susan P. Wyche</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Thomas N. Smyth" class="author">Thomas N. Smyth</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Marshini Chetty" class="author">Marshini Chetty</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a>,<br /><a href="byAuthors.html#Paul M. Aoki" class="author">Paul M. Aoki</a> <a href="byAffiliation.html#Intel Labs Berkeley" class="affiliation">Intel Labs Berkeley</a>,<br /><a href="byAuthors.html#Rebecca E. Grinter" class="author">Rebecca E. Grinter</a> <a href="byAffiliation.html#Georgia Institute of Technology" class="affiliation">Georgia Institute of Technology</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We present results from a qualitative study examining how professionals living and working in Nairobi, Kenya regularly use ICT in their everyday lives.  There are two contributions of this work for the HCI community. First, we provide empirical evidence demonstrating constraints our participants encountered when using technology in an infrastructure-poor setting. These constraints are limited bandwidth, high costs, differing perceptions of responsiveness, and threats to physical and virtual security.   Second, we use our findings to critically evaluate the access, anytime and anywhere construct shaping the design of future technologies.  We present an alternative vision called deliberate interactionsa planned and purposeful interaction style that involves offline preparationand discuss ways ICT can support this online usage behavior.</span></div></div><div class="paper"><span class="title">After Access - Challenges Facing Mobile-Only Internet Users in the Developing World</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Shikoh Gitau" class="author">Shikoh Gitau</a> <a href="byAffiliation.html#University of Cape Town" class="affiliation">University of Cape Town</a>,<br /><a href="byAuthors.html#Gary Marsden" class="author">Gary Marsden</a> <a href="byAffiliation.html#university of Cape Town" class="affiliation">university of Cape Town</a>,<br /><a href="byAuthors.html#Jonathan Donner" class="author">Jonathan Donner</a> <a href="byAffiliation.html#Microsoft Research" class="affiliation">Microsoft Research</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">This study reports results of an ethnographic action research study, exploring mobile-centric internet use. Over the course of 13 weeks, eight women, each a member of a livelihoods collective in urban Cape Town, South Africa, received training to make use of the data (internet) features on the phones they already owned. None of the women had previous exposure to PCs or the internet. Activities focused on social networking, entertainment, information search, and, in particular, job searches. Results of the exercise reveal both the promise of, and barriers to, mobile internet use by a potentially large community of first-time, mobile-centric users. Discussion focuses on the importance of self-expression and identity management in the refinement of online and offline presences, and considers these forces relative to issues of gender and socioeconomic status.</span></div></div><div class="paper"><span class="title">ViralVCD: Tracing Information-Diffusion Paths with Low Cost Media in Developing Communities</span> - <span class="type">Note</span><div class="authors"><a href="byAuthors.html#Nithya Sambasivan" class="author">Nithya Sambasivan</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#Ed Cutrell" class="author">Ed Cutrell</a> <a href="byAffiliation.html#Microsoft Research India" class="affiliation">Microsoft Research India</a>,<br /><a href="byAuthors.html#Kentaro Toyama" class="author">Kentaro Toyama</a> <a href="byAffiliation.html#University of California, Berkeley" class="affiliation">University of California, Berkeley</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We describe ViralVCD: a low cost method for tracing paths of information diffusion in developing communities using physical media. We instituted a participatory video framework for creation and dissemination of developmental videos in seven urban slums and peri-urban communities of Bangalore, India. By combining a call-in contest with Video CDs, we were able to measure developmental impact as well as elicit data on social networks and technology usage practices. In particular, our technique was able to extract data from multiple layerssocial, technological, and developmental. ViralVCD allowed us to identify key actors and map information diffusion, as well as technology ownership and access. These findings have implications for HCI initiatives targeting low income locales and populations. </span></div></div></td>

<td colspan="5" class="session_details" id="S129_details"><div class="paper"><span class="title">Countertop Responsive Mirror: Supporting Physical Retail Shopping for Sellers, Buyers and Companions</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Maurice Chu" class="author">Maurice Chu</a> <a href="byAffiliation.html#Palo Alto Research Center (PARC)" class="affiliation">Palo Alto Research Center (PARC)</a>,<br /><a href="byAuthors.html#Brinda Dalal" class="author">Brinda Dalal</a> <a href="byAffiliation.html#Palo Alto Research Center (PARC)" class="affiliation">Palo Alto Research Center (PARC)</a>,<br /><a href="byAuthors.html#Alan Walendowski" class="author">Alan Walendowski</a> <a href="byAffiliation.html#Palo Alto Research Center (PARC)" class="affiliation">Palo Alto Research Center (PARC)</a>,<br /><a href="byAuthors.html#Bo Begole" class="author">Bo Begole</a> <a href="byAffiliation.html#Palo Alto Research Center (PARC)" class="affiliation">Palo Alto Research Center (PARC)</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">We examine opportunities for ubiquitous technologies in retail shopping, jewelry shopping in this case, to supplement the unique information needs inherent to physical trials of tactile products.  We describe an iterative design approach to develop a mirror system that records and matches images across jewelry trials called the Countertop Responsive Mirror.  The key technological distinction of our system from prior technologies is the use of matched access, which automatically retrieves images that match a scene shown in separately accessed images.  This not only helps shoppers compare jewelry but also promotes interactions among all parties during shopping.  We report qualitative findings from multiple field trials of the system.  This paper contributes to a body of research on the design and introduction of new technologies into retail shopping that provide value to all users without disruption to their normative practices and behaviors.</span></div></div><div class="paper"><span class="title">Investigating the Opportunity for a Smart Activity Bag</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Sun Young Park" class="author">Sun Young Park</a> <a href="byAffiliation.html#University of California, Irvine" class="affiliation">University of California, Irvine</a>,<br /><a href="byAuthors.html#John Zimmerman" class="author">John Zimmerman</a> <a href="byAffiliation.html#Carnegie Mellon University" class="affiliation">Carnegie Mellon University</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">As long as people have traveled, they have constructed bags to help them carry more items than their hands will hold. While quite effective at keeping things together, bags do a poor job of communicating when something is missing. We propose that there exists an opportunity for the HCI community to improve the quality of people's lives by creating bags that have knowledge of people's schedules and equipment needs, can sense their contents, and can communicate when something has been forgotten. To investigate this opportunity, we conducted a field study with six dual-income families. Through interviews and observations we investigated their experiences using bags to organize equipment needed for children's enrichment activities. Based on the findings we generated 100 concepts and conducted a needs validation session to better understand the best opportunity to improve people's lives with technical intervention. This paper reports on our field study and needs validation session, and shares insights on the opportunities and implications of a smart activity bag.</span></div></div><div class="paper"><span class="title">Snap and Match: A Case Study of Virtual Cosmetics Color Consultation</span> - <span class="type">Paper</span><div class="authors"><a href="byAuthors.html#Jhilmil Jain" class="author">Jhilmil Jain</a> <a href="byAffiliation.html#Hewlett Packard Laboratories" class="affiliation">Hewlett Packard Laboratories</a>,<br /><a href="byAuthors.html#Nina Bhatti" class="author">Nina Bhatti</a> <a href="byAffiliation.html#Hewlett Packard Laboratories" class="affiliation">Hewlett Packard Laboratories</a></div><div class="abstract"><span class="toggleAbstract">Abstract &raquo; </span><span class="abstractText">In this paper we describe an imaging based virtual color consultation system that automatically recommends cosmetics appropriate for users skin tone based on users photograph. This system is intended for commercial use to address the problem of color selection of cosmetic foundation. Based on surveys and semi-structured interviews we have verified that visual selection of color foundation cosmetics by consumers is error prone, and the results of our study indicate that both mobile and kiosk touch points are essential to cover the entire target population (women of all ages) since we identified technical vs. social comfort, accuracy vs. convenience and social vs. individual parameters that play a huge role in the usage and adoption of such personal services for women.</span></div></div></td>

</tr><tr class="timeslot"><td class="time">4:30&nbsp;PM</td>
<td id="SClosingPlenary" style="text-align: left" class="session" colspan="8">
<span class="type">Closing Plenary</span>
<span class="title">Doing what's right with robots: an ethical appraisal of robot application</span>
<span class="author">Noel Sharkey, PhD DSc FIEE FBCS CITP FRIN FRSA</span>
Professor of Artificial Intelligence and Robotics
Professor of Public Engagement
EPSRC Senior Media Fellow
<span class="affiliation">University of Sheffield</span>
</td>
</tr>
</table>
</div>


</body>
</html>

